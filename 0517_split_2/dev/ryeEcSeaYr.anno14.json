{"review": [{"text_id": "ryeEcSeaYr", "sid": 0, "sentence": "This paper proposes a hybrid technique for rendering \u201ccontrol-variate\u201d and class-conditional image in two steps, first by generating an approximate rendering of the image (\u201cY\u201d) conditional on the control variate and then filling in the details with a conditional GAN dependent on a latent noise variable Z (although I note that the caption of Figure 2 which identifies \u201cZ\u201d as the identity makes this rather confusing)."}, {"text_id": "ryeEcSeaYr", "sid": 1, "sentence": "To ensure that Z is used to explain aspects of the model that are separate from the controlled variation, Z is combined in the refinement model at later steps (since otherwise the posterior over Z and Y conditional on X could induce entanglement between the variables)."}, {"text_id": "ryeEcSeaYr", "sid": 2, "sentence": "In the \u201csupervised\u201d setting where the control variates are observed, Y can be learned as a simple regression problem independent of the other parts of the model, and this two-stage refinement process is demonstrated (using inception scores) to generate convincing samples, including when C consists of up to 10 control variates."}, {"text_id": "ryeEcSeaYr", "sid": 3, "sentence": "In the unsupervised setting, a beta-VAE is used to learn a disentangled representation of X as a proxy for C, but then the data is regenerated using a two step process."}, {"text_id": "ryeEcSeaYr", "sid": 4, "sentence": "Readability suggestion: the paper starts with a very nice motivating example, but when the setup is provided, i.e., that (x,c) pairs are the input to the learner, the intended content of c is not immediately clear- control variates could assume anything from general context information to privileged information."}, {"text_id": "ryeEcSeaYr", "sid": 5, "sentence": "A similarly informative example would be great!"}, {"text_id": "ryeEcSeaYr", "sid": 6, "sentence": "Clarification regarding lemma 1: it seems that if the true posterior cannot be expressed by q, a gap will necessarily remain, even in the \u201climit\u201d of perfect learning. Is this correct?"}, {"text_id": "ryeEcSeaYr", "sid": 7, "sentence": "Overall: this paper makes a convincing case that it can be used to generate higher quality images, but not that this improves the quality of the disentangled representations."}, {"text_id": "ryeEcSeaYr", "sid": 8, "sentence": "In fact, the separate training seems to make this unlikely."}], "reviewlabels": [{"text_id": "ryeEcSeaYr", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryeEcSeaYr", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryeEcSeaYr", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryeEcSeaYr", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryeEcSeaYr", "sid": 4, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryeEcSeaYr", "sid": 5, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryeEcSeaYr", "sid": 6, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryeEcSeaYr", "sid": 7, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryeEcSeaYr", "sid": 8, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "Bke8tvvLsH", "sid": 0, "sentence": "-- We will add further clarification regarding what C, Z represent."}, {"text_id": "Bke8tvvLsH", "sid": 1, "sentence": "-- As rightly mentioned by the reviewer, our method can handle very high dimensional control variates."}, {"text_id": "Bke8tvvLsH", "sid": 2, "sentence": "-- Lemma 1: Yes, your assumption is correct in general for variational posterior."}, {"text_id": "Bke8tvvLsH", "sid": 3, "sentence": "-- Improving disentangled representation learning over beta-VAE: Beta-VAE obtains disentangled representations by explicitly posing a trade-off between the \u2018quality of disentanglement\u2019 (factorisation of the posterior) vs. the image reconstruction quality."}, {"text_id": "Bke8tvvLsH", "sid": 4, "sentence": "Our method removes this trade-off\u2014-we decouple \u2018disentanglement of the latents\u2019 from \u2018generation quality\u2019, specifically by having a two-stage training process."}, {"text_id": "Bke8tvvLsH", "sid": 5, "sentence": "This allows us to potentially have much higher disentanglement, while still maintaining image quality, unlike beta-VAE where the quality of generation would necessarily be compromised."}, {"text_id": "Bke8tvvLsH", "sid": 6, "sentence": "We would like to emphasize that this is possible only because of the two-stage training process (please see comments to Reviewer 2 regarding d-separation)."}], "rebuttallabels": [{"labels": {"alignments": [4], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "Bke8tvvLsH", "sid": 0}, {"labels": {"alignments": [2], "responsetype": "accept-praise", "coarseresponse": "concur"}, "text_id": "Bke8tvvLsH", "sid": 1}, {"labels": {"alignments": [6], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Bke8tvvLsH", "sid": 2}, {"labels": {"alignments": [7], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "Bke8tvvLsH", "sid": 3}, {"labels": {"alignments": [7], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "Bke8tvvLsH", "sid": 4}, {"labels": {"alignments": [7], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "Bke8tvvLsH", "sid": 5}, {"labels": {"alignments": [7], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "Bke8tvvLsH", "sid": 6}], "metadata": {"anno": "anno14", "review": "ryeEcSeaYr", "rebuttal": "Bke8tvvLsH", "conference": "ICLR2020", "title": "CZ-GEM:  A  FRAMEWORK  FOR DISENTANGLED REPRESENTATION LEARNING", "reviewer": "AnonReviewer3", "forum_id": "r1e74a4twH", "rating": "1: Reject", "experience_assessment": "I have published one or two papers in this area."}}