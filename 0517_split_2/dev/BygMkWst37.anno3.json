{"review": [{"text_id": "BygMkWst37", "sid": 0, "sentence": "- Summary"}, {"text_id": "BygMkWst37", "sid": 1, "sentence": "This paper proposes a multi-objective evolutionary algorithm for the neural architecture search."}, {"text_id": "BygMkWst37", "sid": 2, "sentence": "Specifically, this paper employs a Lamarckian inheritance mechanism based on network morphism operations for speeding up the architecture search."}, {"text_id": "BygMkWst37", "sid": 3, "sentence": "The proposed method is evaluated on CIFAR-10 and ImageNet (64*64) datasets and compared with recent neural architecture search methods."}, {"text_id": "BygMkWst37", "sid": 4, "sentence": "In this paper, the proposed method aims at solving the multi-objective problem: validation error rate as a first objective and the number of parameters in a network as a second objective."}, {"text_id": "BygMkWst37", "sid": 5, "sentence": "- Pros"}, {"text_id": "BygMkWst37", "sid": 6, "sentence": "- The proposed method does not require to be initialized with well-performing architectures."}, {"text_id": "BygMkWst37", "sid": 7, "sentence": "- This paper proposes the approximate network morphisms to reduce the capacity of a network (e.g., removing a layer), which is reasonable property to control the size of a network for multi-objective problems."}, {"text_id": "BygMkWst37", "sid": 8, "sentence": "- Cons"}, {"text_id": "BygMkWst37", "sid": 9, "sentence": "- Judging from Table 1, the proposed method does not seem to provide a large contribution."}, {"text_id": "BygMkWst37", "sid": 10, "sentence": "For example, while the proposed method introduced the regularization about the number of parameters to the optimization, NASNet V2 and ENAS outperform the proposed method in terms of the accuracy and the number of parameters."}, {"text_id": "BygMkWst37", "sid": 11, "sentence": "- It would be better to provide the details of the procedure of the proposed method (e.g., Algorithm 1 and each processing of Algorithm 1) in the paper, not in the Appendix."}, {"text_id": "BygMkWst37", "sid": 12, "sentence": "- In the case of the search space II, how many GPU days does the proposed method require?"}, {"text_id": "BygMkWst37", "sid": 13, "sentence": "- About line 10 in Algorithm 1, how does the proposed method update the population P? Please elaborate on this procedure."}], "reviewlabels": [{"text_id": "BygMkWst37", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BygMkWst37", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BygMkWst37", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BygMkWst37", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BygMkWst37", "sid": 4, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BygMkWst37", "sid": 5, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BygMkWst37", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BygMkWst37", "sid": 7, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BygMkWst37", "sid": 8, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BygMkWst37", "sid": 9, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "BygMkWst37", "sid": 10, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "BygMkWst37", "sid": 11, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BygMkWst37", "sid": 12, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BygMkWst37", "sid": 13, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "ryxN-nQVRX", "sid": 0, "sentence": "Dear AnonReviewer2,"}, {"text_id": "ryxN-nQVRX", "sid": 1, "sentence": "thank you for your constructive feedback. Below we address your concerns and questions."}, {"text_id": "ryxN-nQVRX", "sid": 2, "sentence": "\u201cJudging from Table 1, the proposed method does not seem to provide a large contribution."}, {"text_id": "ryxN-nQVRX", "sid": 3, "sentence": "For example, while the proposed method introduced the regularization about the number of parameters to the optimization, NASNet V2 and ENAS outperform the proposed method in terms of the accuracy and the number of parameters.\u201c"}, {"text_id": "ryxN-nQVRX", "sid": 4, "sentence": "\u2192 The authors of NASNet only provide results for two regimes of parameters (3.3M and  27M) as they do not perform multi-objective optimization but rather just vary two parameters for building NASNet models (number of cells stacked, number of filters)."}, {"text_id": "ryxN-nQVRX", "sid": 5, "sentence": "Their method might be optimized to yield good results in these regimes and, admittedly, LEMONADE does not outperform NASNet for models with ~4M parameters."}, {"text_id": "ryxN-nQVRX", "sid": 6, "sentence": "However, from Figure 3 and Table 2 one can see that only varying these two parameters for NASNet models is not necessarily sufficient to generate good models across all parameter regimes."}, {"text_id": "ryxN-nQVRX", "sid": 7, "sentence": "E.g., LEMONADE clearly outperforms NASNet for very small models (50k params, 200k params - Table 2)."}, {"text_id": "ryxN-nQVRX", "sid": 8, "sentence": "We also refer to Appendix 3 (\u201cLEMONADE with 5 objectives\u201d), Figure 6, in the updated version of our paper, where one can see that while NASNet has quite strong performance in terms of error, number of parameters and number of multiply-add operations, it performs poorly in terms of inference time."}, {"text_id": "ryxN-nQVRX", "sid": 9, "sentence": "Hence, there is a benefit in doing multi-objective optimization if one is actually interested in multiple objectives and diverse models rather than a single model."}, {"text_id": "ryxN-nQVRX", "sid": 10, "sentence": "This is the main contribution of our paper and different to, e.g., the NASNet paper."}, {"text_id": "ryxN-nQVRX", "sid": 11, "sentence": "The same likely also applies for ENAS (as they use the same search space and conduct very similar experiments)."}, {"text_id": "ryxN-nQVRX", "sid": 12, "sentence": "We also would like to highlight two things: 1) NASNet requires 40x computational resources than LEMONADE, so even if NASNet performs better for ~4M parameter models, LEMONADE achieves competitive performance in significantly less time."}, {"text_id": "ryxN-nQVRX", "sid": 13, "sentence": "2) Table 1 shows results for models trained with different training pipelines and hyperparameters, and hence it is hard to say architecture X performs better than architecture Y since differences could simply be due to e.g. different learning rates, batch sizes, etc."}, {"text_id": "ryxN-nQVRX", "sid": 14, "sentence": "In contrast, all other results in the paper (e.g., Figure 3 and Table 2) provide comparisons with exactly the same training pipeline and hyperparameters."}, {"text_id": "ryxN-nQVRX", "sid": 15, "sentence": "."}, {"text_id": "ryxN-nQVRX", "sid": 16, "sentence": "\u201cIt would be better to provide the details of the procedure of the proposed method (e.g., Algorithm 1 and each processing of Algorithm 1) in the paper, not in the Appendix. \u201c"}, {"text_id": "ryxN-nQVRX", "sid": 17, "sentence": "-> Thanks, we agree; we re-organized our paper accordingly."}, {"text_id": "ryxN-nQVRX", "sid": 18, "sentence": "\u201c- In the case of the search space II, how many GPU days does the proposed method require?"}, {"text_id": "ryxN-nQVRX", "sid": 19, "sentence": "-> We also ran this experiments for 7*8 GPU days, however the method converged after roughly 3*8 GPU days (meaning that there were no significant differences afterwards)."}, {"text_id": "ryxN-nQVRX", "sid": 20, "sentence": "\u201cAbout line 10 in Algorithm 1, how does the proposed method update the population P? Please elaborate on this procedure.\u201d"}, {"text_id": "ryxN-nQVRX", "sid": 21, "sentence": "-> The population is updated to be all non-dominated points from the current population and the generated children, i.e. the Pareto frontier based on all current models."}, {"text_id": "ryxN-nQVRX", "sid": 22, "sentence": "We clarified this in Algorithm 1."}, {"text_id": "ryxN-nQVRX", "sid": 23, "sentence": "Thanks for pointing us towards this."}, {"text_id": "ryxN-nQVRX", "sid": 24, "sentence": "We hope this clarifies your questions. Thanks again for the review!"}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "ryxN-nQVRX", "sid": 0}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "ryxN-nQVRX", "sid": 1}, {"labels": {"alignments": [9], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "ryxN-nQVRX", "sid": 2}, {"labels": {"alignments": [10], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "ryxN-nQVRX", "sid": 3}, {"labels": {"alignments": [9, 10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxN-nQVRX", "sid": 4}, {"labels": {"alignments": [9, 10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxN-nQVRX", "sid": 5}, {"labels": {"alignments": [9, 10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxN-nQVRX", "sid": 6}, {"labels": {"alignments": [9, 10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxN-nQVRX", "sid": 7}, {"labels": {"alignments": [9, 10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxN-nQVRX", "sid": 8}, {"labels": {"alignments": [9, 10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxN-nQVRX", "sid": 9}, {"labels": {"alignments": [9, 10], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "ryxN-nQVRX", "sid": 10}, {"labels": {"alignments": [9, 10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxN-nQVRX", "sid": 11}, {"labels": {"alignments": [9, 10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxN-nQVRX", "sid": 12}, {"labels": {"alignments": [9, 10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxN-nQVRX", "sid": 13}, {"labels": {"alignments": [9, 10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxN-nQVRX", "sid": 14}, {"labels": {"alignments": [9, 10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxN-nQVRX", "sid": 15}, {"labels": {"alignments": [11], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "ryxN-nQVRX", "sid": 16}, {"labels": {"alignments": [11], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "ryxN-nQVRX", "sid": 17}, {"labels": {"alignments": [12], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "ryxN-nQVRX", "sid": 18}, {"labels": {"alignments": [12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxN-nQVRX", "sid": 19}, {"labels": {"alignments": [13], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "ryxN-nQVRX", "sid": 20}, {"labels": {"alignments": [13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxN-nQVRX", "sid": 21}, {"labels": {"alignments": [13], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "ryxN-nQVRX", "sid": 22}, {"labels": {"alignments": [13], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "ryxN-nQVRX", "sid": 23}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "ryxN-nQVRX", "sid": 24}], "metadata": {"anno": "anno3", "review": "BygMkWst37", "rebuttal": "ryxN-nQVRX", "conference": "ICLR2019", "title": "Efficient Multi-Objective Neural Architecture Search via Lamarckian Evolution", "reviewer": "AnonReviewer2", "forum_id": "ByME42AqK7", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}}