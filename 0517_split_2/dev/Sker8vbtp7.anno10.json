{"review": [{"text_id": "Sker8vbtp7", "sid": 0, "sentence": "This paper proposes the Cramer-Wold autoencoder."}, {"text_id": "Sker8vbtp7", "sid": 1, "sentence": "The first contribution of the paper is to propose the Cramer-Wold distance between two distributions based on the Cramer-Wold Theorem."}, {"text_id": "Sker8vbtp7", "sid": 2, "sentence": "More specifically, in order to compute the Cramer-Wold distance, we first find the one dimensional projections of the distributions over random slices, and then compute the average L2 distances of the kernel density estimates of these projections over random slices."}, {"text_id": "Sker8vbtp7", "sid": 3, "sentence": "The second contribution of the paper is to develop a generative autoencoder which uses the Cramer-Wold distance to match the latent distribution of the data to the prior distribution."}, {"text_id": "Sker8vbtp7", "sid": 4, "sentence": "While I found the derivation of the Cramer-Wold distance interesting, the final form of this distance (Eq. 2), to me, looks very similar to the MMD with a particular kernel."}, {"text_id": "Sker8vbtp7", "sid": 5, "sentence": "My main question is that: what is the main advantage of the Cramer-Wold distance to an MMD with a proper kernel?"}, {"text_id": "Sker8vbtp7", "sid": 6, "sentence": "The paper points out that the main theoretical contribution is that in the case of the Gaussian distribution, the Cramer-Wold distance has a closed form."}, {"text_id": "Sker8vbtp7", "sid": 7, "sentence": "However, I believe this is also the case in the MMD, since if one of the distributions is Gaussian or analytically known, then E[k(x,x')] in the MMD can be analytically computed."}, {"text_id": "Sker8vbtp7", "sid": 8, "sentence": "The paper further uses this closed form property of the Cramer-Wold distance to propose the Cramer-Wold autoencoder with Gaussian priors."}, {"text_id": "Sker8vbtp7", "sid": 9, "sentence": "My question here is that how is this method better than the standard VAE, where we also have an analytic form for the ELBO when the prior is Gaussian, an no sampling is required."}, {"text_id": "Sker8vbtp7", "sid": 10, "sentence": "Indeed, in VAEs, the prior does not have to be Gaussian, and as long as the density of the prior can be evaluated, we can efficiently optimize the ELBO without sampling the prior; which I don't think is the case for the Cramer-Wold autoencoder."}, {"text_id": "Sker8vbtp7", "sid": 11, "sentence": "I believe the main advantages of methods such as WAE is that they can impose priors that do not have exact analytic forms."}], "reviewlabels": [{"text_id": "Sker8vbtp7", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Sker8vbtp7", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Sker8vbtp7", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Sker8vbtp7", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Sker8vbtp7", "sid": 4, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Sker8vbtp7", "sid": 5, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Sker8vbtp7", "sid": 6, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Sker8vbtp7", "sid": 7, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Sker8vbtp7", "sid": 8, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Sker8vbtp7", "sid": 9, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Sker8vbtp7", "sid": 10, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Sker8vbtp7", "sid": 11, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "SygaBRNB07", "sid": 0, "sentence": "We thank the reviewer for insight into our paper."}, {"text_id": "SygaBRNB07", "sid": 1, "sentence": "The reviewer found some points, where we were not clear enough. It is now the time to respond to them."}, {"text_id": "SygaBRNB07", "sid": 2, "sentence": "1. The reviewer noticed,"}, {"text_id": "SygaBRNB07", "sid": 3, "sentence": "that  \u201cin the MMD, since if one of the distributions is Gaussian or analytically known, then E[k(x,x')] in the MMD can be analytically computed\u201d."}, {"text_id": "SygaBRNB07", "sid": 4, "sentence": "According to the best knowledge of the authors, the Cramer-Wold kernel (which defines the Cramer-Wold metric), except for the classical RBF kernel, is the only known characteristic kernel which has closed form for radial gaussians, and we believe the respective computations in other cases (like the inverse quadratic kernel used in WAE-MMD), would be highly nontrivial."}, {"text_id": "SygaBRNB07", "sid": 5, "sentence": "2."}, {"text_id": "SygaBRNB07", "sid": 6, "sentence": "The reviewer also points out, that the evidence lower bound ELBO, when used with a notiGaussian prior results in case of VAE in a generally analytic formula."}, {"text_id": "SygaBRNB07", "sid": 7, "sentence": "It was never the intention of the authors to sneak in that VAE cannot do it."}, {"text_id": "SygaBRNB07", "sid": 8, "sentence": "Our primary goal was to define a method for training the Gaussian prior generative model using a different closed form formula for the distribution distance."}, {"text_id": "SygaBRNB07", "sid": 9, "sentence": "At the same time VAE requires encoder to be Gaussian non-deterministic, and random decoder, which is not the case in CWAE (as well as in a WAE model, see Tolstikhin https://arxiv.org/pdf/1711.01558.pdf)."}, {"text_id": "SygaBRNB07", "sid": 10, "sentence": "The kernel used in the derivation is not a Gaussian kernel but has a closed form formula for a product of two Gaussians (see last equation in the current paper), itself not being Gaussian."}, {"text_id": "SygaBRNB07", "sid": 11, "sentence": "The Gaussian kernel itself is not well suited,"}, {"text_id": "SygaBRNB07", "sid": 12, "sentence": "because it has an exponential rate of decay, and loses much information on the outliers (see also Bi\u0144kowski et al.,  https://arxiv.org/pdf/1801.01401.pdf, section 2.1)."}, {"text_id": "SygaBRNB07", "sid": 13, "sentence": "Our objective was to add a method alternative to the WAE method, but simpler in use (e.g. less parameters to be found)."}, {"text_id": "SygaBRNB07", "sid": 14, "sentence": "We have extended the contribution part (in the introduction) and added Sections A and B to the Appendix, to make things clearer."}, {"text_id": "SygaBRNB07", "sid": 15, "sentence": "Thank you again for your comments and suggestions. Have our responses and the changes we made to the manuscript addressed all of your concerns?"}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "SygaBRNB07", "sid": 0}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "SygaBRNB07", "sid": 1}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SygaBRNB07", "sid": 2}, {"labels": {"alignments": [7], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SygaBRNB07", "sid": 3}, {"labels": {"alignments": [7], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "SygaBRNB07", "sid": 4}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SygaBRNB07", "sid": 5}, {"labels": {"alignments": [9], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SygaBRNB07", "sid": 6}, {"labels": {"alignments": [9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SygaBRNB07", "sid": 7}, {"labels": {"alignments": [9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SygaBRNB07", "sid": 8}, {"labels": {"alignments": [9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SygaBRNB07", "sid": 9}, {"labels": {"alignments": [9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SygaBRNB07", "sid": 10}, {"labels": {"alignments": [9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SygaBRNB07", "sid": 11}, {"labels": {"alignments": [9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SygaBRNB07", "sid": 12}, {"labels": {"alignments": [9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SygaBRNB07", "sid": 13}, {"labels": {"alignments": [9], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "SygaBRNB07", "sid": 14}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "SygaBRNB07", "sid": 15}], "metadata": {"anno": "anno10", "review": "Sker8vbtp7", "rebuttal": "SygaBRNB07", "conference": "ICLR2019", "title": "Cramer-Wold AutoEncoder", "reviewer": "AnonReviewer3", "forum_id": "rkgwuiA9F7", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}}