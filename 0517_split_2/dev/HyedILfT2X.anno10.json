{"review": [{"text_id": "HyedILfT2X", "sid": 0, "sentence": "The paper proposes using the nested CRP as a clustering model rather than a topic model."}, {"text_id": "HyedILfT2X", "sid": 1, "sentence": "The clustering is on the latent vector input into a neural network for generating the observation."}, {"text_id": "HyedILfT2X", "sid": 2, "sentence": "A variational approach is derived."}, {"text_id": "HyedILfT2X", "sid": 3, "sentence": "The proposed model seems like a straightforward extension of the nCRP with a deep model hanging off the end of it."}, {"text_id": "HyedILfT2X", "sid": 4, "sentence": "A significant concern/confusion for me is that this doesn't seem to be a mixed membership model, and so I don't know how meaningful it is to generate a level distribution from a Dirichlet and then draw from that mixture one time."}, {"text_id": "HyedILfT2X", "sid": 5, "sentence": "From the generative model it seems every data point has its own Dirichlet vector on levels."}, {"text_id": "HyedILfT2X", "sid": 6, "sentence": "For topic models this makes sense since that vector is then drawn from multiple times (once per word) from a Discrete, so there's a distribution to actually learn."}, {"text_id": "HyedILfT2X", "sid": 7, "sentence": "My understanding is that this isn't being done here."}], "reviewlabels": [{"text_id": "HyedILfT2X", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyedILfT2X", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyedILfT2X", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyedILfT2X", "sid": 3, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyedILfT2X", "sid": 4, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyedILfT2X", "sid": 5, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyedILfT2X", "sid": 6, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyedILfT2X", "sid": 7, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "H1xXoJM_a7", "sid": 0, "sentence": "[Q] The paper proposes using the nested CRP as a clustering model rather than a topic model."}, {"text_id": "H1xXoJM_a7", "sid": 1, "sentence": "The clustering is on the latent vector input into a neural network for generating the observation."}, {"text_id": "H1xXoJM_a7", "sid": 2, "sentence": "A variational approach is derived."}, {"text_id": "H1xXoJM_a7", "sid": 3, "sentence": "The proposed model seems like a straightforward extension of the nCRP with a deep model hanging off the end of it."}, {"text_id": "H1xXoJM_a7", "sid": 4, "sentence": "[A1] Dear Reviewer 2, thank you for the thoughtful review."}, {"text_id": "H1xXoJM_a7", "sid": 5, "sentence": "As the reviewer mentioned, we exploited the nested CRP prior to the path selection process."}, {"text_id": "H1xXoJM_a7", "sid": 6, "sentence": "For performing a hierarchical density estimation task in embedding space, we additionally designed a hierarchical-versioned Gaussian mixture model prior with the nested CRP prior."}, {"text_id": "H1xXoJM_a7", "sid": 7, "sentence": "[Q] A significant concern/confusion for me is that this doesn't seem to be a mixed membership model, and so I don't know how meaningful it is to generate a level distribution from a Dirichlet and then draw from that mixture one time."}, {"text_id": "H1xXoJM_a7", "sid": 8, "sentence": "From the generative model, it seems every data point has its own Dirichlet vector on levels."}, {"text_id": "H1xXoJM_a7", "sid": 9, "sentence": "For topic models, this makes sense since that vector is then drawn from multiple times (once per word) from a Discrete, so there's a distribution to actually learn."}, {"text_id": "H1xXoJM_a7", "sid": 10, "sentence": "My understanding is that this isn't being done here."}, {"text_id": "H1xXoJM_a7", "sid": 11, "sentence": "[A1] Thank you for the very constructive comments."}, {"text_id": "H1xXoJM_a7", "sid": 12, "sentence": "In fact, we intended to model the level proportion as shown in the third part of our generative process on page 4."}, {"text_id": "H1xXoJM_a7", "sid": 13, "sentence": "Often, for grouped-data, the level proportion (or topic proportion) is modeled as a group-specific variable."}, {"text_id": "H1xXoJM_a7", "sid": 14, "sentence": "Under our non-grouped data setting, for example, two following approaches are possible: 1) as the reviewer mentioned, globally define a level proportion once, take multiple level samplings for each data, and 2) as our modeling, locally define the data-specific level proportion, followed by sampling the level (this is actually auxiliary variable for specifying the Gaussian distribution)."}, {"text_id": "H1xXoJM_a7", "sid": 15, "sentence": "The reason we chose the latter approach is for modeling more flexible prior."}, {"text_id": "H1xXoJM_a7", "sid": 16, "sentence": "The Gaussian mixture distributions exist separately for each level, and we assume the generative process that the mixing coefficient for the level would be different for each data."}, {"text_id": "H1xXoJM_a7", "sid": 17, "sentence": "Please consider that the data-instance we handled is a high-dimensional data of a document/an image rather than a word/a pixel."}, {"text_id": "H1xXoJM_a7", "sid": 18, "sentence": "The hierarchically Gaussian mixture distributions are learned for different levels, and here assuming a common level proportion for all data forcefully limits the expressive power of the model."}, {"text_id": "H1xXoJM_a7", "sid": 19, "sentence": "Also, for preventing the overfitting, we placed the common prior, Dirichlet(\\alpha), on the data-specific level proportion, which can be considered as one of the regularization terms."}, {"text_id": "H1xXoJM_a7", "sid": 20, "sentence": "[A2] Also, I would like to explain the reviewer\u2019s comment as the formulae."}, {"text_id": "H1xXoJM_a7", "sid": 21, "sentence": "The prior we suggested is this: \\sum_{\\zeta, l} nCRP(\\zeta_n) * \\eta_{nl} * Normal(-) (\uf0e0 please refer to the Figure 3(a).)."}, {"text_id": "H1xXoJM_a7", "sid": 22, "sentence": "Moreover, the point that the reviewer pointed out is on \\eta_{nl}, i.e., \u2018the reason for designing \\eta as \\eta_{nl}, why \\eta is data-specific variable?"}, {"text_id": "H1xXoJM_a7", "sid": 23, "sentence": "\u2019"}, {"text_id": "H1xXoJM_a7", "sid": 24, "sentence": "."}, {"text_id": "H1xXoJM_a7", "sid": 25, "sentence": "There are similar works, which previously published [1-3]."}, {"text_id": "H1xXoJM_a7", "sid": 26, "sentence": "They designed data-specific mixing coefficients of Gaussian mixture models, for improving more flexibility like ours."}, {"text_id": "H1xXoJM_a7", "sid": 27, "sentence": "[1] Ban, Zhihua, Jianguo Liu, and Li Cao. \"Superpixel Segmentation Using Gaussian Mixture Model.\" IEEE Transactions on Image Processing 27.8 (2018): 4105-4117."}, {"text_id": "H1xXoJM_a7", "sid": 28, "sentence": "[2] Zhang, Hui, et al. \"Automatic Visual Detection System of Railway Surface Defects With Curvature Filter and Improved Gaussian Mixture Model.\" IEEE Transactions on Instrumentation and Measurement 67.7 (2018): 1593-1608."}, {"text_id": "H1xXoJM_a7", "sid": 29, "sentence": "[3] Ji, Zexuan, et al. \"A spatially constrained generative asymmetric Gaussian mixture model for image segmentation.\" Journal of Visual Communication and Image Representation 40 (2016): 611-626."}, {"text_id": "H1xXoJM_a7", "sid": 30, "sentence": "Under the newly proposed Gaussian mixture models from the above papers, the cluster assignment of data is sampled once from the data-specific mixing coefficient, where there is no theoretical problem as a fully Bayesian formalization."}, {"text_id": "H1xXoJM_a7", "sid": 31, "sentence": "[A3] We were very impressed with the mathematical detail of the reviewer\u2019s comment and thanked you to the reviewer again. If the reviewer agrees with our argument, we will reflect the argument in our paper."}, {"text_id": "H1xXoJM_a7", "sid": 32, "sentence": "Best regards,"}], "rebuttallabels": [{"labels": {"alignments": [0], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "H1xXoJM_a7", "sid": 0}, {"labels": {"alignments": [1], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "H1xXoJM_a7", "sid": 1}, {"labels": {"alignments": [2], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "H1xXoJM_a7", "sid": 2}, {"labels": {"alignments": [3], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "H1xXoJM_a7", "sid": 3}, {"labels": {"alignments": [0, 1, 2, 3], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "H1xXoJM_a7", "sid": 4}, {"labels": {"alignments": [0, 1, 2, 3], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "H1xXoJM_a7", "sid": 5}, {"labels": {"alignments": [0, 1, 2, 3], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "H1xXoJM_a7", "sid": 6}, {"labels": {"alignments": [4], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "H1xXoJM_a7", "sid": 7}, {"labels": {"alignments": [5], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "H1xXoJM_a7", "sid": 8}, {"labels": {"alignments": [6], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "H1xXoJM_a7", "sid": 9}, {"labels": {"alignments": [7], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "H1xXoJM_a7", "sid": 10}, {"labels": {"alignments": [4, 5, 6, 7], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "H1xXoJM_a7", "sid": 11}, {"labels": {"alignments": [4, 5, 6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1xXoJM_a7", "sid": 12}, {"labels": {"alignments": [4, 5, 6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1xXoJM_a7", "sid": 13}, {"labels": {"alignments": [4, 5, 6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1xXoJM_a7", "sid": 14}, {"labels": {"alignments": [4, 5, 6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1xXoJM_a7", "sid": 15}, {"labels": {"alignments": [4, 5, 6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1xXoJM_a7", "sid": 16}, {"labels": {"alignments": [4, 5, 6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1xXoJM_a7", "sid": 17}, {"labels": {"alignments": [4, 5, 6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1xXoJM_a7", "sid": 18}, {"labels": {"alignments": [4, 5, 6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1xXoJM_a7", "sid": 19}, {"labels": {"alignments": [4, 5, 6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1xXoJM_a7", "sid": 20}, {"labels": {"alignments": [4, 5, 6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1xXoJM_a7", "sid": 21}, {"labels": {"alignments": [4, 5, 6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1xXoJM_a7", "sid": 22}, {"labels": {"alignments": [4, 5, 6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1xXoJM_a7", "sid": 23}, {"labels": {"alignments": [4, 5, 6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1xXoJM_a7", "sid": 24}, {"labels": {"alignments": [4, 5, 6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1xXoJM_a7", "sid": 25}, {"labels": {"alignments": [4, 5, 6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1xXoJM_a7", "sid": 26}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "H1xXoJM_a7", "sid": 27}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "H1xXoJM_a7", "sid": 28}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "H1xXoJM_a7", "sid": 29}, {"labels": {"alignments": [4, 5, 6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1xXoJM_a7", "sid": 30}, {"labels": {"alignments": [4, 5, 6, 7], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "H1xXoJM_a7", "sid": 31}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "H1xXoJM_a7", "sid": 32}], "metadata": {"anno": "anno10", "review": "HyedILfT2X", "rebuttal": "H1xXoJM_a7", "conference": "ICLR2019", "title": "Hierarchically Clustered Representation Learning", "reviewer": "AnonReviewer2", "forum_id": "H1ERcs09KQ", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}}