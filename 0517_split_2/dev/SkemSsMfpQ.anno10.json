{"review": [{"text_id": "SkemSsMfpQ", "sid": 0, "sentence": "The paper presents a novel idea of generating discrete data such as graphs that is conditional on input data to control the graph structure that is being generated."}, {"text_id": "SkemSsMfpQ", "sid": 1, "sentence": "Given an input graph, the proposed method infers a target graph by learning their underlying translation mapping by using new graph convolution and deconvolution"}, {"text_id": "SkemSsMfpQ", "sid": 2, "sentence": "layers to learn the global and local translation mapping."}, {"text_id": "SkemSsMfpQ", "sid": 3, "sentence": "The idea of learning generic shared common and latent implicit patterns across different graph structure is brilliant."}, {"text_id": "SkemSsMfpQ", "sid": 4, "sentence": "Their method learns a distribution over graphs conditioned on the input graph whilst allowing the network to learn latent and implicit properties."}, {"text_id": "SkemSsMfpQ", "sid": 5, "sentence": "The authors claim that their method is applicable for large graphs."}, {"text_id": "SkemSsMfpQ", "sid": 6, "sentence": "However, it seems the experiments do not seem to support this."}, {"text_id": "SkemSsMfpQ", "sid": 7, "sentence": "It is not clear how the noise is introduced in the graphs."}, {"text_id": "SkemSsMfpQ", "sid": 8, "sentence": "I would have expected to see some analysis and results on the translation quality over systematic noise applied to the input graph."}, {"text_id": "SkemSsMfpQ", "sid": 9, "sentence": "It is also not clear what are the assumptions made on the connectivity of the input graph and the target graph."}, {"text_id": "SkemSsMfpQ", "sid": 10, "sentence": "Do we know how does the connectedness of the  input graph affect the translation quality in the case of strongly connected directed graphs? Or what happens if the target graph has a strong connectivity?"}, {"text_id": "SkemSsMfpQ", "sid": 11, "sentence": "Towards this, how does the computational complexity scale wrt to the connectedness?"}, {"text_id": "SkemSsMfpQ", "sid": 12, "sentence": "A lot of clarity is required on the choice of evaluation metric; for example choice of distance measure ?"}, {"text_id": "SkemSsMfpQ", "sid": 13, "sentence": "What is the L1 norm applied on?"}, {"text_id": "SkemSsMfpQ", "sid": 14, "sentence": "I did not completely follow the arguments towards directed graph deconvolution operators."}, {"text_id": "SkemSsMfpQ", "sid": 15, "sentence": "There is lack of clarity and the explanation seems lacking in parts in this particular section; especially since this is the key contribution of this work"}, {"text_id": "SkemSsMfpQ", "sid": 16, "sentence": "Typo:. The \u201cInf\u201d in Tabel 1"}], "reviewlabels": [{"text_id": "SkemSsMfpQ", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SkemSsMfpQ", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "SkemSsMfpQ", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "SkemSsMfpQ", "sid": 3, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SkemSsMfpQ", "sid": 4, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SkemSsMfpQ", "sid": 5, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SkemSsMfpQ", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SkemSsMfpQ", "sid": 7, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Replicability", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SkemSsMfpQ", "sid": 8, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SkemSsMfpQ", "sid": 9, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Replicability", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SkemSsMfpQ", "sid": 10, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Replicability", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SkemSsMfpQ", "sid": 11, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Replicability", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SkemSsMfpQ", "sid": 12, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Replicability", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SkemSsMfpQ", "sid": 13, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Replicability", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SkemSsMfpQ", "sid": 14, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SkemSsMfpQ", "sid": 15, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SkemSsMfpQ", "sid": 16, "labels": {"coarse": "Request", "fine": "Request.Typo", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "SJlugpiVaX", "sid": 0, "sentence": "-----------------------------------------------------------------------"}, {"text_id": "SJlugpiVaX", "sid": 1, "sentence": "Q\uff1aA lot of clarity is required on the choice of evaluation metric; for example, choice of distance measure?"}, {"text_id": "SJlugpiVaX", "sid": 2, "sentence": "What is the L1 norm applied on?"}, {"text_id": "SJlugpiVaX", "sid": 3, "sentence": "A: Answer about Evaluation metrics:"}, {"text_id": "SJlugpiVaX", "sid": 4, "sentence": "(1) We want to evaluate if the generated graphs are scale-free graphs in the direct evaluation for dataset scale-free graphs."}, {"text_id": "SJlugpiVaX", "sid": 5, "sentence": "If the degree distribution of generated graphs is the same to the degree distribution of real target graphs, the generated graphs are good."}, {"text_id": "SJlugpiVaX", "sid": 6, "sentence": "(2) There are many classical evaluation metrics focusing on measuring the similarities or distance of two distributions."}, {"text_id": "SJlugpiVaX", "sid": 7, "sentence": "The four metrics in this paper are among the most authoritative and commonly used ones in existing works, e.g., [2][3][4][5]."}, {"text_id": "SJlugpiVaX", "sid": 8, "sentence": "Answer about L1 norm:"}, {"text_id": "SJlugpiVaX", "sid": 9, "sentence": "(1) L1 norm is applied to the weight adjacent matrix of the graph."}, {"text_id": "SJlugpiVaX", "sid": 10, "sentence": "Our methodology is achieved by a trade-off between L1 loss and adversarial loss (GAN-D)."}, {"text_id": "SJlugpiVaX", "sid": 11, "sentence": "Specifically, L1 makes generated graphs share the same rough outline of sparsity pattern like generated graphs, while under this outline, adversarial loss allows them to vary to some degree."}, {"text_id": "SJlugpiVaX", "sid": 12, "sentence": "(2) L1 norm is commonly used in GAN in relevant domains, e.g., in image-translation domain, for example, reference [1] (with 600+ citations) and reference [6] (with 1300+ citations)."}, {"text_id": "SJlugpiVaX", "sid": 13, "sentence": "They have done extensive experiments to show the advantage of such a strategy."}, {"text_id": "SJlugpiVaX", "sid": 14, "sentence": "(3) The experiment demonstrates its effectiveness."}, {"text_id": "SJlugpiVaX", "sid": 15, "sentence": "Specifically, the proposed GT-GAN that uses L1 norm outperformed all the other comparison methods shown in Table 2,3 and 4."}, {"text_id": "SJlugpiVaX", "sid": 16, "sentence": "-------[2"}, {"text_id": "SJlugpiVaX", "sid": 17, "sentence": "]"}, {"text_id": "SJlugpiVaX", "sid": 18, "sentence": "Schieber, T. A., Carpi, L., D\u00edaz-Guilera, A., Pardalos, P. M., Masoller, C., & Ravetti, M. G. (2017)."}, {"text_id": "SJlugpiVaX", "sid": 19, "sentence": "Quantification of network structural dissimilarities."}, {"text_id": "SJlugpiVaX", "sid": 20, "sentence": "Nature Communications, 8, 13928."}, {"text_id": "SJlugpiVaX", "sid": 21, "sentence": "-------[3] Bauckhage, C., Kersting, K., & Hadiji, F. (2015, July). Parameterizing the Distance Distribution of Undirected Networks. In UAI (pp. 121-130)."}, {"text_id": "SJlugpiVaX", "sid": 22, "sentence": "-------[4] Chiang, S., Cassese, A., Guindani, M., Vannucci, M., Yeh, H. J., Haneef, Z., & Stern, J. M. (2016)."}, {"text_id": "SJlugpiVaX", "sid": 23, "sentence": "Time-dependence of graph theory metrics in functional connectivity analysis. NeuroImage, 125, 601-615."}, {"text_id": "SJlugpiVaX", "sid": 24, "sentence": "-------[5] You, J., Ying, R., Ren, X., Hamilton, W. L., & Leskovec, J. (2018). GraphRNN: A Deep Generative Model for Graphs. arXiv preprint arXiv:1802.08773."}, {"text_id": "SJlugpiVaX", "sid": 25, "sentence": "-------[6"}, {"text_id": "SJlugpiVaX", "sid": 26, "sentence": "] Isola, P., Zhu, J. Y., Zhou, T., & Efros, A. A. (2017). Image-to-image translation with conditional adversarial networks. arXiv preprint."}, {"text_id": "SJlugpiVaX", "sid": 27, "sentence": "-----------------------------------------------------------------------"}, {"text_id": "SJlugpiVaX", "sid": 28, "sentence": "Q\uff1aI did not completely follow the arguments towards directed graph deconvolution operators."}, {"text_id": "SJlugpiVaX", "sid": 29, "sentence": "There is lack of clarity and the explanation seems lacking in parts in this particular section; especially since this is the key contribution of this work."}, {"text_id": "SJlugpiVaX", "sid": 30, "sentence": "A: (1) Our decoder is symmetric to the encoder in their architectures."}, {"text_id": "SJlugpiVaX", "sid": 31, "sentence": "The encoder does n-hop edge information aggregation from the input graphs and learns the latent representation of nodes."}, {"text_id": "SJlugpiVaX", "sid": 32, "sentence": "Then, we first decode the node embedding to get the n-hop aggregated information on edges by node-to-edge layer and then we further decode the n-hop aggregated information layer by layer by n-layers back to get the output adjacency matrix."}, {"text_id": "SJlugpiVaX", "sid": 33, "sentence": "(2) Different from image deconvolution, for each hidden channel, we have two filters vertical to each other, i.e., one is a column vector while the other is a row vector."}, {"text_id": "SJlugpiVaX", "sid": 34, "sentence": "To get the nth hop information of edge <i,j>, row filter decodes all the (n+1)-th hop information of outgoing edges of node i and column filter decodes all the (n+1)-th hop information of incoming edges of node j."}, {"text_id": "SJlugpiVaX", "sid": 35, "sentence": "(3) To make our description clearer, we have updated our paper in Section 3.2.2, e.g, by adding \u201cTo get the nth hop information Aij, row filter decodes all the (n+1)-th hop information of outgoing edges of Vi and column filter decodes all the (n+1)-th hop information of incoming edges of Vj.\u201d"}, {"text_id": "SJlugpiVaX", "sid": 36, "sentence": "-----------------------------------------------------------------------"}, {"text_id": "SJlugpiVaX", "sid": 37, "sentence": "Q: Typo:. The \u201cInf\u201d in Tabel 1"}, {"text_id": "SJlugpiVaX", "sid": 38, "sentence": "A: As explained in Section 4.2.4 \u201cResults on Scale-Free Graphs\u201d, the \u201cInf\u201d in Tabel 1 represents the distance more than 1000."}, {"text_id": "SJlugpiVaX", "sid": 39, "sentence": "We really hope that we have explained every confused point clearly and please let us know if there are any other points."}, {"text_id": "SJlugpiVaX", "sid": 40, "sentence": "Thank you once again for your reviews."}, {"text_id": "SJlugpiVaX", "sid": 41, "sentence": "Dear Reviewer:"}, {"text_id": "SJlugpiVaX", "sid": 42, "sentence": "Thank you very much for your comments and suggestions."}, {"text_id": "SJlugpiVaX", "sid": 43, "sentence": "We would like to answer your questions in detail as follows:"}, {"text_id": "SJlugpiVaX", "sid": 44, "sentence": "-----------------------------------------------------------------------"}, {"text_id": "SJlugpiVaX", "sid": 45, "sentence": "Q: The authors claim that their method is applicable for large graphs."}, {"text_id": "SJlugpiVaX", "sid": 46, "sentence": "However, it seems the experiments do not seem to support this."}, {"text_id": "SJlugpiVaX", "sid": 47, "sentence": "A: (1) We did not mention that we handle \u201clarge graph\u201d, but instead we only mention that we handle \u201clarger\u201d graph."}, {"text_id": "SJlugpiVaX", "sid": 48, "sentence": "In the domain of graph generation, currently, the proposed graph generative models can typically only deal with graphs with dozens of nodes or less (except GraphRNN which can scale to 300)."}, {"text_id": "SJlugpiVaX", "sid": 49, "sentence": "Compared to them, our model handles relatively \u201clarger graph\u201d (6-10 times larger than most existing methods)."}, {"text_id": "SJlugpiVaX", "sid": 50, "sentence": "(2) Translation in graphs is a new topic and we have not found many datasets in very large scale, so we do not test on much larger nodes. But the scalability experiments can still show the superiority of our model compared to others."}, {"text_id": "SJlugpiVaX", "sid": 51, "sentence": "(3) We typically test small-size graphs because most of the comparison methods can only handle small-size graphs."}, {"text_id": "SJlugpiVaX", "sid": 52, "sentence": "-----------------------------------------------------------------------"}, {"text_id": "SJlugpiVaX", "sid": 53, "sentence": "Q: It is not clear how the noise is introduced in the graphs. I would have expected to see some analysis and results on the translation quality over systematic noise applied to the input graph."}, {"text_id": "SJlugpiVaX", "sid": 54, "sentence": "A: Thanks for the review comment."}, {"text_id": "SJlugpiVaX", "sid": 55, "sentence": "(1) The noise is introduced by the dropout function in each convolution layer."}, {"text_id": "SJlugpiVaX", "sid": 56, "sentence": "Dropout functions by randomly ignore 50% of neuron\u2019s output of a network in our mode by a uniform distribution."}, {"text_id": "SJlugpiVaX", "sid": 57, "sentence": "(2) The way we add noise"}, {"text_id": "SJlugpiVaX", "sid": 58, "sentence": "is well-recognized and commonly-used in generative deep learning models[1]."}, {"text_id": "SJlugpiVaX", "sid": 59, "sentence": "The noises added in GANs aim to enable the diversities in the generated graphs to avoid the problem that GANs tend to favor producing same output rather than spreading it evenly over the domain."}, {"text_id": "SJlugpiVaX", "sid": 60, "sentence": "(3) We have shown the analysis of the translation quality against noise in Figures 4 and 5."}, {"text_id": "SJlugpiVaX", "sid": 61, "sentence": "In Figure 5 (see in the supplementary material), each logarithm plot in each column show the power-law trend of each randomly generated graph, which will look linear in such a logarithm plot."}, {"text_id": "SJlugpiVaX", "sid": 62, "sentence": "It can be seen that the generated graphs show the similar randomness pattern as the real graphs."}, {"text_id": "SJlugpiVaX", "sid": 63, "sentence": "Moreover, the larger the graph is (see the graph size of 150), the smaller the randomness is, and the clearer the power-law trend is, which verifies that the translation quality of our method."}, {"text_id": "SJlugpiVaX", "sid": 64, "sentence": "------[1]"}, {"text_id": "SJlugpiVaX", "sid": 65, "sentence": "Isola, P., Zhu, J. Y., Zhou, T., & Efros, A. A. (2017). Image-to-image translation with conditional adversarial networks. arXiv preprint."}, {"text_id": "SJlugpiVaX", "sid": 66, "sentence": "-----------------------------------------------------------------------"}, {"text_id": "SJlugpiVaX", "sid": 67, "sentence": "Q: It is also not clear what are the assumptions made on the connectivity of the input graph and the target graph."}, {"text_id": "SJlugpiVaX", "sid": 68, "sentence": "Do we know how does the connectedness of the input graph affect the translation quality in the case of strongly connected directed graphs? Or what happens if the target graph has a strong connectivity?"}, {"text_id": "SJlugpiVaX", "sid": 69, "sentence": "Towards this, how does the computational complexity scale wrt to the connectedness?"}, {"text_id": "SJlugpiVaX", "sid": 70, "sentence": "A: (1) Similar to all the existing graph deep generative learning methods for generic graphs, we do not have additional assumptions on the graphs."}, {"text_id": "SJlugpiVaX", "sid": 71, "sentence": "The domain of graph deep generative learning methods typically do not require to distinguish or preprocess specific topological types of graphs before applying it, no matter it is strongly- or weakly- connected graph, complete graph, planar graph, scale-free graph, or graphs that have other specific patterns."}, {"text_id": "SJlugpiVaX", "sid": 72, "sentence": "This is actually one of the core advantages of deep learning based models where the graph patterns are not extracted or pre-identified manually by the human but automatically discovered by the end-to-end deep models."}, {"text_id": "SJlugpiVaX", "sid": 73, "sentence": "(2) This paper has given the time complexity in the worst case: O(n^2) as shown in 3.4."}, {"text_id": "SJlugpiVaX", "sid": 74, "sentence": "The worst case happens when the graph is a complete graph."}, {"text_id": "SJlugpiVaX", "sid": 75, "sentence": "The time complexity of a strongly-connected graph will not be worse than that."}, {"text_id": "SJlugpiVaX", "sid": 76, "sentence": "Dear Reviewer,"}, {"text_id": "SJlugpiVaX", "sid": 77, "sentence": "Thank you very much for your new and previous comments."}, {"text_id": "SJlugpiVaX", "sid": 78, "sentence": "We have revised our paper again in order to address all of them in the paper."}, {"text_id": "SJlugpiVaX", "sid": 79, "sentence": "The modifications are listed as followings:"}, {"text_id": "SJlugpiVaX", "sid": 80, "sentence": "1. For graph deconvolution, we have modified and reorganized the content."}, {"text_id": "SJlugpiVaX", "sid": 81, "sentence": "The Section 3.2.2 on \u201cGraph Deconvolution\u201d has been reorganized to two subsections \u201cnode-to-edge deconvolution\u201d and \u201cedge-to-edge deconvolution\u201d."}, {"text_id": "SJlugpiVaX", "sid": 82, "sentence": "We also extended them to make the description on deconvolution operations clearer and more comprehensive."}, {"text_id": "SJlugpiVaX", "sid": 83, "sentence": "2."}, {"text_id": "SJlugpiVaX", "sid": 84, "sentence": "For graph deconvolution, we have also added a new figure and refined the equations\u2019 descriptions."}, {"text_id": "SJlugpiVaX", "sid": 85, "sentence": "Figure 3 is added to describe the mechanism of our proposed deconvolution operators as well as their correlation to the convolution operations."}, {"text_id": "SJlugpiVaX", "sid": 86, "sentence": "Equation 6, Equation 7, and their descriptions have also been revised to make them clearer and concrete."}, {"text_id": "SJlugpiVaX", "sid": 87, "sentence": "Specifically, Figure 3 describes how the node representation and edge representation are respectively decoded by our deconvolution layers, while Equation 6 and Equation 7 describe how to aggregate the decoded information into the final weighted adjacent matrix."}, {"text_id": "SJlugpiVaX", "sid": 88, "sentence": "3. We have referred to all the figures in the body of text."}, {"text_id": "SJlugpiVaX", "sid": 89, "sentence": "4. We have added statements to describe how to introduce random noises in the whole architecture, see in the 2nd paragraph of Section 3.1 in Page 4."}, {"text_id": "SJlugpiVaX", "sid": 90, "sentence": "5. We have added statements of describing the reason to use L1 loss and how L1 loss is applied, please see in the paragraph before Equation 2 in Page 4."}, {"text_id": "SJlugpiVaX", "sid": 91, "sentence": "Additionally, we also added the statements of how L1 norm and GAN loss function jointly, see in the paragraph after Equation 2."}, {"text_id": "SJlugpiVaX", "sid": 92, "sentence": "6. We have added the statements why the metrics are chosen to evaluate the scale-free dataset, please see in the 2nd Paragraph of Section 4.2.2."}, {"text_id": "SJlugpiVaX", "sid": 93, "sentence": "Additionally, to improve the reproducibility of the proposed methodologies and experiments, we have already released our code in https://github.com/anonymous1025/Deep-Graph-Translation-."}, {"text_id": "SJlugpiVaX", "sid": 94, "sentence": "More architecture parameters are also provided in Appendix E."}, {"text_id": "SJlugpiVaX", "sid": 95, "sentence": "Thank you very much again for the comments and please let us know if there are any other issues."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 0}, {"labels": {"alignments": [12], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 1}, {"labels": {"alignments": [13], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 2}, {"labels": {"alignments": [12], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 3}, {"labels": {"alignments": [12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 4}, {"labels": {"alignments": [12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 5}, {"labels": {"alignments": [12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 6}, {"labels": {"alignments": [12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 7}, {"labels": {"alignments": [13], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 8}, {"labels": {"alignments": [13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 9}, {"labels": {"alignments": [13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 10}, {"labels": {"alignments": [13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 11}, {"labels": {"alignments": [13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 12}, {"labels": {"alignments": [13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 13}, {"labels": {"alignments": [13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 14}, {"labels": {"alignments": [13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 15}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 16}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 17}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 18}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 19}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 20}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 21}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 22}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 23}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 24}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 25}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 26}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 27}, {"labels": {"alignments": [14], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 28}, {"labels": {"alignments": [15], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 29}, {"labels": {"alignments": [14, 15], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 30}, {"labels": {"alignments": [14, 15], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 31}, {"labels": {"alignments": [14, 15], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 32}, {"labels": {"alignments": [14, 15], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 33}, {"labels": {"alignments": [14, 15], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 34}, {"labels": {"alignments": [14, 15], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 35}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 36}, {"labels": {"alignments": [16], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 37}, {"labels": {"alignments": [16], "responsetype": "reject-request_scope_No", "coarseresponse": "dispute"}, "text_id": "SJlugpiVaX", "sid": 38}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 39}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 40}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 41}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 42}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 43}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 44}, {"labels": {"alignments": [5], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 45}, {"labels": {"alignments": [6], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 46}, {"labels": {"alignments": [5, 6], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "SJlugpiVaX", "sid": 47}, {"labels": {"alignments": [5, 6], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "SJlugpiVaX", "sid": 48}, {"labels": {"alignments": [5, 6], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "SJlugpiVaX", "sid": 49}, {"labels": {"alignments": [5, 6], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 50}, {"labels": {"alignments": [5, 6], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 51}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 52}, {"labels": {"alignments": [7, 8], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 53}, {"labels": {"alignments": [7, 8], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 54}, {"labels": {"alignments": [7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 55}, {"labels": {"alignments": [7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 56}, {"labels": {"alignments": [7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 57}, {"labels": {"alignments": [7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 58}, {"labels": {"alignments": [7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 59}, {"labels": {"alignments": [7, 8], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 60}, {"labels": {"alignments": [7, 8], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 61}, {"labels": {"alignments": [7, 8], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 62}, {"labels": {"alignments": [7, 8], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 63}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 64}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 65}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 66}, {"labels": {"alignments": [9], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 67}, {"labels": {"alignments": [10], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 68}, {"labels": {"alignments": [11], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 69}, {"labels": {"alignments": [10, 11], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 70}, {"labels": {"alignments": [10, 11], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 71}, {"labels": {"alignments": [10, 11], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 72}, {"labels": {"alignments": [10, 11], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 73}, {"labels": {"alignments": [10, 11], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 74}, {"labels": {"alignments": [10, 11], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 75}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 76}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 77}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 78}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 79}, {"labels": {"alignments": [], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 80}, {"labels": {"alignments": [], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 81}, {"labels": {"alignments": [], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 82}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 83}, {"labels": {"alignments": [], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 84}, {"labels": {"alignments": [], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 85}, {"labels": {"alignments": [], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 86}, {"labels": {"alignments": [], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 87}, {"labels": {"alignments": [], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 88}, {"labels": {"alignments": [], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 89}, {"labels": {"alignments": [], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 90}, {"labels": {"alignments": [], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 91}, {"labels": {"alignments": [], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 92}, {"labels": {"alignments": [], "responsetype": "done_manu_No", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 93}, {"labels": {"alignments": [], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "SJlugpiVaX", "sid": 94}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "SJlugpiVaX", "sid": 95}], "metadata": {"anno": "anno10", "review": "SkemSsMfpQ", "rebuttal": "SJlugpiVaX", "conference": "ICLR2019", "title": "DEEP GRAPH TRANSLATION", "reviewer": "AnonReviewer1", "forum_id": "SJz6MnC5YQ", "rating": "5: Marginally below acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}}