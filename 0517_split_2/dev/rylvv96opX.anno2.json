{"review": [{"text_id": "rylvv96opX", "sid": 0, "sentence": "This paper discusses the addition of a regularizer to a standard sparse coding/dictionary learning algorithm to encourage the atoms to be used with uniform frequency."}, {"text_id": "rylvv96opX", "sid": 1, "sentence": "I do not think this work should be accepted to the conference for the following reasons:"}, {"text_id": "rylvv96opX", "sid": 2, "sentence": "1: The authors show no benefit of this scheme except perhaps faster convergence."}, {"text_id": "rylvv96opX", "sid": 3, "sentence": "If faster training of dictionary learning models was a bottleneck in practical applications, this might be of interest, but it is not."}, {"text_id": "rylvv96opX", "sid": 4, "sentence": "SPAMS (http://spams-devel.gforge.inria.fr/) can train a model on image patches as the authors do here in a few tens of seconds on a modern computer."}, {"text_id": "rylvv96opX", "sid": 5, "sentence": "On the other hand, the authors give no evidence, empirical or otherwise, that their method is useful on any downstream tasks."}, {"text_id": "rylvv96opX", "sid": 6, "sentence": "In my view, they do not even show that the distribution of atom usage will be better with their algorithm after the learning has converged, as at least according to their learning curves, the baselines have not finished converging."}, {"text_id": "rylvv96opX", "sid": 7, "sentence": "It is not even clear that the final compression of the baselines would not be better."}, {"text_id": "rylvv96opX", "sid": 8, "sentence": "Even if they did show these convincingly, it is not obvious to me that it is valuable; the authors need to *show* that uniform usage is desirable."}, {"text_id": "rylvv96opX", "sid": 9, "sentence": "2:    The authors should compare against several costs/algorithms (e.g. l_0 with OMP, l_1 with LARS, etc.), and across various N_0/sparsity penalties, and across several datasets."}, {"text_id": "rylvv96opX", "sid": 10, "sentence": "The empirical evaluation is quite weak- one sparsity setting, two baselines, one dataset"}, {"text_id": "rylvv96opX", "sid": 11, "sentence": "."}, {"text_id": "rylvv96opX", "sid": 12, "sentence": "Even without the \"train to convergence\" question above, I don't think the authors have demonstrated that their claims on the properties of their algorithms/formulations are generally true."}], "reviewlabels": [{"text_id": "rylvv96opX", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rylvv96opX", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rylvv96opX", "sid": 2, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Motivation/Impact", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rylvv96opX", "sid": 3, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Motivation/Impact", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rylvv96opX", "sid": 4, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rylvv96opX", "sid": 5, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rylvv96opX", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rylvv96opX", "sid": 7, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rylvv96opX", "sid": 8, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rylvv96opX", "sid": 9, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Meaningful Comparison", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rylvv96opX", "sid": 10, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "rylvv96opX", "sid": 11, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "rylvv96opX", "sid": 12, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "BylRLBcBAQ", "sid": 0, "sentence": "We thank the reviewer for having taken the time to judge our paper and to have detailed his judgement on their two points."}, {"text_id": "BylRLBcBAQ", "sid": 1, "sentence": "We would like to point out that AnonReviewer4's final quantitative score as well as the confidence given will be crucial for the fact that this paper will or will not be presented at ICLR."}, {"text_id": "BylRLBcBAQ", "sid": 2, "sentence": "We would like to respectfully detail how we completely disagree with the comments given in the two points, but acknowledge that this was mainly due to the way we presented the motivation for the paper."}, {"text_id": "BylRLBcBAQ", "sid": 3, "sentence": "We hope the revised version of the paper now meets the standards for ICLR and justifies to update the \"red flag\" (clear rejection) to a green light."}, {"text_id": "BylRLBcBAQ", "sid": 4, "sentence": "First, the goal is not faster computation on a CPU."}, {"text_id": "BylRLBcBAQ", "sid": 5, "sentence": "Our (github-shared) code runs in a few dozens of seconds per learning on a standard laptop - but the goal is mainly to be able to test all parameters."}, {"text_id": "BylRLBcBAQ", "sid": 6, "sentence": "We have not used SPAMS in this work as we could use the similar methods which are used in the sklearn library."}, {"text_id": "BylRLBcBAQ", "sid": 7, "sentence": "However, SPAMS is a great inspiration for our framework."}, {"text_id": "BylRLBcBAQ", "sid": 8, "sentence": "(For information, the complete simulations for this paper take approximately 12 hours --which are easily distributed on a cluster as we multiplied the number of independent learning runs using different classes of parameters, cross-validations and types of sparse coding algorithms - in total approx 500 experiments."}, {"text_id": "BylRLBcBAQ", "sid": 9, "sentence": "It takes a dozens of minutes on a 100 nodes cluster."}, {"text_id": "BylRLBcBAQ", "sid": 10, "sentence": ")."}, {"text_id": "BylRLBcBAQ", "sid": 11, "sentence": "Our motivation is mainly to understand biological vision and hope this would percolate to ML."}, {"text_id": "BylRLBcBAQ", "sid": 12, "sentence": "Yes, we obtain faster convergence, but as an epiphenomenon of the better efficiency of our adaptive homeostatic algorithm."}, {"text_id": "BylRLBcBAQ", "sid": 13, "sentence": "However, we agree that this was not clear in this first revision: atoms which were displayed looked qualitatively similar."}, {"text_id": "BylRLBcBAQ", "sid": 14, "sentence": "We have solved this issue thanks to the comments of the anonymous reviewers by now displaying the most and least active atoms."}, {"text_id": "BylRLBcBAQ", "sid": 15, "sentence": "This shows a clear distinction between different methods and an important result: when $\\ell_2$ normalizing atoms, dictionary learning may converge to a result for which the ratio of activity between the most activated and the least activated is of the order 2."}, {"text_id": "BylRLBcBAQ", "sid": 16, "sentence": "This result is often overlooked in dictionary learning and is a first novel result of the paper."}, {"text_id": "BylRLBcBAQ", "sid": 17, "sentence": "This being said, Figures 1 and 3 now show the clear qualitative advantage of using homeostasis in unsupervised learning."}, {"text_id": "BylRLBcBAQ", "sid": 18, "sentence": "This now certainly allow to understand *why* convergence speed is a good indicator ---not for an advantage on the running speed on a classical CPU--- but rather in showing that this allows a more efficient dictionary learning overall."}, {"text_id": "BylRLBcBAQ", "sid": 19, "sentence": "Concerning the point \" It is not even clear that the final compression of the baselines would not be better."}, {"text_id": "BylRLBcBAQ", "sid": 20, "sentence": "Even if they did show these convincingly, it is not obvious to me that it is valuable.\", we have performed the same experiments on more iterations such that we clearly see that baseline stay separate."}, {"text_id": "BylRLBcBAQ", "sid": 21, "sentence": "Finally on the same point, we have not used at this point any application, such as supervised learning,  as it is out of the scope of this paper. But we thank the reviewer for suggesting it."}, {"text_id": "BylRLBcBAQ", "sid": 22, "sentence": "Second, we had already done the comparison \"against several costs/algorithms (e.g. l_0 with OMP, l_1 with LARS, etc.), and across various N_0/sparsity penalties\" but we had initially omitted to include this supplementary data (that takes the form of a single jupyter notebook which allows to reproduce all results)."}, {"text_id": "BylRLBcBAQ", "sid": 23, "sentence": "We have now included it in an anonymized format."}, {"text_id": "BylRLBcBAQ", "sid": 24, "sentence": "This supplementary material contains code to replicate all figures but also additional experiments to test the effect of the different parameters."}, {"text_id": "BylRLBcBAQ", "sid": 25, "sentence": "In short, we verified that the results we present are valid over a various number of parameters of the network, like the learning rates (figure 2) but also sparsity and the size of the dictionary (see Response To AnonReviewer3 @ https://openreview.net/forum?id=SyMras0cFQ&noteId=BylQtQPHRX )."}, {"text_id": "BylRLBcBAQ", "sid": 26, "sentence": "As in Sandin, 2017 paper we have shown similar results in OMP."}, {"text_id": "BylRLBcBAQ", "sid": 27, "sentence": "We are in the process of extending this framework to other sparse coding algorithms (LARS and lasso_lars) as plugged in from sklearn without any modification (in theory) to these algorithms."}, {"text_id": "BylRLBcBAQ", "sid": 28, "sentence": "Indeed, we should remind that our adaptive homeostasis allows to be implemented by modifying the norm of each atom of the dictionary (as was done in the original work by Olshausen)."}, {"text_id": "BylRLBcBAQ", "sid": 29, "sentence": "We also show in the paper the application to a one-layer convolution network and our preliminary results show that we can extend this to a hierarchical network."}, {"text_id": "BylRLBcBAQ", "sid": 30, "sentence": "I hope that with these clarifications on the form we gave to the paper (without changing the theory behind it), the statement that \" I don't think the authors have demonstrated that their claims on the properties of their algorithms/formulations are generally true.\"  could be re-assessed to allow us to share this work inspired by biology to the ICLR community."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "BylRLBcBAQ", "sid": 0}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "BylRLBcBAQ", "sid": 1}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "BylRLBcBAQ", "sid": 2}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "BylRLBcBAQ", "sid": 3}, {"labels": {"alignments": [2, 3, 4, 5, 6, 7, 8], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BylRLBcBAQ", "sid": 4}, {"labels": {"alignments": [2, 3, 4, 5, 6, 7, 8], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BylRLBcBAQ", "sid": 5}, {"labels": {"alignments": [2, 3, 4, 5, 6, 7, 8], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BylRLBcBAQ", "sid": 6}, {"labels": {"alignments": [2, 3, 4, 5, 6, 7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BylRLBcBAQ", "sid": 7}, {"labels": {"alignments": [2, 3, 4, 5, 6, 7, 8], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "BylRLBcBAQ", "sid": 8}, {"labels": {"alignments": [2, 3, 4, 5, 6, 7, 8], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BylRLBcBAQ", "sid": 9}, {"labels": {"alignments": [2, 3, 4, 5, 6, 7, 8], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BylRLBcBAQ", "sid": 10}, {"labels": {"alignments": [2, 3, 4, 5, 6, 7, 8], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BylRLBcBAQ", "sid": 11}, {"labels": {"alignments": [2, 3, 4, 5, 6, 7, 8], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BylRLBcBAQ", "sid": 12}, {"labels": {"alignments": [2, 3, 4, 5, 6, 7, 8], "responsetype": "concede-criticism", "coarseresponse": "concur"}, "text_id": "BylRLBcBAQ", "sid": 13}, {"labels": {"alignments": [2, 3, 4, 5, 6, 7, 8], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "BylRLBcBAQ", "sid": 14}, {"labels": {"alignments": [2, 3, 4, 5, 6, 7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BylRLBcBAQ", "sid": 15}, {"labels": {"alignments": [2, 3, 4, 5, 6, 7, 8], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BylRLBcBAQ", "sid": 16}, {"labels": {"alignments": [2, 3, 4, 5, 6, 7, 8], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BylRLBcBAQ", "sid": 17}, {"labels": {"alignments": [2, 3, 4, 5, 6, 7, 8], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BylRLBcBAQ", "sid": 18}, {"labels": {"alignments": [2, 3, 4, 5, 6, 7, 8], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "BylRLBcBAQ", "sid": 19}, {"labels": {"alignments": [2, 3, 4, 5, 6, 7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BylRLBcBAQ", "sid": 20}, {"labels": {"alignments": [2, 3, 4, 5, 6, 7, 8], "responsetype": "reject-request_scope_Yes", "coarseresponse": "dispute"}, "text_id": "BylRLBcBAQ", "sid": 21}, {"labels": {"alignments": [9, 10, 11, 12], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BylRLBcBAQ", "sid": 22}, {"labels": {"alignments": [9, 10, 11, 12], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "BylRLBcBAQ", "sid": 23}, {"labels": {"alignments": [9, 10, 11, 12], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "BylRLBcBAQ", "sid": 24}, {"labels": {"alignments": [9, 10, 11, 12], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "BylRLBcBAQ", "sid": 25}, {"labels": {"alignments": [9, 10, 11, 12], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "BylRLBcBAQ", "sid": 26}, {"labels": {"alignments": [9, 10, 11, 12], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "BylRLBcBAQ", "sid": 27}, {"labels": {"alignments": [9, 10, 11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BylRLBcBAQ", "sid": 28}, {"labels": {"alignments": [9, 10, 11, 12], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "BylRLBcBAQ", "sid": 29}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "BylRLBcBAQ", "sid": 30}], "metadata": {"anno": "anno2", "review": "rylvv96opX", "rebuttal": "BylRLBcBAQ", "conference": "ICLR2019", "title": "An adaptive homeostatic algorithm for the unsupervised learning of visual features", "reviewer": "AnonReviewer4", "forum_id": "SyMras0cFQ", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}}