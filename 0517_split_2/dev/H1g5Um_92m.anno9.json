{"review": [{"text_id": "H1g5Um_92m", "sid": 0, "sentence": "This paper addresses a problem that arises in \"universal\" value-function approximation (that is, reinforcement-learning when a current goal is included as part of the input);  when doing experience replay, the experience buffer might have much more representation of some goals than others, and it's important to keep the training appropriately balanced over goals."}, {"text_id": "H1g5Um_92m", "sid": 1, "sentence": "So, the idea is to a kind of importance weighting of the trajectory memory, by doing a density estimation on the goal distribution represented in the memory and then sample them for training in a way that is inversely related to their densities"}, {"text_id": "H1g5Um_92m", "sid": 2, "sentence": "."}, {"text_id": "H1g5Um_92m", "sid": 3, "sentence": "This method results in a moderate improvement in the effectiveness of DDPG, compared to the previous method for hindsight experience replay."}, {"text_id": "H1g5Um_92m", "sid": 4, "sentence": "The idea is intuitively sensible, but I believe this paper falls short of being ready for publication for three major reasons."}, {"text_id": "H1g5Um_92m", "sid": 5, "sentence": "First, the mechanism provided has no mathematical justification--it seems fairly arbitrary."}, {"text_id": "H1g5Um_92m", "sid": 6, "sentence": "Even if it's not possible to prove something about this strategy, it would be useful to just state a desirable property that the sampling mechanism should have and then argue informally that this mechanism has that property."}, {"text_id": "H1g5Um_92m", "sid": 7, "sentence": "As it is, it's just one point in a large space of possible mechanisms."}, {"text_id": "H1g5Um_92m", "sid": 8, "sentence": "I have a substantial concern that this method might end up assigning a high likelihood of resampling trajectories where something unusual happened, not because of the agent's actions, but because of the world having made a very unusual stochastic transition."}, {"text_id": "H1g5Um_92m", "sid": 9, "sentence": "If that's true, then this distribution would be very bad for training a value function, which is supposed to involve an expectation over \"nature\"'s choices in the MDP."}, {"text_id": "H1g5Um_92m", "sid": 10, "sentence": "Second, the experiments are (as I understand it, but I may be wrong) in deterministic domains, which definitely does not constitute a general test of a proposed RL  method."}, {"text_id": "H1g5Um_92m", "sid": 11, "sentence": "- I'm not sure we can conclude much from the results on fetchSlide (and it would make sense not to use the last set of parameters but the best one encountered during training)"}, {"text_id": "H1g5Um_92m", "sid": 12, "sentence": "- What implementation of the other algorithms did you use?"}, {"text_id": "H1g5Um_92m", "sid": 13, "sentence": "Third, the writing in the paper has some significant lapses in clarity."}, {"text_id": "H1g5Um_92m", "sid": 14, "sentence": "I was a substantial way through the paper before understanding exactly what the set-up was;  in particular, exactly what \"state\" meant was not clear."}, {"text_id": "H1g5Um_92m", "sid": 15, "sentence": "I would suggest saying something like s = ((x^g, x^c), g) where s is a state from the perspective of value iteration, (x^g, x^c) is a state of the system, which is a vector of values divided into two sub-vectors, x^g is the part of the system state that involves the state variables that are specified in the goal, x^c (for 'context')"}, {"text_id": "H1g5Um_92m", "sid": 16, "sentence": "is the rest of the system state, and g is the goal."}, {"text_id": "H1g5Um_92m", "sid": 17, "sentence": "The dimensions of x^g and g should line up."}, {"text_id": "H1g5Um_92m", "sid": 18, "sentence": "- This sentence  was particularly troublesome:  \"Each  state s_t also includes the state of the achieved goal, meaning the goal state is a subset of the normal state."}, {"text_id": "H1g5Um_92m", "sid": 19, "sentence": "Here, we overwrite the notation s_t  as the achieved goal state, i.e., the state of the object.\""}, {"text_id": "H1g5Um_92m", "sid": 20, "sentence": "- Also, it's important to say what the goal actually is, since it doesn't make sense for it to be a point in a continuous space."}, {"text_id": "H1g5Um_92m", "sid": 21, "sentence": "(You do say this later, but it would be helpful to the reader to say it earlier.)"}], "reviewlabels": [{"text_id": "H1g5Um_92m", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1g5Um_92m", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "H1g5Um_92m", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "H1g5Um_92m", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1g5Um_92m", "sid": 4, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Motivation/Impact", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1g5Um_92m", "sid": 5, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1g5Um_92m", "sid": 6, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1g5Um_92m", "sid": 7, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1g5Um_92m", "sid": 8, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1g5Um_92m", "sid": 9, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1g5Um_92m", "sid": 10, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1g5Um_92m", "sid": 11, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1g5Um_92m", "sid": 12, "labels": {"coarse": "Request", "fine": "Request.Clarification", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1g5Um_92m", "sid": 13, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1g5Um_92m", "sid": 14, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1g5Um_92m", "sid": 15, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Clarity", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "H1g5Um_92m", "sid": 16, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Clarity", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "H1g5Um_92m", "sid": 17, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Clarity", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "H1g5Um_92m", "sid": 18, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "H1g5Um_92m", "sid": 19, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "H1g5Um_92m", "sid": 20, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "H1g5Um_92m", "sid": 21, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}], "rebuttal": [{"text_id": "Byl5tiR3pX", "sid": 0, "sentence": "Thank you for the valuable feedback!"}, {"text_id": "Byl5tiR3pX", "sid": 1, "sentence": "We uploaded a revised version of the paper based on the comments."}, {"text_id": "Byl5tiR3pX", "sid": 2, "sentence": "- We added a mathematical justification paragraph in Section 3.3 \u201cAn Importance Sampling Perspective\u201d."}, {"text_id": "Byl5tiR3pX", "sid": 3, "sentence": "We argue that to estimate the integral of the loss function L(\u03c4) of the RL agent efficiently, we need to draw samples \u03c4 from the buffer in regions which have a high probability, p(\u03c4), but also where L|(\u03c4)| is large."}, {"text_id": "Byl5tiR3pX", "sid": 4, "sentence": "Since, p(\u03c4) is a uniform distribution, i.e., the agent replays trajectories at random, we only need to draw samples which has large errors L|(\u03c4)|."}, {"text_id": "Byl5tiR3pX", "sid": 5, "sentence": "The result can be highly efficient, meaning the agent needs less samples than sampling from the uniform distribution p(\u03c4)."}, {"text_id": "Byl5tiR3pX", "sid": 6, "sentence": "The CDP framework finds the samples that have large errors based on the \u2018surprise\u2019 of the trajectory."}, {"text_id": "Byl5tiR3pX", "sid": 7, "sentence": "Any density estimation method that can approximate the trajectory density can provide a more efficient proposal distribution q(\u03c4) than the uniform distribution p(\u03c4)."}, {"text_id": "Byl5tiR3pX", "sid": 8, "sentence": "The sampling mechanism should have a property of oversampling trajectories with larger errors/\u2018surprise\u2019."}, {"text_id": "Byl5tiR3pX", "sid": 9, "sentence": "- To mitigate the influence of very unusual stochastic transitions, we use the ranking instead of the density directly."}, {"text_id": "Byl5tiR3pX", "sid": 10, "sentence": "The reason is that the rank-based variant is more robust because it is not affected by outliers nor by density magnitudes."}, {"text_id": "Byl5tiR3pX", "sid": 11, "sentence": "Furthermore, its heavy-tail property also guarantees that samples will be diverse"}, {"text_id": "Byl5tiR3pX", "sid": 12, "sentence": "(Schaul et al., 2015b)."}, {"text_id": "Byl5tiR3pX", "sid": 13, "sentence": "- Yes, the experiments are mostly in deterministic domains."}, {"text_id": "Byl5tiR3pX", "sid": 14, "sentence": "- In the FetchSlide environment, the best-learned policy of CDP outperforms the baselines and PER, as shown in Table 1."}, {"text_id": "Byl5tiR3pX", "sid": 15, "sentence": "Yes, we did not use the last set of parameters but used the best one encountered during training, as described in Section 4 \u201cExperiments\u201d: \u201cAfter training, we use the best-learned policy as the final policy and test it in the environment."}, {"text_id": "Byl5tiR3pX", "sid": 16, "sentence": "The testing results are the final mean success rates.\u201c"}, {"text_id": "Byl5tiR3pX", "sid": 17, "sentence": "- Our implementation is based on \u201cOpenAI Baselines\u201d, which provides HER. We combined HER with PER in \u201cOpenAI Baselines\u201d."}, {"text_id": "Byl5tiR3pX", "sid": 18, "sentence": "OpenAI Baselines link: https://github.com/openai/baselines"}, {"text_id": "Byl5tiR3pX", "sid": 19, "sentence": "- To improve the clarity of the paper, we move the exact set-up into the earlier section, Section 2.1 \u201cEnvironments\u201d."}, {"text_id": "Byl5tiR3pX", "sid": 20, "sentence": "In this section, we also redefine the \u201cstate\u201d based on your suggestions."}, {"text_id": "Byl5tiR3pX", "sid": 21, "sentence": "We delete the \u201ctroublesome\u201d sentence and also clarify what the goal actually is in Section 2.1."}, {"text_id": "Byl5tiR3pX", "sid": 22, "sentence": "For more detail, please read the revised paper, Section 2.1."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "Byl5tiR3pX", "sid": 0}, {"labels": {"alignments": [], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "Byl5tiR3pX", "sid": 1}, {"labels": {"alignments": [5, 6, 7], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "Byl5tiR3pX", "sid": 2}, {"labels": {"alignments": [5, 6, 7, 8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Byl5tiR3pX", "sid": 3}, {"labels": {"alignments": [5, 6, 7, 8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Byl5tiR3pX", "sid": 4}, {"labels": {"alignments": [5, 6, 7, 8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Byl5tiR3pX", "sid": 5}, {"labels": {"alignments": [5, 6, 7, 8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Byl5tiR3pX", "sid": 6}, {"labels": {"alignments": [5, 6, 7, 8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Byl5tiR3pX", "sid": 7}, {"labels": {"alignments": [5, 6, 7, 8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Byl5tiR3pX", "sid": 8}, {"labels": {"alignments": [8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Byl5tiR3pX", "sid": 9}, {"labels": {"alignments": [8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Byl5tiR3pX", "sid": 10}, {"labels": {"alignments": [8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Byl5tiR3pX", "sid": 11}, {"labels": {"alignments": [8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Byl5tiR3pX", "sid": 12}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Byl5tiR3pX", "sid": 13}, {"labels": {"alignments": [11], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Byl5tiR3pX", "sid": 14}, {"labels": {"alignments": [11], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Byl5tiR3pX", "sid": 15}, {"labels": {"alignments": [11], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Byl5tiR3pX", "sid": 16}, {"labels": {"alignments": [12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Byl5tiR3pX", "sid": 17}, {"labels": {"alignments": [12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Byl5tiR3pX", "sid": 18}, {"labels": {"alignments": [13, 14], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "Byl5tiR3pX", "sid": 19}, {"labels": {"alignments": [13, 14, 15, 16, 17], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "Byl5tiR3pX", "sid": 20}, {"labels": {"alignments": [18, 19], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "Byl5tiR3pX", "sid": 21}, {"labels": {"alignments": [18, 19, 20], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "Byl5tiR3pX", "sid": 22}], "metadata": {"anno": "anno9", "review": "H1g5Um_92m", "rebuttal": "Byl5tiR3pX", "conference": "ICLR2019", "title": "Curiosity-Driven Experience Prioritization via Density Estimation", "reviewer": "AnonReviewer1", "forum_id": "SklXvs0qt7", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}}