{"review": [{"text_id": "HJgQNGqJ9r", "sid": 0, "sentence": "Paper Contributions"}, {"text_id": "HJgQNGqJ9r", "sid": 1, "sentence": "This paper introduces a new text generation scoring approach using BERT, called BERTScore."}, {"text_id": "HJgQNGqJ9r", "sid": 2, "sentence": "Using BERT embeddings and optionally idf scores, a greedy matching is performed between all reference and candidate words, with cosine similarity between vector representations as the scoring."}, {"text_id": "HJgQNGqJ9r", "sid": 3, "sentence": "From this, a precision, recall and F1 score can be derived."}, {"text_id": "HJgQNGqJ9r", "sid": 4, "sentence": "This notably outperforms BLEU, as well as other metrics, most but not all of the time."}, {"text_id": "HJgQNGqJ9r", "sid": 5, "sentence": "The paper offers a broad range of comparisons and analysis."}, {"text_id": "HJgQNGqJ9r", "sid": 6, "sentence": "Decision"}, {"text_id": "HJgQNGqJ9r", "sid": 7, "sentence": "I'm leaning towards accepting the paper on the basis of the following."}, {"text_id": "HJgQNGqJ9r", "sid": 8, "sentence": "Strong points taken in consideration:"}, {"text_id": "HJgQNGqJ9r", "sid": 9, "sentence": "- Simple, well-motivated metric that uses powerful BERT-style models, without being slow to compute either."}, {"text_id": "HJgQNGqJ9r", "sid": 10, "sentence": "- Good performance empirically on WMT. I'm less convinced on COCO since using the image is fair game there."}, {"text_id": "HJgQNGqJ9r", "sid": 11, "sentence": "- Code is provided, and it is simple and adaptable for future work."}, {"text_id": "HJgQNGqJ9r", "sid": 12, "sentence": "- Experimentation is detailed and reproducible."}, {"text_id": "HJgQNGqJ9r", "sid": 13, "sentence": "Weaker points taken in consideration:"}, {"text_id": "HJgQNGqJ9r", "sid": 14, "sentence": "- Work conducted in parallel matches or exceeds the performance of BERTScore."}, {"text_id": "HJgQNGqJ9r", "sid": 15, "sentence": "This shouldn't necessarily be a reason to choose not to publish this work in my opinion, but it should be taken into consideration."}, {"text_id": "HJgQNGqJ9r", "sid": 16, "sentence": "I like that the authors were open and clear regarding this in their discussion."}, {"text_id": "HJgQNGqJ9r", "sid": 17, "sentence": "- The authors haven't come up with a recommendation for a single configuration of their approach."}, {"text_id": "HJgQNGqJ9r", "sid": 18, "sentence": "In one place they recommend F-BERT without idf, in another they argue for picking and choosing based on context, with little help about how to choose."}, {"text_id": "HJgQNGqJ9r", "sid": 19, "sentence": "I think practitioners are only going to be willing to switch away from BLEU, for example, if a single one-size-fits-all metric is proposed instead."}, {"text_id": "HJgQNGqJ9r", "sid": 20, "sentence": "I identify this ambiguity between BERTScore versions as an important weakness of the paper."}, {"text_id": "HJgQNGqJ9r", "sid": 21, "sentence": "- It's unclear throughout whether words or wordpieces are the main token being considered."}, {"text_id": "HJgQNGqJ9r", "sid": 22, "sentence": "Most discussion and definitions use \"words\", but in section 3, subsection Token Representation, it appears to be clearly stated that BERTScore uses a BERT model based on word pieces."}, {"text_id": "HJgQNGqJ9r", "sid": 23, "sentence": "I recommend adjust the language to be more consistent throughout."}, {"text_id": "HJgQNGqJ9r", "sid": 24, "sentence": "Also, scoring examples with word pieces would be more consistent with this as well, imo."}, {"text_id": "HJgQNGqJ9r", "sid": 25, "sentence": "Notably, I'm actually unsure whether you compute IDF over words or word pieces, and how this is applied."}, {"text_id": "HJgQNGqJ9r", "sid": 26, "sentence": "- Finally, I found some weaknesses in the Importance Weighting section (though this isn't too important since IDF isn't part of the recommended BERTScore I believe)."}, {"text_id": "HJgQNGqJ9r", "sid": 27, "sentence": "The IDF scores would be stronger if they were computed on a bigger in-domain corpus than the gold test set."}, {"text_id": "HJgQNGqJ9r", "sid": 28, "sentence": "This would add extra steps to using BERTScore though and make things more complicated in practice, but this should nevertheless probably be tried, or at least discussed in the paper."}, {"text_id": "HJgQNGqJ9r", "sid": 29, "sentence": "Also, the plus-one smoothing handles unknown words (or word piece?) and I'm not sure why. If we're using the test set to compute IDF, and the sentences we're looking *are* in the test set, then there shouldn't be unknown words and no smoothing is required."}, {"text_id": "HJgQNGqJ9r", "sid": 30, "sentence": "So overall, I still think this deserves publication because it's valuable information for researchers, and the metric itself could be immediately useful to some as well."}, {"text_id": "HJgQNGqJ9r", "sid": 31, "sentence": "However, the weaknesses mentioned make me hesitate to fully endorse the work."}], "reviewlabels": [{"text_id": "HJgQNGqJ9r", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQNGqJ9r", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQNGqJ9r", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQNGqJ9r", "sid": 3, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQNGqJ9r", "sid": 4, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQNGqJ9r", "sid": 5, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Meaningful Comparison", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQNGqJ9r", "sid": 6, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQNGqJ9r", "sid": 7, "labels": {"coarse": "Social", "fine": "Social", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQNGqJ9r", "sid": 8, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQNGqJ9r", "sid": 9, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Motivation/Impact", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQNGqJ9r", "sid": 10, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQNGqJ9r", "sid": 11, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Replicability", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQNGqJ9r", "sid": 12, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQNGqJ9r", "sid": 13, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQNGqJ9r", "sid": 14, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "HJgQNGqJ9r", "sid": 15, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "HJgQNGqJ9r", "sid": 16, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQNGqJ9r", "sid": 17, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "HJgQNGqJ9r", "sid": 18, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "HJgQNGqJ9r", "sid": 19, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQNGqJ9r", "sid": 20, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQNGqJ9r", "sid": 21, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "HJgQNGqJ9r", "sid": 22, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "HJgQNGqJ9r", "sid": 23, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "HJgQNGqJ9r", "sid": 24, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "HJgQNGqJ9r", "sid": 25, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQNGqJ9r", "sid": 26, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQNGqJ9r", "sid": 27, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Replicability", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "HJgQNGqJ9r", "sid": 28, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Replicability", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "HJgQNGqJ9r", "sid": 29, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQNGqJ9r", "sid": 30, "labels": {"coarse": "Social", "fine": "Social", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQNGqJ9r", "sid": 31, "labels": {"coarse": "Social", "fine": "Social", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "HyxKnrzGsS", "sid": 0, "sentence": "Thank you for your comments!"}, {"text_id": "HyxKnrzGsS", "sid": 1, "sentence": "We agree with R3 that it would be ideal to have a one-size-fits-all metric."}, {"text_id": "HyxKnrzGsS", "sid": 2, "sentence": "Unfortunately, the complex landscape of the problem doesn\u2019t permit a single recommendation."}, {"text_id": "HyxKnrzGsS", "sid": 3, "sentence": "We did our best to conduct a detailed and honest study."}, {"text_id": "HyxKnrzGsS", "sid": 4, "sentence": "We believe our experiments to be some of the most extensive in this area, and we hope they will contribute to researchers\u2019 understanding of the problem."}, {"text_id": "HyxKnrzGsS", "sid": 5, "sentence": "It\u2019s important to note, though, that BERTScore is an improvement over the commonly used Bleu across the board."}, {"text_id": "HyxKnrzGsS", "sid": 6, "sentence": "Our recommendation to use F1, while potentially not optimal in specific cases, generally performs very well and much better than Bleu."}, {"text_id": "HyxKnrzGsS", "sid": 7, "sentence": "There are largely two sets of options, (1) Among P, R, F; and  (2) What model to use."}, {"text_id": "HyxKnrzGsS", "sid": 8, "sentence": "For (1), as we specify, F-BERT is a reliable metric for MT."}, {"text_id": "HyxKnrzGsS", "sid": 9, "sentence": "For (2), Roberta-Large performs consistently well for to-English language pairs."}, {"text_id": "HyxKnrzGsS", "sid": 10, "sentence": "The results are less conclusive for from-English language pairs."}, {"text_id": "HyxKnrzGsS", "sid": 11, "sentence": "BERTScore computed with Multilingual-BERT is better than most existing metrics except on few low-resource languages."}, {"text_id": "HyxKnrzGsS", "sid": 12, "sentence": "We have updated the paper with these recommendations in Section 7."}, {"text_id": "HyxKnrzGsS", "sid": 13, "sentence": "We are using word pieces in all experiments, and we compute IDF using word pieces."}, {"text_id": "HyxKnrzGsS", "sid": 14, "sentence": "We updated the paper to make this clear in Section 3, under Importance Weighting."}, {"text_id": "HyxKnrzGsS", "sid": 15, "sentence": "Regarding unknown words handling, we computed the IDF on the reference sentences in the test set."}, {"text_id": "HyxKnrzGsS", "sid": 16, "sentence": "This ensures that the IDF is the same for all MT systems that are tested."}, {"text_id": "HyxKnrzGsS", "sid": 17, "sentence": "The candidate sentences generated by MT systems may contain words that never appear in the test set."}, {"text_id": "HyxKnrzGsS", "sid": 18, "sentence": "We apply plus-one smoothing to handle such words."}, {"text_id": "HyxKnrzGsS", "sid": 19, "sentence": "Following your suggestion, we further studied idf scoring."}, {"text_id": "HyxKnrzGsS", "sid": 20, "sentence": "We computed idf scores on the monolingual English corpus released by WMT18 and experimented with BERTScore computed with the Roberta-large model."}, {"text_id": "HyxKnrzGsS", "sid": 21, "sentence": "We have found that this leads to worse performance, likely because of the domain shift."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "HyxKnrzGsS", "sid": 0}, {"labels": {"alignments": [19], "responsetype": "concede-criticism", "coarseresponse": "concur"}, "text_id": "HyxKnrzGsS", "sid": 1}, {"labels": {"alignments": [19], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HyxKnrzGsS", "sid": 2}, {"labels": {"alignments": [19], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HyxKnrzGsS", "sid": 3}, {"labels": {"alignments": [19], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HyxKnrzGsS", "sid": 4}, {"labels": {"alignments": [19, 20], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "HyxKnrzGsS", "sid": 5}, {"labels": {"alignments": [19, 20], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "HyxKnrzGsS", "sid": 6}, {"labels": {"alignments": [19, 20], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HyxKnrzGsS", "sid": 7}, {"labels": {"alignments": [19, 20], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HyxKnrzGsS", "sid": 8}, {"labels": {"alignments": [19, 20], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HyxKnrzGsS", "sid": 9}, {"labels": {"alignments": [19, 20], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HyxKnrzGsS", "sid": 10}, {"labels": {"alignments": [17, 18, 19, 20], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HyxKnrzGsS", "sid": 11}, {"labels": {"alignments": [17, 18, 19, 20], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "HyxKnrzGsS", "sid": 12}, {"labels": {"alignments": [21, 22, 23, 24, 25], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HyxKnrzGsS", "sid": 13}, {"labels": {"alignments": [21, 22, 23, 24, 25], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "HyxKnrzGsS", "sid": 14}, {"labels": {"alignments": [21, 22, 23, 24, 25], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HyxKnrzGsS", "sid": 15}, {"labels": {"alignments": [21, 22, 23, 24, 25], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HyxKnrzGsS", "sid": 16}, {"labels": {"alignments": [26, 27, 28, 29], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HyxKnrzGsS", "sid": 17}, {"labels": {"alignments": [26, 27, 28, 29], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HyxKnrzGsS", "sid": 18}, {"labels": {"alignments": [26, 27, 28, 29], "responsetype": "done_manu_No", "coarseresponse": "concur"}, "text_id": "HyxKnrzGsS", "sid": 19}, {"labels": {"alignments": [26, 27, 28, 29], "responsetype": "done_manu_No", "coarseresponse": "concur"}, "text_id": "HyxKnrzGsS", "sid": 20}, {"labels": {"alignments": [26, 27, 28, 29], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HyxKnrzGsS", "sid": 21}], "metadata": {"anno": "anno3", "review": "HJgQNGqJ9r", "rebuttal": "HyxKnrzGsS", "conference": "ICLR2020", "title": "BERTScore: Evaluating Text Generation with BERT", "reviewer": "AnonReviewer3", "forum_id": "SkeHuCVFDr", "rating": "6: Weak Accept", "experience_assessment": "I have published one or two papers in this area."}}