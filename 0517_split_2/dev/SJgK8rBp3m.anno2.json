{"review": [{"text_id": "SJgK8rBp3m", "sid": 0, "sentence": "This paper proves a theoretical limitation of narrow-and-deep neural networks."}, {"text_id": "SJgK8rBp3m", "sid": 1, "sentence": "It shows that, for any function that can be approximated by such networks, its level set (or decision boundary for binary classification) must be unbounded."}, {"text_id": "SJgK8rBp3m", "sid": 2, "sentence": "The conclusion means that if some problem's decision boundary is a closed set, then it cannot be represented by such narrow networks."}, {"text_id": "SJgK8rBp3m", "sid": 3, "sentence": "The intuition is relatively simple."}, {"text_id": "SJgK8rBp3m", "sid": 4, "sentence": "Under the assumptions of the paper, the neural network can always be approximated by a one-to-one mapping followed by a linear projection."}, {"text_id": "SJgK8rBp3m", "sid": 5, "sentence": "The image of the one-to-one mapping is homeomorphic to R^n, so that it must be an open topological ball."}, {"text_id": "SJgK8rBp3m", "sid": 6, "sentence": "The intersection of this open ball with a linear hyperplane must include the boundary of the ball, thus it extends to infinity in the original input space."}, {"text_id": "SJgK8rBp3m", "sid": 7, "sentence": "The critical assumptions here, which guarantees the one-to-one property of the network, are: 1) the network is narrow, and 2) the activation function can be approximated by a one-to-one function."}, {"text_id": "SJgK8rBp3m", "sid": 8, "sentence": "The authors claim that 2) captures a large family of activation functions."}, {"text_id": "SJgK8rBp3m", "sid": 9, "sentence": "However, it does exclude some popular activation families, such as the polynomial activation, which were proven effective in multiple areas."}, {"text_id": "SJgK8rBp3m", "sid": 10, "sentence": "As a concrete example, the simple function f(x1,x2) = x_1^2 + x_2^2 has bounded level sets, but it can be represented by a narrow 2-layer neural network with the quadratic activation."}, {"text_id": "SJgK8rBp3m", "sid": 11, "sentence": "Overall, I feel that the result is interesting but it depends on a strong assumption and doesn't capture all interesting cases."}, {"text_id": "SJgK8rBp3m", "sid": 12, "sentence": "It is also not clear how this theoretical result can shed insight on the empirical study of neural networks."}], "reviewlabels": [{"text_id": "SJgK8rBp3m", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJgK8rBp3m", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJgK8rBp3m", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJgK8rBp3m", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJgK8rBp3m", "sid": 4, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJgK8rBp3m", "sid": 5, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJgK8rBp3m", "sid": 6, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJgK8rBp3m", "sid": 7, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJgK8rBp3m", "sid": 8, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJgK8rBp3m", "sid": 9, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJgK8rBp3m", "sid": 10, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJgK8rBp3m", "sid": 11, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJgK8rBp3m", "sid": 12, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "r1x5UuwvJE", "sid": 0, "sentence": "It's true that there are many activation functions that the result doesn't apply to, and in fact isn't true for."}, {"text_id": "r1x5UuwvJE", "sid": 1, "sentence": "The selling point isn't the generality of the result, but rather the novelty of the approach and the potential it suggests for future work that would be more general."}], "rebuttallabels": [{"labels": {"alignments": [8, 9, 11], "responsetype": "concede-criticism", "coarseresponse": "concur"}, "text_id": "r1x5UuwvJE", "sid": 0}, {"labels": {"alignments": [8, 9, 11], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "r1x5UuwvJE", "sid": 1}], "metadata": {"anno": "anno2", "review": "SJgK8rBp3m", "rebuttal": "r1x5UuwvJE", "conference": "ICLR2019", "title": "Deep, Skinny Neural Networks are not Universal Approximators", "reviewer": "AnonReviewer3", "forum_id": "ryGgSsAcFQ", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}}