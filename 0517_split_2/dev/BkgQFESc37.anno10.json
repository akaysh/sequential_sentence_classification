{"review": [{"text_id": "BkgQFESc37", "sid": 0, "sentence": "The paper presents a novel hierarchical clustering method over an embedding space."}, {"text_id": "BkgQFESc37", "sid": 1, "sentence": "In the presented approach, both the embedding space and the hierarchical clustering are simultaneously learnt."}, {"text_id": "BkgQFESc37", "sid": 2, "sentence": "The hierarchical clustering algorithm aims to recover complex clustering hierarchies which cannot be captured by previously proposed methods."}, {"text_id": "BkgQFESc37", "sid": 3, "sentence": "The paper address a relevant problem, which is of great interest for extracting knowledge from data."}, {"text_id": "BkgQFESc37", "sid": 4, "sentence": "In general, the quality of the paper is high."}, {"text_id": "BkgQFESc37", "sid": 5, "sentence": "The presented approach is based on a sound formalization of hierarchical clustering and deep generative models."}, {"text_id": "BkgQFESc37", "sid": 6, "sentence": "The paper is easy to follow in spite of the technical difficulty."}, {"text_id": "BkgQFESc37", "sid": 7, "sentence": "The experimental evaluation is really extensive."}, {"text_id": "BkgQFESc37", "sid": 8, "sentence": "It compares against many state-of-the-art methods. And the results are promising from both a quantitative and qualitative point view."}, {"text_id": "BkgQFESc37", "sid": 9, "sentence": "The only issue with this paper is its degree of novelty, which is narrow."}, {"text_id": "BkgQFESc37", "sid": 10, "sentence": "The proposed method adapt a previously presented hierarchical clustering method in the \"standard space\" (Griffiths et al., 2004) to an embedding space defined by a variational autoencoder model."}, {"text_id": "BkgQFESc37", "sid": 11, "sentence": "The inference algorithm builds on standard techniques of deep generative models and, also, on previously proposed methods (Wand and Blei, 2003) for dealing with the complex hierarchical priors involved in this kind of models."}], "reviewlabels": [{"text_id": "BkgQFESc37", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgQFESc37", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgQFESc37", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgQFESc37", "sid": 3, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Motivation/Impact", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgQFESc37", "sid": 4, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Other", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgQFESc37", "sid": 5, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgQFESc37", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgQFESc37", "sid": 7, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgQFESc37", "sid": 8, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgQFESc37", "sid": 9, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgQFESc37", "sid": 10, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgQFESc37", "sid": 11, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "HJgnkeMd67", "sid": 0, "sentence": "[Q] The paper presents a novel hierarchical clustering method over an embedding space."}, {"text_id": "HJgnkeMd67", "sid": 1, "sentence": "In the presented approach, both the embedding space and the hierarchical clustering are simultaneously learned."}, {"text_id": "HJgnkeMd67", "sid": 2, "sentence": "The hierarchical clustering algorithm aims to recover complex clustering hierarchies which cannot be captured by previously proposed methods."}, {"text_id": "HJgnkeMd67", "sid": 3, "sentence": "[A1] Dear Reviewer 1, thank you for the thoughtful review."}, {"text_id": "HJgnkeMd67", "sid": 4, "sentence": "The reviewer mentioned our key point correctly."}, {"text_id": "HJgnkeMd67", "sid": 5, "sentence": "Many works on flat-clustered representation learning except for VAE-nCRP, has been limited to capture flat-level data structure."}, {"text_id": "HJgnkeMd67", "sid": 6, "sentence": "[Q] The paper address a relevant problem, which is of great interest for extracting knowledge from data."}, {"text_id": "HJgnkeMd67", "sid": 7, "sentence": "[A1] There are a lot of high-dimensional data around us, and it obviously contains complex structures inside. What we would like to argue through this study is that we can analyze the complex structure of data in the embedding space learned by a deep neural network."}, {"text_id": "HJgnkeMd67", "sid": 8, "sentence": "[Q] In general, the quality of the paper is high."}, {"text_id": "HJgnkeMd67", "sid": 9, "sentence": "The presented approach is based on a sound formalization of hierarchical clustering and deep generative models."}, {"text_id": "HJgnkeMd67", "sid": 10, "sentence": "The paper is easy to follow in spite of the technical difficulty."}, {"text_id": "HJgnkeMd67", "sid": 11, "sentence": "The experimental evaluation is really extensive."}, {"text_id": "HJgnkeMd67", "sid": 12, "sentence": "It compares against many state-of-the-art methods. And the results are promising from both a quantitative and qualitative point view."}, {"text_id": "HJgnkeMd67", "sid": 13, "sentence": "[A1] Thank you for the comment."}, {"text_id": "HJgnkeMd67", "sid": 14, "sentence": "As we assume a rather complex prior to embedding for flexibility, the technical depth of formalization has deepened."}, {"text_id": "HJgnkeMd67", "sid": 15, "sentence": "We concerned that it would be confused for the readers including the reviewers, to understand."}, {"text_id": "HJgnkeMd67", "sid": 16, "sentence": "Therefore, we carefully presented the figures, especially in Figure 3(a) showing an example of the variable values."}, {"text_id": "HJgnkeMd67", "sid": 17, "sentence": "In the case of experiments, we have devised various quantitative and qualitative experiments to assert why we need this hierarchically clustered representation learning."}, {"text_id": "HJgnkeMd67", "sid": 18, "sentence": "We empirically observed the performance improvement of both density estimation and hierarchical clustering, which motivates the joint optimization."}, {"text_id": "HJgnkeMd67", "sid": 19, "sentence": "Additionally, we qualitatively showed embedding plot, image generation, and result hierarchy with various datasets."}, {"text_id": "HJgnkeMd67", "sid": 20, "sentence": "[Q] The only issue with this paper is its degree of novelty, which is narrow."}, {"text_id": "HJgnkeMd67", "sid": 21, "sentence": "The proposed method adapt a previously presented hierarchical clustering method in the \"standard space\" (Griffiths et al., 2004) to an embedding space defined by a variational autoencoder model."}, {"text_id": "HJgnkeMd67", "sid": 22, "sentence": "The inference algorithm builds on standard techniques of deep generative models and, also, on previously proposed methods (Wand and Blei, 2003) for dealing with the complex hierarchical priors involved in this kind of models."}, {"text_id": "HJgnkeMd67", "sid": 23, "sentence": "[A1] As the reviewer pointed out, we adopted the partial components with the previously proposed techniques or methodologies."}, {"text_id": "HJgnkeMd67", "sid": 24, "sentence": "The theoretical contribution of our study can be considered in conjunction with the unified model based on the fully Bayesian approach of the probabilistic graphical model and the neural network."}, {"text_id": "HJgnkeMd67", "sid": 25, "sentence": "Additionally, we tuned the several detailed heuristic algorithms for operations such as GROW, PRUNE, and MERGE."}, {"text_id": "HJgnkeMd67", "sid": 26, "sentence": "Also, if we take a naive pipelined approach of iterative training between the hierarchical Gaussian mixture model and representation learning, then this work would be an obviously incremental work."}, {"text_id": "HJgnkeMd67", "sid": 27, "sentence": "[A2] VAE imposes a single Gaussian prior on embeddings, which leads to 1) the over-regularization, and 2) poor representations [1,2,5]."}, {"text_id": "HJgnkeMd67", "sid": 28, "sentence": "[1] Chen, Xi, et al. \"Infogan: Interpretable representation learning by information maximizing generative adversarial nets.\" NIPS. 2016."}, {"text_id": "HJgnkeMd67", "sid": 29, "sentence": "[2] Hoffman, Matthew D., and Matthew J. Johnson. \"Elbo surgery: yet another way to carve up the variational evidence lower bound.\" Workshop in Advances in Approximate Bayesian Inference, NIPS. 2016."}, {"text_id": "HJgnkeMd67", "sid": 30, "sentence": "Therefore, the recently published researches can be divided into two branches: 1) designing of an objective function by introducing the additional regularized terms, or 2) constructing of a more flexible prior."}, {"text_id": "HJgnkeMd67", "sid": 31, "sentence": "Our work attempts to the latter approach, which proposes a new prior called a hierarchical-versioned Gaussian mixture distribution prior to the first trial of hierarchical density estimation in the embedding space."}, {"text_id": "HJgnkeMd67", "sid": 32, "sentence": "Another work of the latter approach is:"}, {"text_id": "HJgnkeMd67", "sid": 33, "sentence": "- Variational Deep Embedding (VaDE) [3]: VAE+GMM"}, {"text_id": "HJgnkeMd67", "sid": 34, "sentence": "- VAE-nCRP [4]: VAE+(nCRP+GMM)"}, {"text_id": "HJgnkeMd67", "sid": 35, "sentence": "- VAE with a VampPrior [5]: VAE+ a variational mixture of posteriors prior."}, {"text_id": "HJgnkeMd67", "sid": 36, "sentence": "The contribution of these studies lies on 1) the formalization as a unified model based on the newly proposed prior, though not the original technique proposed by the authors, and 2) demonstrating the superiority of the prior."}, {"text_id": "HJgnkeMd67", "sid": 37, "sentence": "[3] Jiang, Zhuxi, et al. \"Variational deep embedding: an unsupervised and generative approach to clustering.\" IJCAI, 2017."}, {"text_id": "HJgnkeMd67", "sid": 38, "sentence": "[4] Goyal, Prasoon, et al. \"Nonparametric Variational Auto-Encoders for Hierarchical Representation Learning.\" ICCV. 2017."}, {"text_id": "HJgnkeMd67", "sid": 39, "sentence": "[5] Tomczak, Jakub, and Max Welling. \"VAE with a VampPrior.\" AISTATS. 2018."}, {"text_id": "HJgnkeMd67", "sid": 40, "sentence": "Best regards,"}], "rebuttallabels": [{"labels": {"alignments": [0], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "HJgnkeMd67", "sid": 0}, {"labels": {"alignments": [1], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "HJgnkeMd67", "sid": 1}, {"labels": {"alignments": [2], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "HJgnkeMd67", "sid": 2}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "HJgnkeMd67", "sid": 3}, {"labels": {"alignments": [0, 1, 2], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "HJgnkeMd67", "sid": 4}, {"labels": {"alignments": [0, 1, 2], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "HJgnkeMd67", "sid": 5}, {"labels": {"alignments": [3], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "HJgnkeMd67", "sid": 6}, {"labels": {"alignments": [3], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "HJgnkeMd67", "sid": 7}, {"labels": {"alignments": [4], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "HJgnkeMd67", "sid": 8}, {"labels": {"alignments": [5], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "HJgnkeMd67", "sid": 9}, {"labels": {"alignments": [6], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "HJgnkeMd67", "sid": 10}, {"labels": {"alignments": [7], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "HJgnkeMd67", "sid": 11}, {"labels": {"alignments": [8], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "HJgnkeMd67", "sid": 12}, {"labels": {"alignments": [4, 5, 6, 7, 8], "responsetype": "accept-praise", "coarseresponse": "concur"}, "text_id": "HJgnkeMd67", "sid": 13}, {"labels": {"alignments": [4, 5, 6, 7, 8], "responsetype": "accept-praise", "coarseresponse": "concur"}, "text_id": "HJgnkeMd67", "sid": 14}, {"labels": {"alignments": [4, 5, 6, 7, 8], "responsetype": "accept-praise", "coarseresponse": "concur"}, "text_id": "HJgnkeMd67", "sid": 15}, {"labels": {"alignments": [4, 5, 6, 7, 8], "responsetype": "accept-praise", "coarseresponse": "concur"}, "text_id": "HJgnkeMd67", "sid": 16}, {"labels": {"alignments": [4, 5, 6, 7, 8], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "HJgnkeMd67", "sid": 17}, {"labels": {"alignments": [4, 5, 6, 7, 8], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "HJgnkeMd67", "sid": 18}, {"labels": {"alignments": [4, 5, 6, 7, 8], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "HJgnkeMd67", "sid": 19}, {"labels": {"alignments": [9], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "HJgnkeMd67", "sid": 20}, {"labels": {"alignments": [10], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "HJgnkeMd67", "sid": 21}, {"labels": {"alignments": [11], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "HJgnkeMd67", "sid": 22}, {"labels": {"alignments": [9, 10, 11], "responsetype": "concede-criticism", "coarseresponse": "concur"}, "text_id": "HJgnkeMd67", "sid": 23}, {"labels": {"alignments": [9, 10, 11], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "HJgnkeMd67", "sid": 24}, {"labels": {"alignments": [9, 10, 11], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "HJgnkeMd67", "sid": 25}, {"labels": {"alignments": [9, 10, 11], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "HJgnkeMd67", "sid": 26}, {"labels": {"alignments": [9, 10, 11], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "HJgnkeMd67", "sid": 27}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "HJgnkeMd67", "sid": 28}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "HJgnkeMd67", "sid": 29}, {"labels": {"alignments": [9, 10, 11], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "HJgnkeMd67", "sid": 30}, {"labels": {"alignments": [9, 10, 11], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "HJgnkeMd67", "sid": 31}, {"labels": {"alignments": [9, 10, 11], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "HJgnkeMd67", "sid": 32}, {"labels": {"alignments": [9, 10, 11], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "HJgnkeMd67", "sid": 33}, {"labels": {"alignments": [9, 10, 11], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "HJgnkeMd67", "sid": 34}, {"labels": {"alignments": [9, 10, 11], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "HJgnkeMd67", "sid": 35}, {"labels": {"alignments": [9, 10, 11], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "HJgnkeMd67", "sid": 36}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "HJgnkeMd67", "sid": 37}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "HJgnkeMd67", "sid": 38}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "HJgnkeMd67", "sid": 39}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "HJgnkeMd67", "sid": 40}], "metadata": {"anno": "anno10", "review": "BkgQFESc37", "rebuttal": "HJgnkeMd67", "conference": "ICLR2019", "title": "Hierarchically Clustered Representation Learning", "reviewer": "AnonReviewer1", "forum_id": "H1ERcs09KQ", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}}