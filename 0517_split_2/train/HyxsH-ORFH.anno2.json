{"review": [{"text_id": "HyxsH-ORFH", "sid": 0, "sentence": "The paper proposes a way to pre-train quantized representations for speech."}, {"text_id": "HyxsH-ORFH", "sid": 1, "sentence": "The approach proposed is a two-stage process: 1. train a quantized version of wav2vec [my understanding is that wav2vec is the same thing as CPC for Audio except for using a binary cross-entropy loss instead of InfoNCE softmax-cross entropy loss]."}, {"text_id": "HyxsH-ORFH", "sid": 2, "sentence": "the authors propose to use gumbel softmax / VQ codebook for the vector quantization."}, {"text_id": "HyxsH-ORFH", "sid": 3, "sentence": "2. once you have a discrete representation, you could train BERT (as if it were a seq of language tokens)."}, {"text_id": "HyxsH-ORFH", "sid": 4, "sentence": "this makes a lot of sense especially given that CPC / wav2vec recovers phonemes and quantizing the phonemes will recover a language-like version of the raw audio. And running BERT across those tokens will allow you to capture the dependencies at the phoneme level."}, {"text_id": "HyxsH-ORFH", "sid": 5, "sentence": "After pre-training, the authors use the learned representations for speech recognition."}, {"text_id": "HyxsH-ORFH", "sid": 6, "sentence": "They compare this to using log-mel filterbanks."}, {"text_id": "HyxsH-ORFH", "sid": 7, "sentence": "The results (WER / LER) is lower for the proposed pipeline compared to using dense wav2vec representation for n-gram and character LM."}, {"text_id": "HyxsH-ORFH", "sid": 8, "sentence": "It also makes sense that BERT helps for the k-means (vq) setting since the number of codes is large."}, {"text_id": "HyxsH-ORFH", "sid": 9, "sentence": "The authors also cleverly adopt/adapt span-BERT which is more suited to this setting."}, {"text_id": "HyxsH-ORFH", "sid": 10, "sentence": "I think this paper presents a useful contribution as far as improving speech / phoneme recognition using self-supervised learning goes, and also has useful engineering aspects in terms of combining CPC and BERT. I would like to see this paper accepted."}], "reviewlabels": [{"text_id": "HyxsH-ORFH", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxsH-ORFH", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxsH-ORFH", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxsH-ORFH", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxsH-ORFH", "sid": 4, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxsH-ORFH", "sid": 5, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxsH-ORFH", "sid": 6, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxsH-ORFH", "sid": 7, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxsH-ORFH", "sid": 8, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxsH-ORFH", "sid": 9, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxsH-ORFH", "sid": 10, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Motivation/Impact", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "BkxWkgY2sB", "sid": 0, "sentence": "Thank you for your comments!"}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "BkxWkgY2sB", "sid": 0}], "metadata": {"anno": "anno2", "review": "HyxsH-ORFH", "rebuttal": "BkxWkgY2sB", "conference": "ICLR2020", "title": "vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations", "reviewer": "AnonReviewer2", "forum_id": "rylwJxrYDS", "rating": "8: Accept", "experience_assessment": "I have published one or two papers in this area."}}