{"review": [{"text_id": "SJlsCX2CFr", "sid": 0, "sentence": "The authors propose PARCUS (\"Pattern Representations on Continuous Spaces\"), a model which computes a soft-matching probability for all words in an input sequence with so-called prototypes in order to predict a label for the input."}, {"text_id": "SJlsCX2CFr", "sid": 1, "sentence": "Furthermore, for training, PARCUS makes use of rationales."}, {"text_id": "SJlsCX2CFr", "sid": 2, "sentence": "Those are indicators of input importance, and help to boost the loss for relevant tokens."}, {"text_id": "SJlsCX2CFr", "sid": 3, "sentence": "The main motivation to use PARCUS is that it works better in a low-resource setting than recent state-of-the-art models for the high-resource case."}, {"text_id": "SJlsCX2CFr", "sid": 4, "sentence": "This is due to it having relatively few parameters and to it having a strong inductive bias."}, {"text_id": "SJlsCX2CFr", "sid": 5, "sentence": "However, the fact that models with less parameters perform better than BERT-based models in the low-resource case is not very surprising."}, {"text_id": "SJlsCX2CFr", "sid": 6, "sentence": "Looking at the experiments, the results on HATESPEECH show less differences between models than for SPOUSE or MOVIEREVIEW."}, {"text_id": "SJlsCX2CFr", "sid": 7, "sentence": "Another selling point of PARCUS is that it's interpretable. While neural networks can also be analyzed in different ways, I agree with the authors that this is nice to have."}, {"text_id": "SJlsCX2CFr", "sid": 8, "sentence": "Overall, the paper seems solid."}, {"text_id": "SJlsCX2CFr", "sid": 9, "sentence": "=========="}, {"text_id": "SJlsCX2CFr", "sid": 10, "sentence": "Update: After reading the other reviews and the responses by the authors, I lowered my score from 6 to 3."}], "reviewlabels": [{"text_id": "SJlsCX2CFr", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJlsCX2CFr", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJlsCX2CFr", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJlsCX2CFr", "sid": 3, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Motivation/Impact", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJlsCX2CFr", "sid": 4, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Motivation/Impact", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJlsCX2CFr", "sid": 5, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJlsCX2CFr", "sid": 6, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJlsCX2CFr", "sid": 7, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJlsCX2CFr", "sid": 8, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJlsCX2CFr", "sid": 9, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJlsCX2CFr", "sid": 10, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Other", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "S1eEulHdiH", "sid": 0, "sentence": "We thank the reviewer for mentioning the benefits of the proposed model."}, {"text_id": "S1eEulHdiH", "sid": 1, "sentence": "We now clarify some of the reviewer\u2019s doubts:"}, {"text_id": "S1eEulHdiH", "sid": 2, "sentence": "**QUESTION**"}, {"text_id": "S1eEulHdiH", "sid": 3, "sentence": "BERT-based models in the low-resource case is not very surprising"}, {"text_id": "S1eEulHdiH", "sid": 4, "sentence": "**ANSWER**"}, {"text_id": "S1eEulHdiH", "sid": 5, "sentence": "While this result may not look surprising, to the best of our knowledge it was not addressed before for the specific case of BERT."}, {"text_id": "S1eEulHdiH", "sid": 6, "sentence": "In [1], the authors claim that a large pre-trained model can be very helpful in transfer learning scenarios, and they also suggest how to best fine-tune BERT."}, {"text_id": "S1eEulHdiH", "sid": 7, "sentence": "We followed their guidelines and included the results to provide convincing evidence that, in this extreme scenario, our model can perform better (even without the use of rationales)."}, {"text_id": "S1eEulHdiH", "sid": 8, "sentence": "**QUESTION**"}, {"text_id": "S1eEulHdiH", "sid": 9, "sentence": "Looking at the experiments, the results on HATESPEECH show less differences between models than for SPOUSE or MOVIEREVIEW."}, {"text_id": "S1eEulHdiH", "sid": 10, "sentence": "**ANSWER**"}, {"text_id": "S1eEulHdiH", "sid": 11, "sentence": "The reviewer is correct."}, {"text_id": "S1eEulHdiH", "sid": 12, "sentence": "Apart from the reasons mentioned in the paper, it is possible to observe (by manual inspection) that the tweets of the HATESPEECH dataset are very noisy, short and often similar in meaning."}, {"text_id": "S1eEulHdiH", "sid": 13, "sentence": "This clearly helps models based on n-gram features, as we have argued in our work."}, {"text_id": "S1eEulHdiH", "sid": 14, "sentence": "SPOUSE and MOVIEREVIEW are different in this sense."}, {"text_id": "S1eEulHdiH", "sid": 15, "sentence": "SPOUSE, which is where PARCUS performs very well, contains sentences of very different nature and context, which makes it very important to focus on specific concepts (hence the use of prototypes seems appropriate)."}, {"text_id": "S1eEulHdiH", "sid": 16, "sentence": "MOVIEREVIEW, on the other hand, contains very long reviews that need \u201cfiltering\u201d to highlight the important concepts."}, {"text_id": "S1eEulHdiH", "sid": 17, "sentence": "This is another context in which PARCUS can be successfully applied, as training a complex model on few data points that contain \u201clengthy\u201d sentences can be a hard task to solve."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "accept-praise", "coarseresponse": "concur"}, "text_id": "S1eEulHdiH", "sid": 0}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "S1eEulHdiH", "sid": 1}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "S1eEulHdiH", "sid": 2}, {"labels": {"alignments": [5], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "S1eEulHdiH", "sid": 3}, {"labels": {"alignments": [5], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "S1eEulHdiH", "sid": 4}, {"labels": {"alignments": [5], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "S1eEulHdiH", "sid": 5}, {"labels": {"alignments": [5], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "S1eEulHdiH", "sid": 6}, {"labels": {"alignments": [5], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "S1eEulHdiH", "sid": 7}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "S1eEulHdiH", "sid": 8}, {"labels": {"alignments": [6], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "S1eEulHdiH", "sid": 9}, {"labels": {"alignments": [6], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "S1eEulHdiH", "sid": 10}, {"labels": {"alignments": [6], "responsetype": "concede-criticism", "coarseresponse": "concur"}, "text_id": "S1eEulHdiH", "sid": 11}, {"labels": {"alignments": [6], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "S1eEulHdiH", "sid": 12}, {"labels": {"alignments": [6], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "S1eEulHdiH", "sid": 13}, {"labels": {"alignments": [6], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "S1eEulHdiH", "sid": 14}, {"labels": {"alignments": [6], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "S1eEulHdiH", "sid": 15}, {"labels": {"alignments": [6], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "S1eEulHdiH", "sid": 16}, {"labels": {"alignments": [6], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "S1eEulHdiH", "sid": 17}], "metadata": {"anno": "anno13", "review": "SJlsCX2CFr", "rebuttal": "S1eEulHdiH", "conference": "ICLR2020", "title": "Soft Token Matching for Interpretable Low-Resource Classification", "reviewer": "AnonReviewer2", "forum_id": "SJlNnhVYDr", "rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area."}}