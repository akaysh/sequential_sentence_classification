{"review": [{"text_id": "HJxHV7JPjB", "sid": 0, "sentence": "This paper proposes a new method to compare existing classifiers, which does not use fixed test set and adaptively sample it from an arbitrarily large corpus of unlabeled images."}, {"text_id": "HJxHV7JPjB", "sid": 1, "sentence": "The main idea seems similar to adopting active learning for the test set selection."}, {"text_id": "HJxHV7JPjB", "sid": 2, "sentence": "One of the main advantage is that it can select a sample set from an arbitrarily large unlabeled images."}, {"text_id": "HJxHV7JPjB", "sid": 3, "sentence": "However, to compare different classifiers, the proposed algorithm still needs humans to annotate the selected dataset, which is very expensive compared with traditional methods."}, {"text_id": "HJxHV7JPjB", "sid": 4, "sentence": "Since this paper select the top-k images in D, if k is large the annotating for S will be very tedious, however if k is relatively small the method seems very sensitive to selected examples, which will make the comparison not totally convincing."}, {"text_id": "HJxHV7JPjB", "sid": 5, "sentence": "The authors invite five volunteer graduate students to annotate the selected example."}, {"text_id": "HJxHV7JPjB", "sid": 6, "sentence": "However, for many categories, it\u2019s nor easy for normal people to distinguish."}, {"text_id": "HJxHV7JPjB", "sid": 7, "sentence": "So the experiments in this paper is also not convincing."}], "reviewlabels": [{"text_id": "HJxHV7JPjB", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJxHV7JPjB", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJxHV7JPjB", "sid": 2, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJxHV7JPjB", "sid": 3, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJxHV7JPjB", "sid": 4, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJxHV7JPjB", "sid": 5, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJxHV7JPjB", "sid": 6, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJxHV7JPjB", "sid": 7, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "BJgM_eowiS", "sid": 0, "sentence": "With all our due respect to Reviewer #3\u2019s valuable time and effort in reviewing our manuscript, we must admit that we are a bit upset by this last late review, due to the apparent lack of understanding before placing comments, and several factual errors that make the current comments at least poorly grounded."}, {"text_id": "BJgM_eowiS", "sid": 1, "sentence": "We understand that the idea of \u201cmodel falsification as model comparison\u201d might not be trivial to understand for people primarily from practical deep learning backgrounds."}, {"text_id": "BJgM_eowiS", "sid": 2, "sentence": "The idea is deeply rooted in a successful series of studies from image perceptual assessment research: a basic introduction can be found in (Wang & Simoncelli (2008))."}, {"text_id": "BJgM_eowiS", "sid": 3, "sentence": "We notice that Reviewer #2 also kindly points out another interdisciplinary foundation of MAD in software differential testing."}, {"text_id": "BJgM_eowiS", "sid": 4, "sentence": "We hope Reviewer #3 can carefully read the below explanation, and reconsider the rating to a more serious and appropriate one."}, {"text_id": "BJgM_eowiS", "sid": 5, "sentence": "Q1:"}, {"text_id": "BJgM_eowiS", "sid": 6, "sentence": "One of the main advantages is that it can select a sample set from an arbitrarily large unlabeled images."}, {"text_id": "BJgM_eowiS", "sid": 7, "sentence": "However, to compare different classifiers, the proposed algorithm still needs humans to annotate the selected dataset, which is very expensive compared with traditional methods."}, {"text_id": "BJgM_eowiS", "sid": 8, "sentence": "Response:"}, {"text_id": "BJgM_eowiS", "sid": 9, "sentence": "Our method is very efficient in terms of human annotation budget compared with traditional methods, which is one of the main claims we elaborated in our paper."}, {"text_id": "BJgM_eowiS", "sid": 10, "sentence": "We are disappointed that this major important point was not well understood."}, {"text_id": "BJgM_eowiS", "sid": 11, "sentence": "In fact, MAD provides the very first and efficient solution (in the context of image classification) to exploit a large-scale image set under the constraint of the very limited budget for human labeling."}, {"text_id": "BJgM_eowiS", "sid": 12, "sentence": "We have noticed that the other two reviewers agree with us and appreciate this point."}, {"text_id": "BJgM_eowiS", "sid": 13, "sentence": "For example, quote Reviewer #2: \u201cBecause of the efficacy of such \"worst-case\" comparison, the needed set size is very small and thus minimizes the human annotation workload\u201d."}, {"text_id": "BJgM_eowiS", "sid": 14, "sentence": "To evaluate the relative performance of two ImageNet classifiers, traditional evaluation methods compute accuracy on a fixed test set."}, {"text_id": "BJgM_eowiS", "sid": 15, "sentence": "For ImageNet validation set, human annotations for 50,000 images need to be provided."}, {"text_id": "BJgM_eowiS", "sid": 16, "sentence": "This number is large in terms of human labeling effort, but is extremely small compared to the set of all natural images (the natural image manifold)."}, {"text_id": "BJgM_eowiS", "sid": 17, "sentence": "As also mentioned by the reviewer, annotation for each image is a 1000-class classification task, which makes the labeling task more difficult compared to a binary classification problem."}, {"text_id": "BJgM_eowiS", "sid": 18, "sentence": "In contrast, rather than comparing fixed test sets which are typically small, the proposed MAD adaptively samples a test set from an arbitrarily large corpus of unlabeled images so as to maximize the discrepancies between the classifiers, measured by the distance over WordNet hierarchy."}, {"text_id": "BJgM_eowiS", "sid": 19, "sentence": "Human labeling is only required on the resulting small and model-dependent image sets, which contains only k=30 images (for each pair of classifiers) on the ImageNet experiment as reported in our paper."}, {"text_id": "BJgM_eowiS", "sid": 20, "sentence": "Our experiments show that the MAD ranking stabilizes at around k>15 (see figure 5) and successfully tracks the recent progress in image classification ."}, {"text_id": "BJgM_eowiS", "sid": 21, "sentence": "For comparing 11 classifiers, the total labeled images needed are 1,650 (see page 6): it is obviously smaller than 50,000 and leaves much room to compare more classifiers (before it reaches 50, 000)."}, {"text_id": "BJgM_eowiS", "sid": 22, "sentence": "In conclusion, our method is apparently much more efficient in terms of human annotation budget compared with traditional methods."}, {"text_id": "BJgM_eowiS", "sid": 23, "sentence": "In addition, despite the fact that the selected set by MAD is small (as a way of maximizing the efficiency of human labeling), it provides the strongest examples to let classifiers compete with one another."}, {"text_id": "BJgM_eowiS", "sid": 24, "sentence": "Quote Reviewer #2: \u201cThe proposed MAD competition distinguishes classifiers by finding their respective counterexamples. It is therefore an \"error spotting\" mechanism\u201d."}, {"text_id": "BJgM_eowiS", "sid": 25, "sentence": "Their respective strengths, weaknesses as well as biases can be most easily revealed (see figures in the appendix), which sheds light on potential ways to improve the classifiers or combine them into a better one."}, {"text_id": "BJgM_eowiS", "sid": 26, "sentence": "Those gains are way beyond the scope of collecting random image samples."}, {"text_id": "BJgM_eowiS", "sid": 27, "sentence": "Q2: Since this paper select the top-k images in D, if k is large the annotating for S will be very tedious, however if k is relatively small the method seems very sensitive to selected examples, which will make the comparison not totally convincing."}, {"text_id": "BJgM_eowiS", "sid": 28, "sentence": "Response:"}, {"text_id": "BJgM_eowiS", "sid": 29, "sentence": "We agree with the reviewer that k is a critical parameter in MAD."}, {"text_id": "BJgM_eowiS", "sid": 30, "sentence": "We want to however draw the reviewer\u2019s attention to the ablation study and figure 5, if they were accidentally missed in the first reading."}, {"text_id": "BJgM_eowiS", "sid": 31, "sentence": "Based on them, we cannot concur with the statement \u201cif k is relatively small the method seems very sensitive to selected examples\u201d."}, {"text_id": "BJgM_eowiS", "sid": 32, "sentence": "When we apply MAD to compare imageNet classifiers, we find that the MAD ranking stabilizes very quickly when around k>15."}, {"text_id": "BJgM_eowiS", "sid": 33, "sentence": "We would like to also emphasize that despite the small size of labeled images, MAD successfully tracks the steady progress in image classification, as verified by a reasonable Spearman rank-order correlation coefficient (SRCC) of 0.89 between the accuracy rank on ImageNet validation set and the MAD rank on our test set."}, {"text_id": "BJgM_eowiS", "sid": 34, "sentence": "As also pointed out by Review #2, the selected top-k images provide the strongest examples to let classifiers compete with one another."}, {"text_id": "BJgM_eowiS", "sid": 35, "sentence": "Through this process, their respective strengths, weaknesses as well as biases can be most easily revealed (see figures in the appendix)."}, {"text_id": "BJgM_eowiS", "sid": 36, "sentence": "Q3: The authors invite five volunteer graduate students to annotate the selected example."}, {"text_id": "BJgM_eowiS", "sid": 37, "sentence": "However, for many categories, it\u2019s nor easy for normal people to distinguish."}, {"text_id": "BJgM_eowiS", "sid": 38, "sentence": "So the experiments in this paper is also not convincing."}, {"text_id": "BJgM_eowiS", "sid": 39, "sentence": "Response:"}, {"text_id": "BJgM_eowiS", "sid": 40, "sentence": "As veterans in performing subjective studies, we understand and agree with the reviewer that querying ground truth labels for a 200-class classification problem is difficult. That is exactly why we have carefully designed our subjective experiment."}, {"text_id": "BJgM_eowiS", "sid": 41, "sentence": "Given an image x, which is associated with two classifiers f_i and f_j , we pick two binary questions for human annotators: \u201cDoes x contain an f_i(x)?\u201d and \u201cDoes x contain an f_j (x)?\u201d."}, {"text_id": "BJgM_eowiS", "sid": 42, "sentence": "For each question, we follow  the original ImageNet instructions and include the definition of f_i(x) (or f_j(x))  with a link to a corresponding Wikipedia page."}, {"text_id": "BJgM_eowiS", "sid": 43, "sentence": "We also show several example images of f_i(x) (or f_j(x)) sampled from the ImageNet validation set."}, {"text_id": "BJgM_eowiS", "sid": 44, "sentence": "Moreover, if more than three of our five human annotators find difficulty in labeling x, it is discarded and replaced."}, {"text_id": "BJgM_eowiS", "sid": 45, "sentence": "When both answers to the two binary questions are false (corresponding to Case III), we cease to source the ground-truth label of x for reasons mentioned by the reviewer, and treat x as a strong counterexample for both f_i and f_j."}, {"text_id": "BJgM_eowiS", "sid": 46, "sentence": "Based on the above, we cannot concur with the judgement \u201cthe experiments in this paper is (are) also not convincing\u201d."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgM_eowiS", "sid": 0}, {"labels": {"alignments": [], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgM_eowiS", "sid": 1}, {"labels": {"alignments": [], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgM_eowiS", "sid": 2}, {"labels": {"alignments": [], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgM_eowiS", "sid": 3}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "BJgM_eowiS", "sid": 4}, {"labels": {"alignments": [2, 3], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "BJgM_eowiS", "sid": 5}, {"labels": {"alignments": [2, 3], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "BJgM_eowiS", "sid": 6}, {"labels": {"alignments": [2, 3], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "BJgM_eowiS", "sid": 7}, {"labels": {"alignments": [2, 3], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "BJgM_eowiS", "sid": 8}, {"labels": {"alignments": [2, 3], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgM_eowiS", "sid": 9}, {"labels": {"alignments": [2, 3], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgM_eowiS", "sid": 10}, {"labels": {"alignments": [2, 3], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgM_eowiS", "sid": 11}, {"labels": {"alignments": [2, 3], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgM_eowiS", "sid": 12}, {"labels": {"alignments": [2, 3], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgM_eowiS", "sid": 13}, {"labels": {"alignments": [2, 3], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgM_eowiS", "sid": 14}, {"labels": {"alignments": [2, 3], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgM_eowiS", "sid": 15}, {"labels": {"alignments": [2, 3], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgM_eowiS", "sid": 16}, {"labels": {"alignments": [2, 3], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgM_eowiS", "sid": 17}, {"labels": {"alignments": [2, 3], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgM_eowiS", "sid": 18}, {"labels": {"alignments": [2, 3], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgM_eowiS", "sid": 19}, {"labels": {"alignments": [2, 3], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgM_eowiS", "sid": 20}, {"labels": {"alignments": [2, 3], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgM_eowiS", "sid": 21}, {"labels": {"alignments": [2, 3], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgM_eowiS", "sid": 22}, {"labels": {"alignments": [2, 3], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgM_eowiS", "sid": 23}, {"labels": {"alignments": [2, 3], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgM_eowiS", "sid": 24}, {"labels": {"alignments": [2, 3], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgM_eowiS", "sid": 25}, {"labels": {"alignments": [2, 3], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgM_eowiS", "sid": 26}, {"labels": {"alignments": [4], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "BJgM_eowiS", "sid": 27}, {"labels": {"alignments": [4], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "BJgM_eowiS", "sid": 28}, {"labels": {"alignments": [4], "responsetype": "concede-criticism", "coarseresponse": "concur"}, "text_id": "BJgM_eowiS", "sid": 29}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgM_eowiS", "sid": 30}, {"labels": {"alignments": [4], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgM_eowiS", "sid": 31}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgM_eowiS", "sid": 32}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgM_eowiS", "sid": 33}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgM_eowiS", "sid": 34}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgM_eowiS", "sid": 35}, {"labels": {"alignments": [5, 6, 7], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "BJgM_eowiS", "sid": 36}, {"labels": {"alignments": [5, 6, 7], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "BJgM_eowiS", "sid": 37}, {"labels": {"alignments": [5, 6, 7], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "BJgM_eowiS", "sid": 38}, {"labels": {"alignments": [5, 6, 7], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "BJgM_eowiS", "sid": 39}, {"labels": {"alignments": [5, 6, 7], "responsetype": "concede-criticism", "coarseresponse": "concur"}, "text_id": "BJgM_eowiS", "sid": 40}, {"labels": {"alignments": [5, 6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgM_eowiS", "sid": 41}, {"labels": {"alignments": [5, 6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgM_eowiS", "sid": 42}, {"labels": {"alignments": [5, 6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgM_eowiS", "sid": 43}, {"labels": {"alignments": [5, 6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgM_eowiS", "sid": 44}, {"labels": {"alignments": [5, 6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgM_eowiS", "sid": 45}, {"labels": {"alignments": [5, 6, 7], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgM_eowiS", "sid": 46}], "metadata": {"anno": "anno2", "review": "HJxHV7JPjB", "rebuttal": "BJgM_eowiS", "conference": "ICLR2020", "title": "I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively", "reviewer": "AnonReviewer3", "forum_id": "rJehNT4YPr", "rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years."}}