{"review": [{"text_id": "H1l4PVq4KH", "sid": 0, "sentence": "The paper devises a pipeline that aims to address catastrophic forgetting in continual learning (CL) by the well-known generative replay (GR) technique."}, {"text_id": "H1l4PVq4KH", "sid": 1, "sentence": "The key ingredient of the pipeline is a modern variational auto-encoder (VAE) that is trained with class labels with respect to a mutual information maximization criterion."}, {"text_id": "H1l4PVq4KH", "sid": 2, "sentence": "The paper does not follow a smooth story line, where an open research question is presented and a solution to this problem is developed in steps."}, {"text_id": "H1l4PVq4KH", "sid": 3, "sentence": "The flowchart in Fig 1 is rather a system design consisting of many components, the functionality of which is not clearly described and existence of which is not justified."}, {"text_id": "H1l4PVq4KH", "sid": 4, "sentence": "This complex flowchart does not even describe the complete task."}, {"text_id": "H1l4PVq4KH", "sid": 5, "sentence": "It is in the end plugged into a continual learning algorithm which also performs domain transformation."}, {"text_id": "H1l4PVq4KH", "sid": 6, "sentence": "All of these pieces are very well-known methods (e.g. VAEs, conditional VAEs, CL, catastrophic forgetting, domain transformation) in the literature and this paper puts them together in a straightforward way."}, {"text_id": "H1l4PVq4KH", "sid": 7, "sentence": "Hence, I kindly do not think the outcome is truly a research result."}, {"text_id": "H1l4PVq4KH", "sid": 8, "sentence": "It is more system engineering than science."}, {"text_id": "H1l4PVq4KH", "sid": 9, "sentence": "The next submission of the paper could choose one or few of these pieces as target research problems and develop a thoroughly analyzed novel technical solution for them."}, {"text_id": "H1l4PVq4KH", "sid": 10, "sentence": "If this solution can be proven to improve a valuable metric (e.g. accuracy, interpretability, theoretical understanding, or computational efficiency) of a setup, it is then worthwhile being published."}, {"text_id": "H1l4PVq4KH", "sid": 11, "sentence": "Minor: The abstract could be improved by providing more clear pointers to the presented novelty."}], "reviewlabels": [{"text_id": "H1l4PVq4KH", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1l4PVq4KH", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1l4PVq4KH", "sid": 2, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1l4PVq4KH", "sid": 3, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1l4PVq4KH", "sid": 4, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1l4PVq4KH", "sid": 5, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1l4PVq4KH", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1l4PVq4KH", "sid": 7, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1l4PVq4KH", "sid": 8, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1l4PVq4KH", "sid": 9, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1l4PVq4KH", "sid": 10, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1l4PVq4KH", "sid": 11, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "rygR36nHjr", "sid": 0, "sentence": "We appreciate your constructive feedback."}, {"text_id": "rygR36nHjr", "sid": 1, "sentence": "Specifically, your comments about our motivation and development of our idea greatly help us to improve the quality of our paper."}, {"text_id": "rygR36nHjr", "sid": 2, "sentence": "If we correctly understand reviewer 2\u2019s concerns, the concerns can be divided into two folds:"}, {"text_id": "rygR36nHjr", "sid": 3, "sentence": "1. Our suggestion to mitigate the catastrophic forgetting looks a naive combination of well-known concepts. Thus, it is more system engineering than science."}, {"text_id": "rygR36nHjr", "sid": 4, "sentence": "2. Each component described in Figure 1 is not explained enough."}, {"text_id": "rygR36nHjr", "sid": 5, "sentence": "Also, there is no description of the complete task."}, {"text_id": "rygR36nHjr", "sid": 6, "sentence": "[Response for 1]"}, {"text_id": "rygR36nHjr", "sid": 7, "sentence": "As we explained at the common response, we started our research from clear open questions."}, {"text_id": "rygR36nHjr", "sid": 8, "sentence": "Our first open question was that why other GR-based algorithms [1, 2] assume unit Gaussian priors even though they integrate classification loss into their VAE formulation."}, {"text_id": "rygR36nHjr", "sid": 9, "sentence": "Since they do not consider the conflict between the unit Gaussian prior and discriminative loss for the latent variable z, their models generate ambiguous samples that negatively affect the performance of incremental learning, which is discussed in section 4.1 in our paper."}, {"text_id": "rygR36nHjr", "sid": 10, "sentence": "This leads us to a more theoretical formulation for classification-regularized VAE."}, {"text_id": "rygR36nHjr", "sid": 11, "sentence": "By introducing class conditional priors induced by the mutual information maximization, DiVA yields class-wise discriminative one mode Gaussians for latent variable z."}, {"text_id": "rygR36nHjr", "sid": 12, "sentence": "Naturally, DiVA can conduct both class prediction and class conditional sample generation with one integrated model."}, {"text_id": "rygR36nHjr", "sid": 13, "sentence": "The second open question was that why GR-based algorithms suffer from serious catastrophic forgetting in natural image datasets, even though generated samples are not completely noisy."}, {"text_id": "rygR36nHjr", "sid": 14, "sentence": "We assumed that this is due to the vulnerability of neural networks [3] triggered by different distributions of pixel values between real and generated images."}, {"text_id": "rygR36nHjr", "sid": 15, "sentence": "Thus, we defined the two domains: real domain and sample domain."}, {"text_id": "rygR36nHjr", "sid": 16, "sentence": "To narrowing the distribution gap, we needed a solution that satisfies two conditions (also described in section 5):"}, {"text_id": "rygR36nHjr", "sid": 17, "sentence": "1. We should translate only the style (a global pattern of a specific domain) as keeping outline patterns of given images."}, {"text_id": "rygR36nHjr", "sid": 18, "sentence": "2. We should consider an unpaired domain translation between real and generated images because the generated images are sampled randomly."}, {"text_id": "rygR36nHjr", "sid": 19, "sentence": "Fortunately, we were able to find an existing solution that satisfies the requirements: CycleGAN. Any other domain translators that satisfy the conditions can be used or newly studied."}, {"text_id": "rygR36nHjr", "sid": 20, "sentence": "With the solution, we could make a breakthrough for GR-based methods."}, {"text_id": "rygR36nHjr", "sid": 21, "sentence": "To the best of our knowledge, this is the first successful approach for a GR-based algorithm to start to resist the catastrophic forgetting problem with a natural image dataset."}, {"text_id": "rygR36nHjr", "sid": 22, "sentence": "[Response for 2]"}, {"text_id": "rygR36nHjr", "sid": 23, "sentence": "Figure 1 is a conceptual description of our proposed model, DiVA."}, {"text_id": "rygR36nHjr", "sid": 24, "sentence": "Each component is explained in section 4, below Equation 2, and justified in section 4.1."}, {"text_id": "rygR36nHjr", "sid": 25, "sentence": "Also, for an easy understanding of the whole CL process with DiVA, we added another figure in Appendix E."}, {"text_id": "rygR36nHjr", "sid": 26, "sentence": "[References]"}, {"text_id": "rygR36nHjr", "sid": 27, "sentence": "[1] van de Ven, Gido M., and Andreas S. Tolias. \"Generative replay with feedback connections as a general strategy for continual learning.\" arXiv preprint arXiv:1809.10635 (2018)."}, {"text_id": "rygR36nHjr", "sid": 28, "sentence": "[2] Mundt, Martin, et al. \"Unified Probabilistic Deep Continual Learning through Generative Replay and Open Set Recognition.\" arXiv preprint arXiv:1905.12019 (2019)."}, {"text_id": "rygR36nHjr", "sid": 29, "sentence": "[3] Su, Jiawei, Danilo Vasconcellos Vargas, and Kouichi Sakurai. \"One pixel attack for fooling deep neural networks.\" IEEE Transactions on Evolutionary Computation (2019)."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "rygR36nHjr", "sid": 0}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "rygR36nHjr", "sid": 1}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "rygR36nHjr", "sid": 2}, {"labels": {"alignments": [6], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rygR36nHjr", "sid": 3}, {"labels": {"alignments": [3, 4, 5], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rygR36nHjr", "sid": 4}, {"labels": {"alignments": [11], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rygR36nHjr", "sid": 5}, {"labels": {"alignments": [6, 7, 8], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rygR36nHjr", "sid": 6}, {"labels": {"alignments": [6, 7, 8], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "rygR36nHjr", "sid": 7}, {"labels": {"alignments": [6, 7, 8], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "rygR36nHjr", "sid": 8}, {"labels": {"alignments": [6, 7, 8], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "rygR36nHjr", "sid": 9}, {"labels": {"alignments": [6, 7, 8], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "rygR36nHjr", "sid": 10}, {"labels": {"alignments": [6, 7, 8], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "rygR36nHjr", "sid": 11}, {"labels": {"alignments": [6, 7, 8], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "rygR36nHjr", "sid": 12}, {"labels": {"alignments": [6, 7, 8], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "rygR36nHjr", "sid": 13}, {"labels": {"alignments": [6, 7, 8], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "rygR36nHjr", "sid": 14}, {"labels": {"alignments": [6, 7, 8], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "rygR36nHjr", "sid": 15}, {"labels": {"alignments": [6, 7, 8], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "rygR36nHjr", "sid": 16}, {"labels": {"alignments": [6, 7, 8], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "rygR36nHjr", "sid": 17}, {"labels": {"alignments": [6, 7, 8], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "rygR36nHjr", "sid": 18}, {"labels": {"alignments": [6, 7, 8], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "rygR36nHjr", "sid": 19}, {"labels": {"alignments": [6, 7, 8], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "rygR36nHjr", "sid": 20}, {"labels": {"alignments": [6, 7, 8], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "rygR36nHjr", "sid": 21}, {"labels": {"alignments": [3, 4, 5], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rygR36nHjr", "sid": 22}, {"labels": {"alignments": [3, 4, 5], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "rygR36nHjr", "sid": 23}, {"labels": {"alignments": [3, 4, 5], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "rygR36nHjr", "sid": 24}, {"labels": {"alignments": [3, 4, 5], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "rygR36nHjr", "sid": 25}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rygR36nHjr", "sid": 26}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rygR36nHjr", "sid": 27}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rygR36nHjr", "sid": 28}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rygR36nHjr", "sid": 29}], "metadata": {"anno": "anno13", "review": "H1l4PVq4KH", "rebuttal": "rygR36nHjr", "conference": "ICLR2020", "title": "Discriminative Variational Autoencoder for Continual Learning with Generative Replay", "reviewer": "AnonReviewer2", "forum_id": "SJxjPxSYDH", "rating": "1: Reject", "experience_assessment": "I have published one or two papers in this area."}}