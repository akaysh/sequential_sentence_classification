{"review": [{"text_id": "B1ez1LvJcB", "sid": 0, "sentence": "This paper presents a method for adapting a model that has been trained to perform one task, so that it can perform a new task (potentially without using any new training data at all\u2014i.e., zero-shot learning)."}, {"text_id": "B1ez1LvJcB", "sid": 1, "sentence": "In some ways the presented work is a form of meta-learning or *meta-mapping* as the authors refer to it."}, {"text_id": "B1ez1LvJcB", "sid": 2, "sentence": "The premise of the paper is very interesting and the overall problem is definitely of high interest and high potential impact."}, {"text_id": "B1ez1LvJcB", "sid": 3, "sentence": "I believe that the presentation of the proposed method can be significantly improved."}, {"text_id": "B1ez1LvJcB", "sid": 4, "sentence": "The method description was a bit confusing and unclear to me."}, {"text_id": "B1ez1LvJcB", "sid": 5, "sentence": "The experimental results presented were all done on small synthetic datasets and it\u2019s hard to evaluate whether the method is practically useful."}, {"text_id": "B1ez1LvJcB", "sid": 6, "sentence": "Furthermore, no comparisons were provided to any baselines/alternative methods."}, {"text_id": "B1ez1LvJcB", "sid": 7, "sentence": "For example, in Sections 4 and 5 I was hoping to see comparisons to methods like MAML."}, {"text_id": "B1ez1LvJcB", "sid": 8, "sentence": "Also, I felt that the proposed approach in Section 5 is very similar to MAML intuitively. This makes a comparison with MAML even more desirable."}, {"text_id": "B1ez1LvJcB", "sid": 9, "sentence": "Without any comparisons it\u2019s hard to tell how difficult the tasks under consideration are and what would amount to good performance on the held-out tasks."}, {"text_id": "B1ez1LvJcB", "sid": 10, "sentence": "In summary, I feel the paper tackles an interesting problem with an interesting approach, but the content could be organized much better."}, {"text_id": "B1ez1LvJcB", "sid": 11, "sentence": "Also, this work would benefit significantly from a better experimental evaluation."}, {"text_id": "B1ez1LvJcB", "sid": 12, "sentence": "For these reasons I lean towards rejecting this paper for now, but would love to see it refined for a future machine learning conference."}, {"text_id": "B1ez1LvJcB", "sid": 13, "sentence": "Also, the work by Platanios, et al. on contextual parameter generation is very relevant to this work as it tackles multi-task learning using HyperNetworks."}, {"text_id": "B1ez1LvJcB", "sid": 14, "sentence": "It may be worth adding a short discussion/comparison to that work as it also considers zero-shot learning."}, {"text_id": "B1ez1LvJcB", "sid": 15, "sentence": "Minor comments:"}, {"text_id": "B1ez1LvJcB", "sid": 16, "sentence": "- Capitalize: \u201csection\u201d -> \u201cSection\u201d, \u201cappendix\u201d -> \u201cAppendix\u201d, \u201cfig.\u201d -> \u201cFigure\u201d."}, {"text_id": "B1ez1LvJcB", "sid": 17, "sentence": "Sometimes these are capitalized, but the use is inconsistent throughout the paper."}, {"text_id": "B1ez1LvJcB", "sid": 18, "sentence": "- \u201cHold-out\u201d vs \u201cheld-out\u201d"}, {"text_id": "B1ez1LvJcB", "sid": 19, "sentence": "."}, {"text_id": "B1ez1LvJcB", "sid": 20, "sentence": "Be consistent and use \u201cheld-out\u201d throughout."}], "reviewlabels": [{"text_id": "B1ez1LvJcB", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1ez1LvJcB", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1ez1LvJcB", "sid": 2, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Motivation/Impact", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1ez1LvJcB", "sid": 3, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1ez1LvJcB", "sid": 4, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1ez1LvJcB", "sid": 5, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1ez1LvJcB", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Meaningful Comparison", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1ez1LvJcB", "sid": 7, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Meaningful Comparison", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1ez1LvJcB", "sid": 8, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Meaningful Comparison", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1ez1LvJcB", "sid": 9, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1ez1LvJcB", "sid": 10, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Motivation/Impact", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1ez1LvJcB", "sid": 11, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1ez1LvJcB", "sid": 12, "labels": {"coarse": "Social", "fine": "Social", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1ez1LvJcB", "sid": 13, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1ez1LvJcB", "sid": 14, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Meaningful Comparison", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1ez1LvJcB", "sid": 15, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1ez1LvJcB", "sid": 16, "labels": {"coarse": "Request", "fine": "Request.Typo", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1ez1LvJcB", "sid": 17, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1ez1LvJcB", "sid": 18, "labels": {"coarse": "Request", "fine": "Request.Typo", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "B1ez1LvJcB", "sid": 19, "labels": {"coarse": "Request", "fine": "Request.Typo", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "B1ez1LvJcB", "sid": 20, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "rygJHT4DoB", "sid": 0, "sentence": "Thank you for your thoughtful review."}, {"text_id": "rygJHT4DoB", "sid": 1, "sentence": "We appreciate that you think our problem and approach are interesting! We have made some substantial revisions to clarify the presentation, we hope that these will help address your concerns."}, {"text_id": "rygJHT4DoB", "sid": 2, "sentence": "We respond to some specific comments below:"}, {"text_id": "rygJHT4DoB", "sid": 3, "sentence": "> No comparisons were provided to any baselines/alternative methods."}, {"text_id": "rygJHT4DoB", "sid": 4, "sentence": "We do compare to a number of lesions in the supplement, and to an alternative method (performing tasks from a description alone)."}, {"text_id": "rygJHT4DoB", "sid": 5, "sentence": "We have moved this latter comparison to the main text at the suggestion of Reviewer 1."}, {"text_id": "rygJHT4DoB", "sid": 6, "sentence": "> in Sections 4 and 5 I was hoping to see comparisons to methods like MAML."}, {"text_id": "rygJHT4DoB", "sid": 7, "sentence": "Also, I felt that the proposed approach in Section 5 is very similar to MAML intuitively."}, {"text_id": "rygJHT4DoB", "sid": 8, "sentence": "This makes a comparison with MAML even more desirable. Without any comparisons it\u2019s hard to tell how difficult the tasks under consideration are and what would amount to good performance on the held-out tasks."}, {"text_id": "rygJHT4DoB", "sid": 9, "sentence": "Our main contribution is to propose a meta-mapping framework for zero-shot task performance, and parsimonious method for performing these meta-mappings."}, {"text_id": "rygJHT4DoB", "sid": 10, "sentence": "MAML as such is not a method of zero-shot task performance, it requires examples to learn"}, {"text_id": "rygJHT4DoB", "sid": 11, "sentence": "from"}, {"text_id": "rygJHT4DoB", "sid": 12, "sentence": "."}, {"text_id": "rygJHT4DoB", "sid": 13, "sentence": "We could therefore compare to MAML for our basic-meta-learning results, but those are simply a sanity check."}, {"text_id": "rygJHT4DoB", "sid": 14, "sentence": "We also compare to a variety of baselines, including chance and optimal performance, untransformed representations, and the most correlated task experienced (in the cards domain)."}, {"text_id": "rygJHT4DoB", "sid": 15, "sentence": "However, if our paper is accepted, and you feel that the comparison to MAML for basic meta-learning is useful, we will run MAML on our tasks before the camera-ready submission."}, {"text_id": "rygJHT4DoB", "sid": 16, "sentence": "One might take inspiration from our framework try to use MAML for zero-shot task performance by transforming task representations would require adopting our meta-mapping framework, as well as a number of ideas of our architecture (where do the task representations come from, and how are they used?), and so its not clear to us that this is an appropriate baseline, rather than simply another implementation of our technique."}, {"text_id": "rygJHT4DoB", "sid": 17, "sentence": "Instead, we feel the more appropriate baseline is performing tasks from a natural language description, as many prior zero-shot works have, and so we have moved this result to the main text, as noted above."}, {"text_id": "rygJHT4DoB", "sid": 18, "sentence": "> The experimental results presented were all done on small synthetic datasets and it\u2019s hard to evaluate whether the method is practically useful."}, {"text_id": "rygJHT4DoB", "sid": 19, "sentence": "We already have more material than fits in this paper, especially now that we have added clarifications that all reviewers requested."}, {"text_id": "rygJHT4DoB", "sid": 20, "sentence": "We remained with synthetic tasks for two reasons: 1) to illustrate the method in settings we thought would be clearer, 2) because as we highlight in the future directions, there is a lack of meta-learning datasets that contain as structured of relationships between tasks as we consider."}, {"text_id": "rygJHT4DoB", "sid": 21, "sentence": "(Taskonomy, for example, has at best a notion of \"similarity\" in terms of transfer.) We are working on creating several such datasets, but we think that this paper as it stands is a useful contribution that illustrates the concept and ideas -- the datasets themselves will also require further description, and including them in a paper of this length would likely result in even more material being cut, and so a less clear presentation."}, {"text_id": "rygJHT4DoB", "sid": 22, "sentence": "We do think this is an important direction, but we think this paper makes a useful contribution by highlighting this new perspective. We hope that you agree."}, {"text_id": "rygJHT4DoB", "sid": 23, "sentence": "> Also, the work by Platanios, et al. on contextual parameter generation is very relevant to this work as it tackles multi-task learning using HyperNetworks."}, {"text_id": "rygJHT4DoB", "sid": 24, "sentence": "It may be worth adding a short discussion/comparison to that work as it also considers zero-shot learning."}, {"text_id": "rygJHT4DoB", "sid": 25, "sentence": "Thanks, we weren't familiar with this very interesting work! We have added a reference and a brief discussion of the relationship."}, {"text_id": "rygJHT4DoB", "sid": 26, "sentence": "- Capitalize: \u201csection\u201d -> \u201cSection\u201d, \u201cappendix\u201d -> \u201cAppendix\u201d, \u201cfig.\u201d -> \u201cFigure\u201d."}, {"text_id": "rygJHT4DoB", "sid": 27, "sentence": "Sometimes these are capitalized, but the use is inconsistent throughout the paper."}, {"text_id": "rygJHT4DoB", "sid": 28, "sentence": "Thanks for pointing this out, fixed."}, {"text_id": "rygJHT4DoB", "sid": 29, "sentence": "- \u201cHold-out\u201d vs \u201cheld-out\u201d"}, {"text_id": "rygJHT4DoB", "sid": 30, "sentence": "."}, {"text_id": "rygJHT4DoB", "sid": 31, "sentence": "Be consistent and use \u201cheld-out\u201d throughout."}, {"text_id": "rygJHT4DoB", "sid": 32, "sentence": "We are making a grammatical distinction here -- \"held-out\" is an adjective and \"hold-out\" is a noun. That is, one might refer to a \"held-out task\" or to a \"a hold-out.\" Hopefully this clarifies things."}, {"text_id": "rygJHT4DoB", "sid": 33, "sentence": "We hope that this clarifies things, and will help to address your concerns. Please let us know if further changes would be useful."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "rygJHT4DoB", "sid": 0}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rygJHT4DoB", "sid": 1}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rygJHT4DoB", "sid": 2}, {"labels": {"alignments": [6], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rygJHT4DoB", "sid": 3}, {"labels": {"alignments": [6], "responsetype": "refute-question", "coarseresponse": "dispute"}, "text_id": "rygJHT4DoB", "sid": 4}, {"labels": {"alignments": [6], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "rygJHT4DoB", "sid": 5}, {"labels": {"alignments": [7, 8, 9], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rygJHT4DoB", "sid": 6}, {"labels": {"alignments": [7, 8, 9], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rygJHT4DoB", "sid": 7}, {"labels": {"alignments": [7, 8, 9], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rygJHT4DoB", "sid": 8}, {"labels": {"alignments": [7, 8, 9], "responsetype": "refute-question", "coarseresponse": "dispute"}, "text_id": "rygJHT4DoB", "sid": 9}, {"labels": {"alignments": [7, 8, 9], "responsetype": "refute-question", "coarseresponse": "dispute"}, "text_id": "rygJHT4DoB", "sid": 10}, {"labels": {"alignments": [7, 8, 9], "responsetype": "refute-question", "coarseresponse": "dispute"}, "text_id": "rygJHT4DoB", "sid": 11}, {"labels": {"alignments": [7, 8, 9], "responsetype": "refute-question", "coarseresponse": "dispute"}, "text_id": "rygJHT4DoB", "sid": 12}, {"labels": {"alignments": [7, 8, 9], "responsetype": "refute-question", "coarseresponse": "dispute"}, "text_id": "rygJHT4DoB", "sid": 13}, {"labels": {"alignments": [7, 8, 9], "responsetype": "refute-question", "coarseresponse": "dispute"}, "text_id": "rygJHT4DoB", "sid": 14}, {"labels": {"alignments": [7, 8, 9], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "rygJHT4DoB", "sid": 15}, {"labels": {"alignments": [7, 8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rygJHT4DoB", "sid": 16}, {"labels": {"alignments": [7, 8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rygJHT4DoB", "sid": 17}, {"labels": {"alignments": [5], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rygJHT4DoB", "sid": 18}, {"labels": {"alignments": [5], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "rygJHT4DoB", "sid": 19}, {"labels": {"alignments": [5], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "rygJHT4DoB", "sid": 20}, {"labels": {"alignments": [5], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "rygJHT4DoB", "sid": 21}, {"labels": {"alignments": [5], "responsetype": "reject-request_scope_Yes", "coarseresponse": "dispute"}, "text_id": "rygJHT4DoB", "sid": 22}, {"labels": {"alignments": [13, 14], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rygJHT4DoB", "sid": 23}, {"labels": {"alignments": [13, 14], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rygJHT4DoB", "sid": 24}, {"labels": {"alignments": [13, 14], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "rygJHT4DoB", "sid": 25}, {"labels": {"alignments": [16, 17], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rygJHT4DoB", "sid": 26}, {"labels": {"alignments": [16, 17], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rygJHT4DoB", "sid": 27}, {"labels": {"alignments": [16, 17], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "rygJHT4DoB", "sid": 28}, {"labels": {"alignments": [18, 19, 20], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rygJHT4DoB", "sid": 29}, {"labels": {"alignments": [18, 19, 20], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rygJHT4DoB", "sid": 30}, {"labels": {"alignments": [18, 19, 20], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rygJHT4DoB", "sid": 31}, {"labels": {"alignments": [18, 19, 20], "responsetype": "reject-request_scope_No", "coarseresponse": "dispute"}, "text_id": "rygJHT4DoB", "sid": 32}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "rygJHT4DoB", "sid": 33}], "metadata": {"anno": "anno2", "review": "B1ez1LvJcB", "rebuttal": "rygJHT4DoB", "conference": "ICLR2020", "title": "Zero-shot task adaptation by homoiconic meta-mapping", "reviewer": "AnonReviewer3", "forum_id": "HyeX7aVKvr", "rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area."}}