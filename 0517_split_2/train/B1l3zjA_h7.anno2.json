{"review": [{"text_id": "B1l3zjA_h7", "sid": 0, "sentence": "## Summary ##"}, {"text_id": "B1l3zjA_h7", "sid": 1, "sentence": "The authors apply policy gradients to combinatorial optimization problems."}, {"text_id": "B1l3zjA_h7", "sid": 2, "sentence": "They suggest a surrogate reward function that mitigates the variance in the reward, and hence the update size."}, {"text_id": "B1l3zjA_h7", "sid": 3, "sentence": "They demonstrate performance on a clique-finding problem."}, {"text_id": "B1l3zjA_h7", "sid": 4, "sentence": "## Assessment ##"}, {"text_id": "B1l3zjA_h7", "sid": 5, "sentence": "I don't think Cakewalk is different enough from the cross-entropy method to warrant acceptance in ICLR."}, {"text_id": "B1l3zjA_h7", "sid": 6, "sentence": "I also have concerns about the independence assumption in their sampling distribution (Section 3.2), and the fact that their experiments use the same set of (untuned) hyperparameters for each method."}, {"text_id": "B1l3zjA_h7", "sid": 7, "sentence": "They both approximate the reward CDF from K samples and use this to construct a surrogate reward."}, {"text_id": "B1l3zjA_h7", "sid": 8, "sentence": "The difference is that Cakewalk uses the CDF directly, while CE uses a threshold function on the CDF."}, {"text_id": "B1l3zjA_h7", "sid": 9, "sentence": "## Specific Comments and Questions ##"}, {"text_id": "B1l3zjA_h7", "sid": 10, "sentence": "1. Cakewalk is *very* closely related to the cross-entropy method."}, {"text_id": "B1l3zjA_h7", "sid": 11, "sentence": "The authors acknowledge this connection, but I think they should begin by introducing CE and then explain how Cakewalk generalizes it."}, {"text_id": "B1l3zjA_h7", "sid": 12, "sentence": "Both Cakewalk and CE approximate the reward CDF from K samples and use this to construct a surrogate reward."}, {"text_id": "B1l3zjA_h7", "sid": 13, "sentence": "The difference is that Cakewalk uses the CDF directly, while CE uses a threshold function on the CDF."}, {"text_id": "B1l3zjA_h7", "sid": 14, "sentence": "2. The distribution proposed in section 3.2 assumes independence between the elements $x_j$. This seems problematic for some relatively simple problems."}, {"text_id": "B1l3zjA_h7", "sid": 15, "sentence": "Consider $x$ a binary vector and reward equal to the parity $S(x) = \\sum{x_j} % 2$."}, {"text_id": "B1l3zjA_h7", "sid": 16, "sentence": "3. In the experiments, there are large discrepancies between different optimizers on Cakewalk (e.g. SGA vs AdaGrad, Table 4)."}, {"text_id": "B1l3zjA_h7", "sid": 17, "sentence": "Is there any explanation for this?"}, {"text_id": "B1l3zjA_h7", "sid": 18, "sentence": "4. How were the hyperparameters (learning rate, AdaGrad $\\delta$, Adam $\\beta_1, \\beta_2$) chosen?"}, {"text_id": "B1l3zjA_h7", "sid": 19, "sentence": "It seems like a large assumption that the same learning rate would work for different methods, especially when some of them are normalizing the objective function."}, {"text_id": "B1l3zjA_h7", "sid": 20, "sentence": "I would suggest tuning these values for each method independently."}, {"text_id": "B1l3zjA_h7", "sid": 21, "sentence": "5. It would be nice to see experimental results on more than one problem."}, {"text_id": "B1l3zjA_h7", "sid": 22, "sentence": "The authors discuss their results on k-medoids in the appendices, but it seems like these results aren't quite complete yet."}, {"text_id": "B1l3zjA_h7", "sid": 23, "sentence": "6. In Table 3, the figure in bold is not the lowest (best) in the table."}, {"text_id": "B1l3zjA_h7", "sid": 24, "sentence": "The reason for this is only given in a single sentence at the end of Section 6, so it is a little confusing."}, {"text_id": "B1l3zjA_h7", "sid": 25, "sentence": "I would replace these values with N/A or something similar."}], "reviewlabels": [{"text_id": "B1l3zjA_h7", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1l3zjA_h7", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1l3zjA_h7", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1l3zjA_h7", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1l3zjA_h7", "sid": 4, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1l3zjA_h7", "sid": 5, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1l3zjA_h7", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1l3zjA_h7", "sid": 7, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1l3zjA_h7", "sid": 8, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1l3zjA_h7", "sid": 9, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1l3zjA_h7", "sid": 10, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1l3zjA_h7", "sid": 11, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Meaningful Comparison", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1l3zjA_h7", "sid": 12, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1l3zjA_h7", "sid": 13, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1l3zjA_h7", "sid": 14, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1l3zjA_h7", "sid": 15, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1l3zjA_h7", "sid": 16, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1l3zjA_h7", "sid": 17, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1l3zjA_h7", "sid": 18, "labels": {"coarse": "Request", "fine": "Request.Clarification", "asp": "Replicability", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1l3zjA_h7", "sid": 19, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1l3zjA_h7", "sid": 20, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Soundness/Correctness", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1l3zjA_h7", "sid": 21, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1l3zjA_h7", "sid": 22, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1l3zjA_h7", "sid": 23, "labels": {"coarse": "Structuring", "fine": "Structuring.Quote", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1l3zjA_h7", "sid": 24, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1l3zjA_h7", "sid": 25, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Soundness/Correctness", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "SyxFgYgiTQ", "sid": 0, "sentence": "Except for the learning rate, all the hyper-parameters were chosen according to the values suggested by the authors of AdaGrad, and Adam."}, {"text_id": "SyxFgYgiTQ", "sid": 1, "sentence": "The learning rate was chosen as 1/K, with K=100 being the number of examples used to estimate the CDF."}, {"text_id": "SyxFgYgiTQ", "sid": 2, "sentence": "As our stated goal is to present an algorithm which can be blindly applied with some fixed set of hyper-parameters to any possible objective, one of the goals of the experiments is to show that in such a setting some methods will work, while others will fail."}, {"text_id": "SyxFgYgiTQ", "sid": 3, "sentence": "Thus, as a controlled experiment for this hypothesis, we first fixed the set of all hyper-parameters for all methods, and then proceeded to apply them to various problems."}, {"text_id": "SyxFgYgiTQ", "sid": 4, "sentence": "In this setting therefore, tuning the learning rate or any other hyper-parameter for that matter will compromise the validity of our results."}, {"text_id": "SyxFgYgiTQ", "sid": 5, "sentence": "Regarding table 3, we accept the reviewer\u2019s suggestion, this is a good point. We particularly like the suggestion of writing NA or some such value, and we will use it to correct the paper."}, {"text_id": "SyxFgYgiTQ", "sid": 6, "sentence": "We thank the reviewer for the evaluation."}, {"text_id": "SyxFgYgiTQ", "sid": 7, "sentence": "Please see our detailed response to several recurring issues at https://openreview.net/forum?id=Hkx-ii05FQ&noteId=HygFbNmL6X."}, {"text_id": "SyxFgYgiTQ", "sid": 8, "sentence": "In that response we address the following issues:"}, {"text_id": "SyxFgYgiTQ", "sid": 9, "sentence": "(1) We emphasize fundamental differences between Cakewalk and CE."}, {"text_id": "SyxFgYgiTQ", "sid": 10, "sentence": "These go beyond the differences the reviewer mentions."}, {"text_id": "SyxFgYgiTQ", "sid": 11, "sentence": "(2) How the sampling distribution should not be considered as a part of Cakewalk, and that it is mostly provided as an example, and a basis for the reported experiments."}, {"text_id": "SyxFgYgiTQ", "sid": 12, "sentence": "(3) The experiments include results two tasks."}, {"text_id": "SyxFgYgiTQ", "sid": 13, "sentence": "Nonetheless, it appears the paper doesn\u2019t convey this clearly, and we suggest two possible ways how to update the paper in this regard."}, {"text_id": "SyxFgYgiTQ", "sid": 14, "sentence": "Next, we try to answer the specific issues the reviewer mentions."}, {"text_id": "SyxFgYgiTQ", "sid": 15, "sentence": "First, we address the suggestion of introducing Cakewalk as a generalization of CE."}, {"text_id": "SyxFgYgiTQ", "sid": 16, "sentence": "While we were writing the paper we in fact considered presenting Cakewalk as the reviewer suggests."}, {"text_id": "SyxFgYgiTQ", "sid": 17, "sentence": "We eventually decided against this approach as CE is a method for adapting an importance sampler, and its convergence guarantees only apply when it is treated as such."}, {"text_id": "SyxFgYgiTQ", "sid": 18, "sentence": "The convergence guarantees of REINFORCE on the other hand still apply under our surrogate objective framework."}, {"text_id": "SyxFgYgiTQ", "sid": 19, "sentence": "This property allows us to explore various surrogates, where one such construction allows us to interpret CE as a policy gradient method, and another makes the basis for Cakewalk."}, {"text_id": "SyxFgYgiTQ", "sid": 20, "sentence": "Second, we address the issue of using a sampling distribution that assumes independence between the different dimensions."}, {"text_id": "SyxFgYgiTQ", "sid": 21, "sentence": "As the author correctly states, such a distribution will not always be useful, and one can design a problem for which this distribution will lead to a poor local optimum."}, {"text_id": "SyxFgYgiTQ", "sid": 22, "sentence": "Note however that a global maximizer for the objective suggested by the reviewer can be easily found just by random sampling: sampling such a maximizer has the same probably as sampling an odd integer - half."}, {"text_id": "SyxFgYgiTQ", "sid": 23, "sentence": "Nonetheless, for the clique problem such a distribution can be effective."}, {"text_id": "SyxFgYgiTQ", "sid": 24, "sentence": "Intuitively, if some node i is part of a large clique, then sampling x_i=1 is likely to result in a good objective as there are many nodes that are connected to i, and the chance of not sampling any of them decreases with the clique size."}, {"text_id": "SyxFgYgiTQ", "sid": 25, "sentence": "In this way, over time the probability for sampling such nodes becomes higher, and the chance of sampling all of them together increases."}, {"text_id": "SyxFgYgiTQ", "sid": 26, "sentence": "A similar reasoning applies for the k-medoids problem."}, {"text_id": "SyxFgYgiTQ", "sid": 27, "sentence": "We note that these kind of factorized distributions have a long history of being useful in machine learning."}, {"text_id": "SyxFgYgiTQ", "sid": 28, "sentence": "In a similar context to the one studied in the paper, such distributions have been studied by Rubinstein in his paper which discusses CE as an algorithm for combinatorial optimization, and in the classical bandit papers Exp3 is applied independently to several dimensions to study game theoretic problems."}, {"text_id": "SyxFgYgiTQ", "sid": 29, "sentence": "In different contexts, such distributions have also been used as naive mean field approximations in variational inference."}, {"text_id": "SyxFgYgiTQ", "sid": 30, "sentence": "Next, we address the question regarding the gradient update types."}, {"text_id": "SyxFgYgiTQ", "sid": 31, "sentence": "One intuitive explanation for why an algorithm that maintains a \u2018memory\u2019 of previous gradient updates like AdaGrad or Adam is required"}, {"text_id": "SyxFgYgiTQ", "sid": 32, "sentence": "is that they protect against sampling biases."}, {"text_id": "SyxFgYgiTQ", "sid": 33, "sentence": "Consider for example the case when the execution is at the start, and the sampling distribution still has maximum entropy."}, {"text_id": "SyxFgYgiTQ", "sid": 34, "sentence": "Due to the combinatorial nature of the solution space, the examples that have been sampled thus far create a distorted representation of the solution space."}, {"text_id": "SyxFgYgiTQ", "sid": 35, "sentence": "In this case we could get that some x_i=j will occur few times, while some other x_k will not receive the value j at all."}, {"text_id": "SyxFgYgiTQ", "sid": 36, "sentence": "Now if we apply vanilla gradient updates this can skew the sampling distribution in random directions."}, {"text_id": "SyxFgYgiTQ", "sid": 37, "sentence": "Gradient updates such as those of AdaGrad and Adam on the other hand will lessen the impact of such deviations as the importance of each case is inversely proportional to the number of previous observations."}, {"text_id": "SyxFgYgiTQ", "sid": 38, "sentence": "As such deviations will inevitably occur whenever we rely on polynomially sized samples to represent a combinatorial solution space, without such corrections a gradient based adaptive sampling algorithm will almost surely fail."}, {"text_id": "SyxFgYgiTQ", "sid": 39, "sentence": "Indeed, as can be seen in tables 1,2 and 4, SGA almost never leads to a locally optimal solution."}, {"text_id": "SyxFgYgiTQ", "sid": 40, "sentence": "Furthermore, this reasoning explains why AdaGrad is superior to Adam: AdaGrad corrects against sampling biases that entail all the examples that have been encountered, while Adam does this only within some exponentially moving time window."}, {"text_id": "SyxFgYgiTQ", "sid": 41, "sentence": "Indeed, this phenomenon is studied in detail in the AdaGrad paper (though without assuming a data distribution), and sparse data like ours (one can say our data points are N indicator vectors of length M) is the first motivating example in their paper."}], "rebuttallabels": [{"labels": {"alignments": [18, 19, 20], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyxFgYgiTQ", "sid": 0}, {"labels": {"alignments": [18, 19, 20], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyxFgYgiTQ", "sid": 1}, {"labels": {"alignments": [18, 19, 20], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyxFgYgiTQ", "sid": 2}, {"labels": {"alignments": [18, 19, 20], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyxFgYgiTQ", "sid": 3}, {"labels": {"alignments": [18, 19, 20], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyxFgYgiTQ", "sid": 4}, {"labels": {"alignments": [23, 24, 25], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "SyxFgYgiTQ", "sid": 5}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "SyxFgYgiTQ", "sid": 6}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SyxFgYgiTQ", "sid": 7}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SyxFgYgiTQ", "sid": 8}, {"labels": {"alignments": [], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "SyxFgYgiTQ", "sid": 9}, {"labels": {"alignments": [], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "SyxFgYgiTQ", "sid": 10}, {"labels": {"alignments": [], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "SyxFgYgiTQ", "sid": 11}, {"labels": {"alignments": [], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "SyxFgYgiTQ", "sid": 12}, {"labels": {"alignments": [], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "SyxFgYgiTQ", "sid": 13}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SyxFgYgiTQ", "sid": 14}, {"labels": {"alignments": [10, 11, 12, 13], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SyxFgYgiTQ", "sid": 15}, {"labels": {"alignments": [10, 11, 12, 13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyxFgYgiTQ", "sid": 16}, {"labels": {"alignments": [10, 11, 12, 13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyxFgYgiTQ", "sid": 17}, {"labels": {"alignments": [10, 11, 12, 13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyxFgYgiTQ", "sid": 18}, {"labels": {"alignments": [10, 11, 12, 13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyxFgYgiTQ", "sid": 19}, {"labels": {"alignments": [14, 15], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SyxFgYgiTQ", "sid": 20}, {"labels": {"alignments": [14, 15], "responsetype": "concede-criticism", "coarseresponse": "concur"}, "text_id": "SyxFgYgiTQ", "sid": 21}, {"labels": {"alignments": [14, 15], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "SyxFgYgiTQ", "sid": 22}, {"labels": {"alignments": [14, 15], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "SyxFgYgiTQ", "sid": 23}, {"labels": {"alignments": [14, 15], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyxFgYgiTQ", "sid": 24}, {"labels": {"alignments": [14, 15], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyxFgYgiTQ", "sid": 25}, {"labels": {"alignments": [14, 15], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyxFgYgiTQ", "sid": 26}, {"labels": {"alignments": [14, 15], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyxFgYgiTQ", "sid": 27}, {"labels": {"alignments": [14, 15], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyxFgYgiTQ", "sid": 28}, {"labels": {"alignments": [14, 15], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyxFgYgiTQ", "sid": 29}, {"labels": {"alignments": [16, 17], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SyxFgYgiTQ", "sid": 30}, {"labels": {"alignments": [16, 17], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyxFgYgiTQ", "sid": 31}, {"labels": {"alignments": [16, 17], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyxFgYgiTQ", "sid": 32}, {"labels": {"alignments": [16, 17], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyxFgYgiTQ", "sid": 33}, {"labels": {"alignments": [16, 17], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyxFgYgiTQ", "sid": 34}, {"labels": {"alignments": [16, 17], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyxFgYgiTQ", "sid": 35}, {"labels": {"alignments": [16, 17], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyxFgYgiTQ", "sid": 36}, {"labels": {"alignments": [16, 17], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyxFgYgiTQ", "sid": 37}, {"labels": {"alignments": [16, 17], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyxFgYgiTQ", "sid": 38}, {"labels": {"alignments": [16, 17], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SyxFgYgiTQ", "sid": 39}, {"labels": {"alignments": [16, 17], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyxFgYgiTQ", "sid": 40}, {"labels": {"alignments": [16, 17], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyxFgYgiTQ", "sid": 41}], "metadata": {"anno": "anno2", "review": "B1l3zjA_h7", "rebuttal": "SyxFgYgiTQ", "conference": "ICLR2019", "title": "The Cakewalk Method", "reviewer": "AnonReviewer2", "forum_id": "Hkx-ii05FQ", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}}