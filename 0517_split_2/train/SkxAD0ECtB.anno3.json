{"review": [{"text_id": "SkxAD0ECtB", "sid": 0, "sentence": "This paper proposes new pre-training strategies for GNN with both a node-level and a graph-level pretraining."}, {"text_id": "SkxAD0ECtB", "sid": 1, "sentence": "For the node-level pretraining, the goal is to map nodes with similar surrounding structures to nearby context (similarly to word2vec)."}, {"text_id": "SkxAD0ECtB", "sid": 2, "sentence": "The main problem is that directly predicting the context is intractable because of combinatorial explosion."}, {"text_id": "SkxAD0ECtB", "sid": 3, "sentence": "The main idea is then to use an additional GNN to encode the context and to learn simultaneously the main GNN and the context GNN via negative sampling."}, {"text_id": "SkxAD0ECtB", "sid": 4, "sentence": "Another method used is attribute masking where some masked node and edge attributes need to be predicted by the GNN."}, {"text_id": "SkxAD0ECtB", "sid": 5, "sentence": "For graph-level pretraining, some general graph properties need to be predicted by the graph."}, {"text_id": "SkxAD0ECtB", "sid": 6, "sentence": "Experiments are conducted on datasets in the chemistry domain and the biology domain showing the benefit of the pre-training."}, {"text_id": "SkxAD0ECtB", "sid": 7, "sentence": "The paper addresses an important and timely problem."}, {"text_id": "SkxAD0ECtB", "sid": 8, "sentence": "It is a pity that the code is not provided."}, {"text_id": "SkxAD0ECtB", "sid": 9, "sentence": "In particular, the node-level pretraining described in section 3.1.1. seems rather complicated to implement as a context graph needs to be computed for each node in the graph."}, {"text_id": "SkxAD0ECtB", "sid": 10, "sentence": "In particular I do not think the satement 'all the pre-training methods are at most linear with respect to the number of edges' made in appendix F is correct."}], "reviewlabels": [{"text_id": "SkxAD0ECtB", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SkxAD0ECtB", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SkxAD0ECtB", "sid": 2, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SkxAD0ECtB", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SkxAD0ECtB", "sid": 4, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SkxAD0ECtB", "sid": 5, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SkxAD0ECtB", "sid": 6, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SkxAD0ECtB", "sid": 7, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SkxAD0ECtB", "sid": 8, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SkxAD0ECtB", "sid": 9, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SkxAD0ECtB", "sid": 10, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "BJgEvjdmsH", "sid": 0, "sentence": "We thank the reviewer for acknowledging the technical aspects of the paper and for noting that our\u200b \u200bresults\u200b \u200bare\u200b \u200bsolid\u200b \u200band\u200b \u200bour\u200b \u200banalysis\u200b \u200bis\u200b \u200bthorough."}, {"text_id": "BJgEvjdmsH", "sid": 1, "sentence": "RE: Source code"}, {"text_id": "BJgEvjdmsH", "sid": 2, "sentence": "The reviewer makes an important point about the availability of the source code."}, {"text_id": "BJgEvjdmsH", "sid": 3, "sentence": "To address this point, in the link privately shared with the reviewers, we have provided all of our code, datasets together with their train/test splits, as well as our pre-trained models, to help with the reproducibility of our results."}, {"text_id": "BJgEvjdmsH", "sid": 4, "sentence": "We note that we will share PyTorch implementations of all pre-training methods and datasets with the community upon publication."}, {"text_id": "BJgEvjdmsH", "sid": 5, "sentence": "Please feel free to ask any further questions regarding our code and implementation."}, {"text_id": "BJgEvjdmsH", "sid": 6, "sentence": "RE: Linear time complexity in Appendix F"}, {"text_id": "BJgEvjdmsH", "sid": 7, "sentence": "We acknowledge that the time complexity of our pre-training methods was not well explained in Appendix F. In Figure 2 (a) we show that we only sample one node per graph."}, {"text_id": "BJgEvjdmsH", "sid": 8, "sentence": "We then use breadth-first search to extract a K-hop neighborhood of the node, which takes at most linear time with respect to the number of edges in the graph."}, {"text_id": "BJgEvjdmsH", "sid": 9, "sentence": "As a result, pre-training via context prediction has linear time complexity."}, {"text_id": "BJgEvjdmsH", "sid": 10, "sentence": "We will edit Appendix F to include more detailed information and cover this important point."}, {"text_id": "BJgEvjdmsH", "sid": 11, "sentence": "Please let us know if you have any further questions or comments!"}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "BJgEvjdmsH", "sid": 0}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "BJgEvjdmsH", "sid": 1}, {"labels": {"alignments": [8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgEvjdmsH", "sid": 2}, {"labels": {"alignments": [8], "responsetype": "done_manu_No", "coarseresponse": "concur"}, "text_id": "BJgEvjdmsH", "sid": 3}, {"labels": {"alignments": [8], "responsetype": "by-cr_manu_No", "coarseresponse": "concur"}, "text_id": "BJgEvjdmsH", "sid": 4}, {"labels": {"alignments": [8], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "BJgEvjdmsH", "sid": 5}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "BJgEvjdmsH", "sid": 6}, {"labels": {"alignments": [9], "responsetype": "concede-criticism", "coarseresponse": "concur"}, "text_id": "BJgEvjdmsH", "sid": 7}, {"labels": {"alignments": [9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgEvjdmsH", "sid": 8}, {"labels": {"alignments": [9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgEvjdmsH", "sid": 9}, {"labels": {"alignments": [9], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "BJgEvjdmsH", "sid": 10}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "BJgEvjdmsH", "sid": 11}], "metadata": {"anno": "anno3", "review": "SkxAD0ECtB", "rebuttal": "BJgEvjdmsH", "conference": "ICLR2020", "title": "Strategies for Pre-training Graph Neural Networks", "reviewer": "AnonReviewer1", "forum_id": "HJlWWJSFDH", "rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area."}}