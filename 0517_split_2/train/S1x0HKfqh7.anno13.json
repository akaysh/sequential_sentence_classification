{"review": [{"text_id": "S1x0HKfqh7", "sid": 0, "sentence": "This paper proposes an evaluation method for confidence thresholding defense models, as well as a new approach for generating of adversarial examples by choosing the wrong class with the most confidence when employing targeted attacks."}, {"text_id": "S1x0HKfqh7", "sid": 1, "sentence": "Although the idea behind this paper is fairly simple, the paper is very difficult to understand."}, {"text_id": "S1x0HKfqh7", "sid": 2, "sentence": "I have no idea that what is the propose of defining a new evaluation method and how this new evaluation method helps in the further design of the MaxConfidence method."}, {"text_id": "S1x0HKfqh7", "sid": 3, "sentence": "Furthermore, the usage of the evaluation method unclear as well, it seems to be designed for evaluating the effectiveness of different adversarial attacks in Figure 2."}, {"text_id": "S1x0HKfqh7", "sid": 4, "sentence": "However, in Figure 2, it is used for evaluating defense schemes."}, {"text_id": "S1x0HKfqh7", "sid": 5, "sentence": "Again, this confuses me on what is the main topic of this paper."}, {"text_id": "S1x0HKfqh7", "sid": 6, "sentence": "Indeed, why the commonly used attack success ratio or other similar measures cannot be used in the case?"}, {"text_id": "S1x0HKfqh7", "sid": 7, "sentence": "Intuitively, it should provide similar results to the success-failure curve."}, {"text_id": "S1x0HKfqh7", "sid": 8, "sentence": "The paper also lacks experimental results, and the main conclusion from these results seems to be \"MNIST is not suitable for benchmarking of adversarial attacks\"."}, {"text_id": "S1x0HKfqh7", "sid": 9, "sentence": "If the authors claim that the proposed MaxConfidence attack method is more powerful than the MaxLoss based attacks, they should provide more comparisons between these methods."}, {"text_id": "S1x0HKfqh7", "sid": 10, "sentence": "Meanwhile, the computational cost on large dataset such as ImageNet could be huge, the authors should further develop the method to make sure it works in all situations."}], "reviewlabels": [{"text_id": "S1x0HKfqh7", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "S1x0HKfqh7", "sid": 1, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "S1x0HKfqh7", "sid": 2, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Motivation/Impact", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "S1x0HKfqh7", "sid": 3, "labels": {"coarse": "Request", "fine": "Request.Clarification", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "S1x0HKfqh7", "sid": 4, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "S1x0HKfqh7", "sid": 5, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "S1x0HKfqh7", "sid": 6, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "S1x0HKfqh7", "sid": 7, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "S1x0HKfqh7", "sid": 8, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "S1x0HKfqh7", "sid": 9, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Meaningful Comparison", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "S1x0HKfqh7", "sid": 10, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "S1xAN6UJT7", "sid": 0, "sentence": "The main topic of the paper is how to evaluate models that use confidence thresholding."}, {"text_id": "S1xAN6UJT7", "sid": 1, "sentence": "The primary purpose is to compare *defenses*. However, to justify the attack strategy that we propose to use, we also compare *attacks*. Specifically, we provide an experiment demonstrating that our attack actually is stronger than the baseline."}, {"text_id": "S1xAN6UJT7", "sid": 2, "sentence": "However, it is not really necessary to provide multiple experiments demonstrating that MaxConfidence is more powerful because the superiority of MaxConfidence is theoretically guaranteed."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "S1xAN6UJT7", "sid": 0}, {"labels": {"alignments": [], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "S1xAN6UJT7", "sid": 1}, {"labels": {"alignments": [8, 9], "responsetype": "reject-request_scope_Yes", "coarseresponse": "dispute"}, "text_id": "S1xAN6UJT7", "sid": 2}], "metadata": {"anno": "anno13", "review": "S1x0HKfqh7", "rebuttal": "S1xAN6UJT7", "conference": "ICLR2019", "title": "Evaluation Methodology for Attacks Against Confidence Thresholding Models", "reviewer": "AnonReviewer3", "forum_id": "H1g0piA9tQ", "rating": "3: Clear rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}}