{"review": [{"text_id": "BJeYeRM0jm", "sid": 0, "sentence": "The paper builds upon Deep Image Prior (DIP) - work which shows that one can optimize a neural generator to fit a single image without learning on any dataset, and the output of the generator (which approximates the image) can be used for denoising / super resolution / etc."}, {"text_id": "BJeYeRM0jm", "sid": 1, "sentence": "The paper proposes a new architecture for the DIP method which has much less parameters, but works on par with DIP."}, {"text_id": "BJeYeRM0jm", "sid": 2, "sentence": "Another contribution of the paper is theoretical treatment of (a simplified version of) the proposed architecture showing that it can\u2019t fit random noise (and thus maybe better suited for denoising)."}, {"text_id": "BJeYeRM0jm", "sid": 3, "sentence": "The paper is clearly written, and the proposed architecture has too cool properties: it\u2019s compact enough to be used for image compression; and it doesn\u2019t overfit thus making early stopping notnesesary (which was crucial for the original DIP model)."}, {"text_id": "BJeYeRM0jm", "sid": 4, "sentence": "I have two main concerns about this paper."}, {"text_id": "BJeYeRM0jm", "sid": 5, "sentence": "First, it is somewhat misleading about its contributions: it's not obvious from abstract/introduction that the whole model is the same as DIP except for the proposed architecture."}, {"text_id": "BJeYeRM0jm", "sid": 6, "sentence": "Specifically, the first contribution listed in the introduction makes it look like this paper introduces the idea of not learning the decoder on the dataset (the one that starts with \u201cThe network is not learned and itself incorporates all assumptions on the data.\u201d)."}, {"text_id": "BJeYeRM0jm", "sid": 7, "sentence": "My second concern is about the theoretical contribution."}, {"text_id": "BJeYeRM0jm", "sid": 8, "sentence": "On the one hand, I enjoyed the angle the authors tackled proving that the network architecture is underparameterized enough to be a good model for denoising."}, {"text_id": "BJeYeRM0jm", "sid": 9, "sentence": "On the other hand, the obtained results are very weak: only one layered version of the paper is analysed and the theorem applies only to networks with less than some threshold of parameters."}, {"text_id": "BJeYeRM0jm", "sid": 10, "sentence": "Roughly, the theorem states that if for example we fix any matrix B of size e.g. 256 x k and matrix U of size 512 x 256 and then compute U relu(B C) where C is the vector of parameters of size k x 1, AND if k < 2.5 (i.e. if we use at most 2 parameters), then it would be very hard to fit 512 iid gaussian values (i.e. min_C ||U relu(B C) - eta|| where eta ~ N(0, 1))."}, {"text_id": "BJeYeRM0jm", "sid": 11, "sentence": "This restriction of the number of parameters to be small is only mentioned in the theorem itself, not in the discussion of its implications."}, {"text_id": "BJeYeRM0jm", "sid": 12, "sentence": "Also, the theorem only applies to the iid noise, while most natural noise patterns have structure (e.g. JPEG artifacts, broken pixels, etc) and thus can probably be better approximated with deep models."}, {"text_id": "BJeYeRM0jm", "sid": 13, "sentence": "Since the paper manages to use very few parameters (BTW, how many parameters in total do you have? Can you please add this number to the text?), it would be cool to see if second order methods like LBFGS can be applied here."}, {"text_id": "BJeYeRM0jm", "sid": 14, "sentence": "Some less important points:"}, {"text_id": "BJeYeRM0jm", "sid": 15, "sentence": "Fig 4 is very confusing."}, {"text_id": "BJeYeRM0jm", "sid": 16, "sentence": "First, it doesn\u2019t label the X axis."}, {"text_id": "BJeYeRM0jm", "sid": 17, "sentence": "Second, the caption mentions that early stopping is beneficial for the proposed method, but I can\u2019t see it from the figure."}, {"text_id": "BJeYeRM0jm", "sid": 18, "sentence": "Third, I don\u2019t get what is plotted on different subplots."}, {"text_id": "BJeYeRM0jm", "sid": 19, "sentence": "The text mentions that (a) is fitting the noisy image, (b) is fitting the noiseless image, and (c) is fitting noise. Is it all done independently with three different models?"}, {"text_id": "BJeYeRM0jm", "sid": 20, "sentence": "Then why does the figure says test and train loss? And why DIP loss goes up, it should be able to fit anything, right? If not and it\u2019s a single model that gets fitted on the noisy image and tested on the noiseless image, then how can you estimate the level of noise fitting? ||G(C) - eta|| should be high if G(C) ~= x."}, {"text_id": "BJeYeRM0jm", "sid": 21, "sentence": "Also, in this quote \u201cIn Fig. 4(a) we plot the Mean Squared Error (MSE) over the number of iterations of the optimizer for fitting the noisy astronaut image x + \u03b7 (i.e., FORMULA ...\u201d the formula doesn\u2019t correspond to the text."}, {"text_id": "BJeYeRM0jm", "sid": 22, "sentence": "And finally, the discussion of this figure makes claims about the behaviour of the model that seems to be too strong to be based on a single image experiment."}, {"text_id": "BJeYeRM0jm", "sid": 23, "sentence": "I don\u2019t get the details of the batch normalization used: with respect to which axis the mean and variance are computed?"}, {"text_id": "BJeYeRM0jm", "sid": 24, "sentence": "The authors claim that the model is not convolutional."}, {"text_id": "BJeYeRM0jm", "sid": 25, "sentence": "But first, it\u2019s not obvious why this would be a good thing (or a bad thing for that matter)"}, {"text_id": "BJeYeRM0jm", "sid": 26, "sentence": "."}, {"text_id": "BJeYeRM0jm", "sid": 27, "sentence": "Second, it\u2019s not exactly correct (as noted in the paper itself): the architecture uses 1x1 convolutions and upsampling, which combined give a weak and underparametrized analog of convolutions."}, {"text_id": "BJeYeRM0jm", "sid": 28, "sentence": "> The deep decoder is a deep image model G: R N \u2192 R n, where N is the number of parameters of the model, and n is the output dimension, which is typically much larger than the number of parameters (N << n)."}, {"text_id": "BJeYeRM0jm", "sid": 29, "sentence": "I think it should be vice versa, N >> n"}, {"text_id": "BJeYeRM0jm", "sid": 30, "sentence": "The following footnote"}, {"text_id": "BJeYeRM0jm", "sid": 31, "sentence": "> Specifically, we took a deep decoder G with d = 6 layers and output dimension 512\u00d7512\u00d73, and choose k = 64 and k = 128 for the respective compression ratios."}, {"text_id": "BJeYeRM0jm", "sid": 32, "sentence": "Uses unintroduced (at that point) notation and is very confusing."}, {"text_id": "BJeYeRM0jm", "sid": 33, "sentence": "It would be nice to have a version of Figure 6 with k = 6, so that one can see all feature maps (in contrast to a subset of them)."}, {"text_id": "BJeYeRM0jm", "sid": 34, "sentence": "I\u2019m also wondering, is it harder to optimize the proposed architecture compared to DIP?"}, {"text_id": "BJeYeRM0jm", "sid": 35, "sentence": "The literature on distillation indicates that overparameterization can be beneficial for convergence and final performance."}], "reviewlabels": [{"text_id": "BJeYeRM0jm", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 3, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 4, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 5, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 7, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 8, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 9, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 10, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 11, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 12, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 13, "labels": {"coarse": "Request", "fine": "Request.Clarification", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 14, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 15, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 16, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 17, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 18, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 19, "labels": {"coarse": "Request", "fine": "Request.Clarification", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 20, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 21, "labels": {"coarse": "Request", "fine": "Request.Clarification", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 22, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 23, "labels": {"coarse": "Request", "fine": "Request.Clarification", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 24, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 25, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "BJeYeRM0jm", "sid": 26, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "BJeYeRM0jm", "sid": 27, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 28, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 29, "labels": {"coarse": "Request", "fine": "Request.Typo", "asp": "Other", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 30, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 31, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 32, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 33, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 34, "labels": {"coarse": "Request", "fine": "Request.Clarification", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeYeRM0jm", "sid": 35, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "r1gzyKy_a7", "sid": 0, "sentence": "Many thanks for the detailed review!"}, {"text_id": "r1gzyKy_a7", "sid": 1, "sentence": "Main comments:"}, {"text_id": "r1gzyKy_a7", "sid": 2, "sentence": "1/ The DIP approach critically relies on regularization in order to make the method work (both by adding random noise in each optimization step to the input, as well as early stopping)."}, {"text_id": "r1gzyKy_a7", "sid": 3, "sentence": "As the first reviewer noted ``In fact, the DIP of Ulyanov et al. can hardly be considered \"a model\" (or a prior, for that matter), and instead should be considered \"an algorithm\", since it relies on the early stopping of a specific optimization algorithm''."}, {"text_id": "r1gzyKy_a7", "sid": 4, "sentence": "However we follow the reviewers' suggestion and made clear that the idea to use a deep network without learning as an image model is not new and rewrote the item to ``The network itself acts as a natural data model.  Not only does the network require no training (just as the DIP); it also does not critically rely on regularization, for example by early stopping (in contrast to the DIP).''"}, {"text_id": "r1gzyKy_a7", "sid": 5, "sentence": "Before that, in the introduction, in the original and revised version, we have a paragraph devoted to the DIP explaining that Ulyanov et al. introduced the idea of using a deep neural network without learning as an image model."}, {"text_id": "r1gzyKy_a7", "sid": 6, "sentence": "2/ Regarding the theoretical contribution: We fully agree that a limitation of the theorem is that it pertains to a one layered version of the decoder."}, {"text_id": "r1gzyKy_a7", "sid": 7, "sentence": "We are currently extending this to the multilayer case, but still have to address a technical difficulty in counting the number of different sign pattern matrices."}, {"text_id": "r1gzyKy_a7", "sid": 8, "sentence": "Regarding the assumptions: The proposition uses the assumption that k^2 log(n_0)  / n <= 1/32."}, {"text_id": "r1gzyKy_a7", "sid": 9, "sentence": "Here, the constant 1/32 is not optimal."}, {"text_id": "r1gzyKy_a7", "sid": 10, "sentence": "k^2 is essentially the number of parameters of the model, and n is the output dimension."}, {"text_id": "r1gzyKy_a7", "sid": 11, "sentence": "The proposition is only interesting if k^2 log(n_0)  / n <= 1/20 even without this assumption (due to the right hand side of the lower bound) therefore this assumption is not restrictive."}, {"text_id": "r1gzyKy_a7", "sid": 12, "sentence": "The bound is applicable if the number of parameters, k^2 is smaller than a logarithmic term times the number of output parameters, i.e., it allows the number of parameters to scale almost linearly in the output dimension."}, {"text_id": "r1gzyKy_a7", "sid": 13, "sentence": "This is the regime in which the deep decoder operates throughout the paper."}, {"text_id": "r1gzyKy_a7", "sid": 14, "sentence": "We agree that many natural noise patterns have structure, and that those can be better approximated with deep models, and are thus more difficult to remove."}, {"text_id": "r1gzyKy_a7", "sid": 15, "sentence": "3/ We have added the sentence ``In the default architectures with $d=6$ and $k=64$ or $k=128$, we have that N = 25,536 (for k=64) and N = 100,224 (k=128)"}, {"text_id": "r1gzyKy_a7", "sid": 16, "sentence": "out of an RGB image space of dimensionality 512\\times512\\times3=786,432 parameters.'' to specify the number of parameters."}, {"text_id": "r1gzyKy_a7", "sid": 17, "sentence": "Thanks for the suggestion to try second order method like LBFGS; we have tried LBFGS as a response to the reviewer's comment."}, {"text_id": "r1gzyKy_a7", "sid": 18, "sentence": "It converges in significantly fewer iterations, but each iterations is so much more expensive that overall it optimizes slower than ADAM or gradient descent."}, {"text_id": "r1gzyKy_a7", "sid": 19, "sentence": "Minor comments:"}, {"text_id": "r1gzyKy_a7", "sid": 20, "sentence": "1/ Figure 4: We have added labels and the sentence ``Early stopping can mildly enhance the performance of DD; to see this note that in panel (a), the minimum is obtained at around 5000 iterations and not at 50,000.'' in the caption to clarify."}, {"text_id": "r1gzyKy_a7", "sid": 21, "sentence": "Also, we have added the sentence ``Models are fitted independently for the noisy image, the noiseless image, and the noise.'', and rewrote the paragraph"}, {"text_id": "r1gzyKy_a7", "sid": 22, "sentence": "Thanks for pointing this out!"}, {"text_id": "r1gzyKy_a7", "sid": 23, "sentence": "We agree that here we present only results for one image, but we did carry out simulations for many images, and those plots are qualitatively the same for all the images considered."}, {"text_id": "r1gzyKy_a7", "sid": 24, "sentence": "Thus our conclusions about the model do not only hold for one image."}, {"text_id": "r1gzyKy_a7", "sid": 25, "sentence": "2/ Normalization is applied channel wise."}, {"text_id": "r1gzyKy_a7", "sid": 26, "sentence": "Let z{ij} be the j-th column in the i-th layer."}, {"text_id": "r1gzyKy_a7", "sid": 27, "sentence": "Then z{ij} is normalized independently of any of the other channels."}, {"text_id": "r1gzyKy_a7", "sid": 28, "sentence": "3/ We have reworded the corresponding paragraphs to make clear that while we do not use convolutions, and thus this is not strictly speaking a convolutional neural network, it shares many structural similarities with a conventional neural network, as pointed out by the reviewer."}, {"text_id": "r1gzyKy_a7", "sid": 29, "sentence": "4/ The equation is correct in that the parameter choices in the paper are such that the deep decoder has much fewer model parameters N than its output dimension. Thus N is much less than n."}, {"text_id": "r1gzyKy_a7", "sid": 30, "sentence": "5/ We agree that it is not optimal to use unintroduced notation at this point, but we made this compromise so that we can illustrate the performance of the deep decoder without introducing its details, but wanted to give a reader the chance to later see exactly what parameters we used."}, {"text_id": "r1gzyKy_a7", "sid": 31, "sentence": "6/ Unfortunately choosing k=6 is too small to have a small representation error, i.e., to represent the image well."}, {"text_id": "r1gzyKy_a7", "sid": 32, "sentence": "We have, however not hand-selected the 8 images shown out of the 64, and the other 64-8 images look very similar."}, {"text_id": "r1gzyKy_a7", "sid": 33, "sentence": "We have all the images in the jupyter notebook that comes with the paper."}, {"text_id": "r1gzyKy_a7", "sid": 34, "sentence": "7/ Great question, it is faster to optimize the deep decoder since the adam/SGD steps are cheaper, but it indeed seems to require slightly more iterations for best performance than the DIP."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "r1gzyKy_a7", "sid": 0}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "r1gzyKy_a7", "sid": 1}, {"labels": {"alignments": [5, 6], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gzyKy_a7", "sid": 2}, {"labels": {"alignments": [5, 6], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gzyKy_a7", "sid": 3}, {"labels": {"alignments": [5, 6], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gzyKy_a7", "sid": 4}, {"labels": {"alignments": [5, 6], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gzyKy_a7", "sid": 5}, {"labels": {"alignments": [7, 8, 9], "responsetype": "concede-criticism", "coarseresponse": "concur"}, "text_id": "r1gzyKy_a7", "sid": 6}, {"labels": {"alignments": [7, 8, 9], "responsetype": "concede-criticism", "coarseresponse": "concur"}, "text_id": "r1gzyKy_a7", "sid": 7}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gzyKy_a7", "sid": 8}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gzyKy_a7", "sid": 9}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gzyKy_a7", "sid": 10}, {"labels": {"alignments": [10, 11], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gzyKy_a7", "sid": 11}, {"labels": {"alignments": [11], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gzyKy_a7", "sid": 12}, {"labels": {"alignments": [11], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gzyKy_a7", "sid": 13}, {"labels": {"alignments": [12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gzyKy_a7", "sid": 14}, {"labels": {"alignments": [13], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "r1gzyKy_a7", "sid": 15}, {"labels": {"alignments": [13], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "r1gzyKy_a7", "sid": 16}, {"labels": {"alignments": [13], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "r1gzyKy_a7", "sid": 17}, {"labels": {"alignments": [13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gzyKy_a7", "sid": 18}, {"labels": {"alignments": [14], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "r1gzyKy_a7", "sid": 19}, {"labels": {"alignments": [15, 16, 17], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gzyKy_a7", "sid": 20}, {"labels": {"alignments": [15, 16, 17, 18, 19], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gzyKy_a7", "sid": 21}, {"labels": {"alignments": [15, 16, 17, 18, 19], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "r1gzyKy_a7", "sid": 22}, {"labels": {"alignments": [22], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "r1gzyKy_a7", "sid": 23}, {"labels": {"alignments": [22], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "r1gzyKy_a7", "sid": 24}, {"labels": {"alignments": [23], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gzyKy_a7", "sid": 25}, {"labels": {"alignments": [23], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gzyKy_a7", "sid": 26}, {"labels": {"alignments": [23], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gzyKy_a7", "sid": 27}, {"labels": {"alignments": [24, 25, 27], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "r1gzyKy_a7", "sid": 28}, {"labels": {"alignments": [28, 29], "responsetype": "reject-request_scope_No", "coarseresponse": "dispute"}, "text_id": "r1gzyKy_a7", "sid": 29}, {"labels": {"alignments": [31, 32], "responsetype": "concede-criticism", "coarseresponse": "concur"}, "text_id": "r1gzyKy_a7", "sid": 30}, {"labels": {"alignments": [33], "responsetype": "reject-request_scope_No", "coarseresponse": "dispute"}, "text_id": "r1gzyKy_a7", "sid": 31}, {"labels": {"alignments": [33], "responsetype": "reject-request_scope_No", "coarseresponse": "dispute"}, "text_id": "r1gzyKy_a7", "sid": 32}, {"labels": {"alignments": [33], "responsetype": "reject-request_scope_No", "coarseresponse": "dispute"}, "text_id": "r1gzyKy_a7", "sid": 33}, {"labels": {"alignments": [34, 35], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gzyKy_a7", "sid": 34}], "metadata": {"anno": "anno13", "review": "BJeYeRM0jm", "rebuttal": "r1gzyKy_a7", "conference": "ICLR2019", "title": "Deep Decoder: Concise Image Representations from Untrained Non-convolutional Networks", "reviewer": "AnonReviewer1", "forum_id": "rylV-2C9KQ", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}}