{"review": [{"text_id": "HJxl4O3AYB", "sid": 0, "sentence": "The paper proposes to use the triplet loss as a convex relaxation of the ordinal embedding problem."}, {"text_id": "HJxl4O3AYB", "sid": 1, "sentence": "The loss is solved using feed-forward neural network with the input to the network being the ids of the items encoded in binary codes."}, {"text_id": "HJxl4O3AYB", "sid": 2, "sentence": "The benefit of using a deep network is to exploit its optimization capability and the parallelism on GPUs."}, {"text_id": "HJxl4O3AYB", "sid": 3, "sentence": "The experiments presented in the paper include a set of simulation experiments and a real-world task."}, {"text_id": "HJxl4O3AYB", "sid": 4, "sentence": "I am giving a score of 3."}, {"text_id": "HJxl4O3AYB", "sid": 5, "sentence": "This work is an interesting application of deep learning, but it gives little insight as to why deep networks are able to solve the problem and how to solve ordinal embedding itself."}, {"text_id": "HJxl4O3AYB", "sid": 6, "sentence": "To elaborate, the problem is known to be NP-hard in the worst case, while the data sets used in the paper seem to have certain nice properties."}, {"text_id": "HJxl4O3AYB", "sid": 7, "sentence": "It would be interesting to see how deep networks do for the hard cases."}, {"text_id": "HJxl4O3AYB", "sid": 8, "sentence": "It would also be interesting to see if additional assumptions, such as the existence of clusters or separation between clusters, make ordinal embedding simpler and thus tractable."}, {"text_id": "HJxl4O3AYB", "sid": 9, "sentence": "Another approach is to assume the solution to have low surrogate loss (4), and any convex solver with sufficiently large number of points is able to find such a solution."}, {"text_id": "HJxl4O3AYB", "sid": 10, "sentence": "Then the question becomes how deep networks solve the particular convex optimization problem."}, {"text_id": "HJxl4O3AYB", "sid": 11, "sentence": "Thinking along these directions would bring more insight and impact to both the ordinal embedding problem and optimization in deep networks."}, {"text_id": "HJxl4O3AYB", "sid": 12, "sentence": "one quick question:"}, {"text_id": "HJxl4O3AYB", "sid": 13, "sentence": "equations (3) and (4)"}, {"text_id": "HJxl4O3AYB", "sid": 14, "sentence": "--> isn't this the same as using the hinge loss to bound the zero-one loss?"}], "reviewlabels": [{"text_id": "HJxl4O3AYB", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJxl4O3AYB", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJxl4O3AYB", "sid": 2, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJxl4O3AYB", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJxl4O3AYB", "sid": 4, "labels": {"coarse": "Social", "fine": "Social", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJxl4O3AYB", "sid": 5, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJxl4O3AYB", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJxl4O3AYB", "sid": 7, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJxl4O3AYB", "sid": 8, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJxl4O3AYB", "sid": 9, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJxl4O3AYB", "sid": 10, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJxl4O3AYB", "sid": 11, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJxl4O3AYB", "sid": 12, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJxl4O3AYB", "sid": 13, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJxl4O3AYB", "sid": 14, "labels": {"coarse": "Request", "fine": "Request.Clarification", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "SJgNYnkcsS", "sid": 0, "sentence": "We would like to thank the reviewer for their feedback."}, {"text_id": "SJgNYnkcsS", "sid": 1, "sentence": "We address each comment below individually with appropriate headings."}, {"text_id": "SJgNYnkcsS", "sid": 2, "sentence": "- Summary"}, {"text_id": "SJgNYnkcsS", "sid": 3, "sentence": "We would like to point out that the reviewer in the summary incorrectly described that our approach uses the \"triplet loss as a convex relaxation of the ordinal embedding problem\"."}, {"text_id": "SJgNYnkcsS", "sid": 4, "sentence": "Using the triplet loss as a proxy does not make the problem convex."}, {"text_id": "SJgNYnkcsS", "sid": 5, "sentence": "- The relation between data distribution and hardness of ordinal embedding"}, {"text_id": "SJgNYnkcsS", "sid": 6, "sentence": "Ordinal embedding is NP-hard independent of the data distribution."}, {"text_id": "SJgNYnkcsS", "sid": 7, "sentence": "The paper \u201cLandscape of non-convex quadratic feasibility\u201d (Bower et al. 2018) can shed more light on this."}, {"text_id": "SJgNYnkcsS", "sid": 8, "sentence": "The equation (1) in this paper rephrases the ordinal embedding problem as a homogeneous quadratic feasibility problem."}, {"text_id": "SJgNYnkcsS", "sid": 9, "sentence": "The constraint matrices of the problem (P_i in the paper), which correspond to the triplet inequalities, are all indefinite which makes the whole optimization NP-hard."}, {"text_id": "SJgNYnkcsS", "sid": 10, "sentence": "Moreover, many of our experiments in this paper feature the uniform distribution, which does not satisfy any nice structural assumptions."}, {"text_id": "SJgNYnkcsS", "sid": 11, "sentence": "- Using a convex solver"}, {"text_id": "SJgNYnkcsS", "sid": 12, "sentence": "As we pointed out earlier, using the triplet loss does not make the optimization problem convex and hence using a convex solver would not be possible here."}, {"text_id": "SJgNYnkcsS", "sid": 13, "sentence": "- \u201cEquations (3) and (4):  isn't this the same as using the hinge loss to bound the zero-one loss?\u201d"}, {"text_id": "SJgNYnkcsS", "sid": 14, "sentence": "Yes, that is true."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "SJgNYnkcsS", "sid": 0}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJgNYnkcsS", "sid": 1}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJgNYnkcsS", "sid": 2}, {"labels": {"alignments": [0], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "SJgNYnkcsS", "sid": 3}, {"labels": {"alignments": [0], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "SJgNYnkcsS", "sid": 4}, {"labels": {"alignments": [6], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJgNYnkcsS", "sid": 5}, {"labels": {"alignments": [6], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJgNYnkcsS", "sid": 6}, {"labels": {"alignments": [6], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJgNYnkcsS", "sid": 7}, {"labels": {"alignments": [6], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJgNYnkcsS", "sid": 8}, {"labels": {"alignments": [6, 7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJgNYnkcsS", "sid": 9}, {"labels": {"alignments": [6, 7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJgNYnkcsS", "sid": 10}, {"labels": {"alignments": [10, 11], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJgNYnkcsS", "sid": 11}, {"labels": {"alignments": [10, 11], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJgNYnkcsS", "sid": 12}, {"labels": {"alignments": [13, 14], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJgNYnkcsS", "sid": 13}, {"labels": {"alignments": [13, 14], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJgNYnkcsS", "sid": 14}], "metadata": {"anno": "anno3", "review": "HJxl4O3AYB", "rebuttal": "SJgNYnkcsS", "conference": "ICLR2020", "title": "LARGE SCALE REPRESENTATION LEARNING FROM TRIPLET COMPARISONS", "reviewer": "AnonReviewer1", "forum_id": "rklhqkHFDB", "rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area."}}