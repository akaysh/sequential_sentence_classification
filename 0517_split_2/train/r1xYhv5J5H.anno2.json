{"review": [{"text_id": "r1xYhv5J5H", "sid": 0, "sentence": "This paper points out that the traditional way of model selection is flawed due to that the validation/test set is often small."}, {"text_id": "r1xYhv5J5H", "sid": 1, "sentence": "The authors also attribute the existence of adversarial examples to the small validation/test set, which I agree to some degree."}, {"text_id": "r1xYhv5J5H", "sid": 2, "sentence": "Hence, the authors proposed an alternative approach to comparing different classification models by the notion of inter-model discrepancy."}, {"text_id": "r1xYhv5J5H", "sid": 3, "sentence": "The main idea is reasonable, but it requires that the models to compare all perform reasonably well."}, {"text_id": "r1xYhv5J5H", "sid": 4, "sentence": "Otherwise, some poorly performed models could lead to near-random or adversarial inter-model discrepancies, failing the proposed approach."}, {"text_id": "r1xYhv5J5H", "sid": 5, "sentence": "Another potential issue is that the proposed approach cannot handle training set bias. If all models are biased in similar ways (e.g., toward a particular class or domain), they will not reveal informative discrepancies for the images over which they all make similar mistakes."}, {"text_id": "r1xYhv5J5H", "sid": 6, "sentence": "Another question which is not answered in the paper is the number $k$ of images to select for each pair of classifiers. Is this number task-dependent? Is it related to the number of classes?"}, {"text_id": "r1xYhv5J5H", "sid": 7, "sentence": "What is a general guideline for one to choose this number $k$ given a new application scenario?"}, {"text_id": "r1xYhv5J5H", "sid": 8, "sentence": "The unlabeled set is not \"unlabeled\" in essence. If my understanding was correct, it cannot contain open-set images which do not belong to any of the classes of interest."}, {"text_id": "r1xYhv5J5H", "sid": 9, "sentence": "It is also nontrivial to control that the images contain only one salient object per image."}, {"text_id": "r1xYhv5J5H", "sid": 10, "sentence": "Hence, while I agree with the authors that existing approaches to comparing deep neural network classifiers could be improved, I think the proposed solution is not a good alternative yet."}], "reviewlabels": [{"text_id": "r1xYhv5J5H", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1xYhv5J5H", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1xYhv5J5H", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1xYhv5J5H", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1xYhv5J5H", "sid": 4, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1xYhv5J5H", "sid": 5, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1xYhv5J5H", "sid": 6, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1xYhv5J5H", "sid": 7, "labels": {"coarse": "Request", "fine": "Request.Clarification", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1xYhv5J5H", "sid": 8, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1xYhv5J5H", "sid": 9, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1xYhv5J5H", "sid": 10, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "BJgfCUWlsB", "sid": 0, "sentence": "Regarding comment 1: Thanks for recognizing the merit of our idea."}, {"text_id": "BJgfCUWlsB", "sid": 1, "sentence": "As also mentioned by Reviewer #2, the proposed MAD implicitly assumes that classifiers in the competition are reasonably accurate."}, {"text_id": "BJgfCUWlsB", "sid": 2, "sentence": "Otherwise, the selected counterexamples may be less meaningful."}, {"text_id": "BJgfCUWlsB", "sid": 3, "sentence": "We will make this assumption explicit in the revised manuscript."}, {"text_id": "BJgfCUWlsB", "sid": 4, "sentence": "From this perspective (and other reasons mentioned in the discussion section), MAD should be viewed as complementary to, rather than a replacement for, the conventional accuracy comparison for image classification."}, {"text_id": "BJgfCUWlsB", "sid": 5, "sentence": "When two classifiers perform at a reasonable level and achieve very close accuracy numbers (e.g., VGG16BN and ResNet34 on ImageNet validation set), MAD provides the most efficient way of differentiating the two models by maximizing their discrepancies over a large-scale image set."}, {"text_id": "BJgfCUWlsB", "sid": 6, "sentence": "We want to emphasize that MAD is especially useful on image classification tasks where most cutting-edge classifiers achieve very close performance."}, {"text_id": "BJgfCUWlsB", "sid": 7, "sentence": "In these situations, the MAD competition ranking, which is obtained by evaluating on corner examples searched from web-scale unlabeled dataset, is more convincing than something like 1% accuracy advantage on the validation set."}, {"text_id": "BJgfCUWlsB", "sid": 8, "sentence": "For problem domains where there are few sufficiently accurate models, we may still apply the underlying principle behind MAD to create adaptive test sets such that the strengths and weaknesses of the models are most easily revealed."}, {"text_id": "BJgfCUWlsB", "sid": 9, "sentence": "In those scenarios, we conjecture that we need increase k to a reasonably larger number, thus at the cost of efficiency."}, {"text_id": "BJgfCUWlsB", "sid": 10, "sentence": "Regarding comment 2: Thanks for the comment."}, {"text_id": "BJgfCUWlsB", "sid": 11, "sentence": "As long as two (or multiple) models differ (even in slightly different ways), MAD provides the highly efficient way of spotting such differences by exploring a large-scale unlabelled dataset."}, {"text_id": "BJgfCUWlsB", "sid": 12, "sentence": "However, these differences are less likely to be revealed using a fixed and small test set (i.e., they will probably have the same accuracy numbers as models to be compared are very similar and are biased in similar ways)."}, {"text_id": "BJgfCUWlsB", "sid": 13, "sentence": "For the extreme case that two models are exactly the same (i.e, they are biased in identical ways and make identical prediction errors), both MAD and traditional accuracy-based methods will draw the same conclusion - the two models have the same performance."}, {"text_id": "BJgfCUWlsB", "sid": 14, "sentence": "Accuracy-based evaluation methods arrive at this conclusion by comparing model predictions with ground truth labels and outputting the same accuracy numbers."}, {"text_id": "BJgfCUWlsB", "sid": 15, "sentence": "In contrast, MAD arrives at the same conclusion without any human labeling since the set S for subjective testing is empty."}, {"text_id": "BJgfCUWlsB", "sid": 16, "sentence": "So in this extreme case, both MAD and accuracy fail to compare those two models."}, {"text_id": "BJgfCUWlsB", "sid": 17, "sentence": "In summary, to reliably compare the relative performance of computational models, all evaluation methodologies (including MAD) rely on the assumption that the models to be compared should be diverse to a certain extent, and the proposed MAD makes this assumption more explicit."}, {"text_id": "BJgfCUWlsB", "sid": 18, "sentence": "In fact, MAD makes the best use of model discrepancies (even if models are biased in very similar but not identical ways) to rank the model performance."}, {"text_id": "BJgfCUWlsB", "sid": 19, "sentence": "As a matter of fact, based on our experiments, we find that state-of-the-art ImageNet classifiers do have their own biases. (See figure 8 in the appendix.)"}, {"text_id": "BJgfCUWlsB", "sid": 20, "sentence": "Regarding comment 3: Thanks for the excellent question."}, {"text_id": "BJgfCUWlsB", "sid": 21, "sentence": "We believe that the parameter k is task-dependent."}, {"text_id": "BJgfCUWlsB", "sid": 22, "sentence": "For problem domains where there are reasonably accurate models (e.g., imageNet classification in our example), we may obtain a stable ranking with a relative small k (e.g., k=15 in the imageNet classification example)."}, {"text_id": "BJgfCUWlsB", "sid": 23, "sentence": "For problem domains where there are no good models, we may increase k to the limit of human labeling budget in order to obtain reasonable performance comparison."}, {"text_id": "BJgfCUWlsB", "sid": 24, "sentence": "Regarding comment 4: Thanks for the comment."}, {"text_id": "BJgfCUWlsB", "sid": 25, "sentence": "In our current setting, we restrict the dataset D to the domain of interest that contain natural images of mainly 200 classes."}, {"text_id": "BJgfCUWlsB", "sid": 26, "sentence": "However, as the construction of D is noisy and coarse, D contains plenty of open-set images, which do not belong to any class of interest."}, {"text_id": "BJgfCUWlsB", "sid": 27, "sentence": "Since we do not perform any manually data screening at this stage, some of the open-set images may even be selected to construct the dataset S."}, {"text_id": "BJgfCUWlsB", "sid": 28, "sentence": "This means that although the selected open-set image is out of the domain of interest, the associated two classifiers make different, high-confident (with threshold set to 0.8), but incorrect predictions (Case III)."}, {"text_id": "BJgfCUWlsB", "sid": 29, "sentence": "As a result, we consider it as a strong counterexample of the two classifiers."}, {"text_id": "BJgfCUWlsB", "sid": 30, "sentence": "Note that this situation rarely happens, at least in our experiments because the competing classifiers tend to give open-set images low-confidence, and therefore are automatically filtered out."}, {"text_id": "BJgfCUWlsB", "sid": 31, "sentence": "We agree with the reviewer that selecting images that contain only one salient object requires a lot of human effort."}, {"text_id": "BJgfCUWlsB", "sid": 32, "sentence": "So we did not eliminate Case I. It turns out that keeping Case I does not seem to affect the comparison and analysis of competing models."}], "rebuttallabels": [{"labels": {"alignments": [3, 4], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "BJgfCUWlsB", "sid": 0}, {"labels": {"alignments": [3, 4], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgfCUWlsB", "sid": 1}, {"labels": {"alignments": [3, 4], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgfCUWlsB", "sid": 2}, {"labels": {"alignments": [3, 4], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "BJgfCUWlsB", "sid": 3}, {"labels": {"alignments": [3, 4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgfCUWlsB", "sid": 4}, {"labels": {"alignments": [3, 4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgfCUWlsB", "sid": 5}, {"labels": {"alignments": [3, 4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgfCUWlsB", "sid": 6}, {"labels": {"alignments": [3, 4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgfCUWlsB", "sid": 7}, {"labels": {"alignments": [3, 4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgfCUWlsB", "sid": 8}, {"labels": {"alignments": [3, 4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgfCUWlsB", "sid": 9}, {"labels": {"alignments": [5], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "BJgfCUWlsB", "sid": 10}, {"labels": {"alignments": [5], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgfCUWlsB", "sid": 11}, {"labels": {"alignments": [5], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgfCUWlsB", "sid": 12}, {"labels": {"alignments": [5], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgfCUWlsB", "sid": 13}, {"labels": {"alignments": [5], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgfCUWlsB", "sid": 14}, {"labels": {"alignments": [5], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgfCUWlsB", "sid": 15}, {"labels": {"alignments": [5], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJgfCUWlsB", "sid": 16}, {"labels": {"alignments": [5], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "BJgfCUWlsB", "sid": 17}, {"labels": {"alignments": [5], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "BJgfCUWlsB", "sid": 18}, {"labels": {"alignments": [5], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "BJgfCUWlsB", "sid": 19}, {"labels": {"alignments": [6, 7], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "BJgfCUWlsB", "sid": 20}, {"labels": {"alignments": [6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgfCUWlsB", "sid": 21}, {"labels": {"alignments": [6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgfCUWlsB", "sid": 22}, {"labels": {"alignments": [6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgfCUWlsB", "sid": 23}, {"labels": {"alignments": [8, 9], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "BJgfCUWlsB", "sid": 24}, {"labels": {"alignments": [8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgfCUWlsB", "sid": 25}, {"labels": {"alignments": [8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgfCUWlsB", "sid": 26}, {"labels": {"alignments": [8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgfCUWlsB", "sid": 27}, {"labels": {"alignments": [8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgfCUWlsB", "sid": 28}, {"labels": {"alignments": [8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgfCUWlsB", "sid": 29}, {"labels": {"alignments": [8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgfCUWlsB", "sid": 30}, {"labels": {"alignments": [8, 9], "responsetype": "concede-criticism", "coarseresponse": "concur"}, "text_id": "BJgfCUWlsB", "sid": 31}, {"labels": {"alignments": [8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJgfCUWlsB", "sid": 32}], "metadata": {"anno": "anno2", "review": "r1xYhv5J5H", "rebuttal": "BJgfCUWlsB", "conference": "ICLR2020", "title": "I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively", "reviewer": "AnonReviewer1", "forum_id": "rJehNT4YPr", "rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years."}}