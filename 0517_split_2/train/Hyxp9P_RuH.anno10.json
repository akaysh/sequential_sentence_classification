{"review": [{"text_id": "Hyxp9P_RuH", "sid": 0, "sentence": "###Summary###"}, {"text_id": "Hyxp9P_RuH", "sid": 1, "sentence": "This paper tackles the multi-source domain adaptation by aggregate multiple source domains dynamically during the training phase."}, {"text_id": "Hyxp9P_RuH", "sid": 2, "sentence": "The observation is that in many real-world applications, we want to exploit multiple source datasets of similar tasks to learn a model for a different but related target datasets."}, {"text_id": "Hyxp9P_RuH", "sid": 3, "sentence": "Firstly, the paper derives a multiple-source domain adaptation upper-bound from single-to-single domain adaptation generalization bound, based on the theoretical work from Cortes et al (2019)."}, {"text_id": "Hyxp9P_RuH", "sid": 4, "sentence": "The idea is similar to Zhao et al (2019), which introduces a weighted parameter \\alpha to combine the source domains together."}, {"text_id": "Hyxp9P_RuH", "sid": 5, "sentence": "Secondly, based on the theoretical result, the paper proposes an algorithm to minimize the upper bound of the theoretical result."}, {"text_id": "Hyxp9P_RuH", "sid": 6, "sentence": "The upper bound can be simplified as the quartic form (Eq. 4) and can be optimized with the Lagrangian form."}, {"text_id": "Hyxp9P_RuH", "sid": 7, "sentence": "Since no closed-form expression for the optimal v can be derived, the authors propose to use binary search to find it."}, {"text_id": "Hyxp9P_RuH", "sid": 8, "sentence": "Based on the theoretical results and the algorithm, the paper introduces Domain AggRegation Network (DARN), which contains a base network for feature extraction, h_y to minimize the task loss and h_d to evaluate the discrepancy between each source domain and target domain."}, {"text_id": "Hyxp9P_RuH", "sid": 9, "sentence": "The loss is aggregation with the parameter \\alpha."}, {"text_id": "Hyxp9P_RuH", "sid": 10, "sentence": "Finally, the paper conduct experiments on sentimental analysis benchmark, Amazon Review and digit datasets."}, {"text_id": "Hyxp9P_RuH", "sid": 11, "sentence": "The paper selects MDAN, DANN, MDMN as the baselines."}, {"text_id": "Hyxp9P_RuH", "sid": 12, "sentence": "On the amazon review dataset, the performance of the proposed DARN model is comparable with the MDMN baseline."}, {"text_id": "Hyxp9P_RuH", "sid": 13, "sentence": "On the digit dataset, the model can outperform the baselines."}, {"text_id": "Hyxp9P_RuH", "sid": 14, "sentence": "### Novelty ##"}, {"text_id": "Hyxp9P_RuH", "sid": 15, "sentence": "#"}, {"text_id": "Hyxp9P_RuH", "sid": 16, "sentence": "The theoretical results in this paper are extended from Cortes et al (2019) and Zhao et al (2018)."}, {"text_id": "Hyxp9P_RuH", "sid": 17, "sentence": "Thus, the theoretical contribution of this paper is limited."}, {"text_id": "Hyxp9P_RuH", "sid": 18, "sentence": "The algorithm proposed in this paper is interesting."}, {"text_id": "Hyxp9P_RuH", "sid": 19, "sentence": "However, the motivation of the proposed method is to minimize the upper bound, not the loss itself, i.e. L_T(h, f_T)."}, {"text_id": "Hyxp9P_RuH", "sid": 20, "sentence": "Intuitively, when the upper bound of the loss is minimized, it will be beneficial to minimize the loss itself."}, {"text_id": "Hyxp9P_RuH", "sid": 21, "sentence": "But it's not guaranteed as the upper bound contains other variables, such as the number of training samples and model complexity."}, {"text_id": "Hyxp9P_RuH", "sid": 22, "sentence": "If the training samples and model complexity (think about the parameters in the deep models) are significantly large, the upper bound of the loss might be also very large."}, {"text_id": "Hyxp9P_RuH", "sid": 23, "sentence": "As for the experimental results, the paper only provides results on the sentimental analysis results and digit datasets, which are small benchmarks."}, {"text_id": "Hyxp9P_RuH", "sid": 24, "sentence": "The selected baselines are not sufficient."}, {"text_id": "Hyxp9P_RuH", "sid": 25, "sentence": "The improvement from the baselines is also limited."}, {"text_id": "Hyxp9P_RuH", "sid": 26, "sentence": "###Clarity##"}, {"text_id": "Hyxp9P_RuH", "sid": 27, "sentence": "#"}, {"text_id": "Hyxp9P_RuH", "sid": 28, "sentence": "Overall, the paper is well organized and logically clear."}, {"text_id": "Hyxp9P_RuH", "sid": 29, "sentence": "The images are well-presented and well-explained by the captions and the text."}, {"text_id": "Hyxp9P_RuH", "sid": 30, "sentence": "The derivation of the algorithm in Sec 3.2 is logically clear and easy to follow."}, {"text_id": "Hyxp9P_RuH", "sid": 31, "sentence": "###Pros#"}, {"text_id": "Hyxp9P_RuH", "sid": 32, "sentence": "##"}, {"text_id": "Hyxp9P_RuH", "sid": 33, "sentence": "1) The paper proposes a new theoretical upper-bound based on the prior works, the upper-bound and its derivation are interesting and heuristic to the domain adaptation research community."}, {"text_id": "Hyxp9P_RuH", "sid": 34, "sentence": "2) The paper is applicable to many practical scenarios since the data from the real-world application is typically collected from multiple sources."}, {"text_id": "Hyxp9P_RuH", "sid": 35, "sentence": "3) The paper is overall well-organized and well-written."}, {"text_id": "Hyxp9P_RuH", "sid": 36, "sentence": "The claims of the paper are verified by the experimental results."}, {"text_id": "Hyxp9P_RuH", "sid": 37, "sentence": "##"}, {"text_id": "Hyxp9P_RuH", "sid": 38, "sentence": "#Cons#"}, {"text_id": "Hyxp9P_RuH", "sid": 39, "sentence": "##"}, {"text_id": "Hyxp9P_RuH", "sid": 40, "sentence": "1) The critical issue of this paper is that the algorithm is designed to minimize the upper bound."}, {"text_id": "Hyxp9P_RuH", "sid": 41, "sentence": "The idea is intuitive when the upper bound is small."}, {"text_id": "Hyxp9P_RuH", "sid": 42, "sentence": "However, the proposed upper bound in the paper involves other parameters, such as the model complexity and the number of training samples."}, {"text_id": "Hyxp9P_RuH", "sid": 43, "sentence": "It's an intuitive idea to weight different source domains in multi-source domain adaptation."}, {"text_id": "Hyxp9P_RuH", "sid": 44, "sentence": "The paper derives the weight by the Lagrangian form to minimize the upper bound."}, {"text_id": "Hyxp9P_RuH", "sid": 45, "sentence": "While another trivial trick is to evaluate \\alpha by the domain closeness between each source domain with the target domain."}, {"text_id": "Hyxp9P_RuH", "sid": 46, "sentence": "2) The experimental results provided in this paper are weak."}, {"text_id": "Hyxp9P_RuH", "sid": 47, "sentence": "In the abstract and introduction"}, {"text_id": "Hyxp9P_RuH", "sid": 48, "sentence": ",  the paper motivates the multi-source domain adaptation (MSDA) problem by arguing that the MSDA has a lot of real applications."}, {"text_id": "Hyxp9P_RuH", "sid": 49, "sentence": "But the paper only provides empirical results on sentimental analysis and digit recognition."}, {"text_id": "Hyxp9P_RuH", "sid": 50, "sentence": "Besides, the results on the sentimental analysis are comparable with the compared baselines."}, {"text_id": "Hyxp9P_RuH", "sid": 51, "sentence": "It will be also interesting to see how does the proposed method perform on large-scale datasets such as DomainNet and Office-Home dataset:"}, {"text_id": "Hyxp9P_RuH", "sid": 52, "sentence": "DomainNet: Moment Matching for Multi-Source Domain Adaptation, ICCV 2019."}, {"text_id": "Hyxp9P_RuH", "sid": 53, "sentence": "http://ai.bu.edu/DomainNet/"}, {"text_id": "Hyxp9P_RuH", "sid": 54, "sentence": "Office-Home: Deep Hashing Network for Unsupervised Domain Adaptation, CVPR 2017."}, {"text_id": "Hyxp9P_RuH", "sid": 55, "sentence": "http://hemanthdv.org/OfficeHome-Dataset/"}, {"text_id": "Hyxp9P_RuH", "sid": 56, "sentence": "3) The novelty of this paper is incremental as the theoretical results are extended from Cortes et al (2019) and Zhao et al (2018)."}, {"text_id": "Hyxp9P_RuH", "sid": 57, "sentence": "Based on the summary, cons, and pros, the current rating I am giving now is weak reject. I would like to discuss the final rating with other reviewers, ACs."}, {"text_id": "Hyxp9P_RuH", "sid": 58, "sentence": "To improve the rating, the author should explain the following questions:"}, {"text_id": "Hyxp9P_RuH", "sid": 59, "sentence": "1). Why minimizing the upper bound in this scenario would help to minimize the loss on the target domain, when the upper bound can be substantially huge? How about just evaluate \\alpha by the closeness of the source domain with the target domain?"}, {"text_id": "Hyxp9P_RuH", "sid": 60, "sentence": "2)"}, {"text_id": "Hyxp9P_RuH", "sid": 61, "sentence": "."}, {"text_id": "Hyxp9P_RuH", "sid": 62, "sentence": "In the introduction, the paper motivates the multi-source domain adaptation (MSDA) problem by arguing that the MSDA has a lot of real applications."}, {"text_id": "Hyxp9P_RuH", "sid": 63, "sentence": "While the experiments are only performed on sentimental analysis and digit recognition. How about evaluating the proposed methods on real image recognition such as DomainNet or Office-Home?"}], "reviewlabels": [{"text_id": "Hyxp9P_RuH", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 4, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 5, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 6, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 7, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 8, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 9, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 10, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 11, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 12, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 13, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 14, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "Hyxp9P_RuH", "sid": 15, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "Hyxp9P_RuH", "sid": 16, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 17, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 18, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 19, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 20, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 21, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 22, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 23, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 24, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 25, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 26, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "Hyxp9P_RuH", "sid": 27, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "Hyxp9P_RuH", "sid": 28, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 29, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 30, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 31, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "Hyxp9P_RuH", "sid": 32, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "Hyxp9P_RuH", "sid": 33, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 34, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Motivation/Impact", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 35, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 36, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 37, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "Hyxp9P_RuH", "sid": 38, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "Hyxp9P_RuH", "sid": 39, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "Hyxp9P_RuH", "sid": 40, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 41, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 42, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 43, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 44, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 45, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 46, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 47, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "Hyxp9P_RuH", "sid": 48, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "Hyxp9P_RuH", "sid": 49, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 50, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 51, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 52, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 53, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 54, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 55, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 56, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 57, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Other", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 58, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Other", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 59, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 60, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "Hyxp9P_RuH", "sid": 61, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "Hyxp9P_RuH", "sid": 62, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hyxp9P_RuH", "sid": 63, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "BkeUECAvsr", "sid": 0, "sentence": "Thank you for your thorough assessment and helpful comments! To answer your two questions:"}, {"text_id": "BkeUECAvsr", "sid": 1, "sentence": "1) Upper bound"}, {"text_id": "BkeUECAvsr", "sid": 2, "sentence": "You are right that it would be ideal to optimize the target loss L_T(h, f_T) directly."}, {"text_id": "BkeUECAvsr", "sid": 3, "sentence": "However, this is not possible because we do not have labelled target data (i.e., f_T is unknown)."}, {"text_id": "BkeUECAvsr", "sid": 4, "sentence": "Minimizing an upper bound is arguably the only viable option *with theoretical generalization guarantee*. It is a common practice in the domain adaptation community (Mansour et al., 2009a, 2009b; Ben-David et al. 2007, 2010; Cortes and Mohri, 2011), and it is essentially the key idea of PAC learning and generalization analysis (Gy\u00f6rfi et al., 2006; Sch\u00f6lkopf et al., 2002; Vapnik, 2013)."}, {"text_id": "BkeUECAvsr", "sid": 5, "sentence": "Besides, our method *directly* optimizes the upper bound without resorting to heuristics, unlike prior methods."}, {"text_id": "BkeUECAvsr", "sid": 6, "sentence": "Ref:"}, {"text_id": "BkeUECAvsr", "sid": 7, "sentence": "- Gy\u00f6rfi, L., Kohler, M., Krzyzak, A. and Walk, H., 2006. A distribution-free theory of nonparametric regression. Springer Science & Business Media."}, {"text_id": "BkeUECAvsr", "sid": 8, "sentence": "- Sch\u00f6lkopf, B., Smola, A.J. and Bach, F., 2002. Learning with kernels: support vector machines, regularization, optimization, and beyond. MIT press."}, {"text_id": "BkeUECAvsr", "sid": 9, "sentence": "- Vapnik, V., 2013. The nature of statistical learning theory. Springer science & business media."}, {"text_id": "BkeUECAvsr", "sid": 10, "sentence": "2) More experiment"}, {"text_id": "BkeUECAvsr", "sid": 11, "sentence": "Thank you for pointing out these datasets."}, {"text_id": "BkeUECAvsr", "sid": 12, "sentence": "We have conducted further experiments on the Office-Home dataset,  using the ResNet50 as the backbone architecture and changing the classification head to 65 classes."}, {"text_id": "BkeUECAvsr", "sid": 13, "sentence": "As we can see in the new Section 5.3, our method achieve state-of-the-art performance and outperform all alternatives"}, {"text_id": "BkeUECAvsr", "sid": 14, "sentence": "; these results are statistically significant."}, {"text_id": "BkeUECAvsr", "sid": 15, "sentence": "In addition, we have added one more competitive baseline (M3SDA) from the DomainNet paper you mentioned, using their public code with a few necessary adjustments for each dataset (e.g., network architecture, etc)."}, {"text_id": "BkeUECAvsr", "sid": 16, "sentence": "We ensure that all methods use the same backbone architecture for a fair comparison."}, {"text_id": "BkeUECAvsr", "sid": 17, "sentence": "Again, our method outperform M3SDA in all datasets."}, {"text_id": "BkeUECAvsr", "sid": 18, "sentence": "If you have any other comments or concerns, we are happy to provide further feedback."}, {"text_id": "BkeUECAvsr", "sid": 19, "sentence": "Thank you!"}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "BkeUECAvsr", "sid": 0}, {"labels": {"alignments": [59], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "BkeUECAvsr", "sid": 1}, {"labels": {"alignments": [59], "responsetype": "reject-request_scope_Yes", "coarseresponse": "dispute"}, "text_id": "BkeUECAvsr", "sid": 2}, {"labels": {"alignments": [59], "responsetype": "reject-request_scope_Yes", "coarseresponse": "dispute"}, "text_id": "BkeUECAvsr", "sid": 3}, {"labels": {"alignments": [59], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BkeUECAvsr", "sid": 4}, {"labels": {"alignments": [59], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BkeUECAvsr", "sid": 5}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "BkeUECAvsr", "sid": 6}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "BkeUECAvsr", "sid": 7}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "BkeUECAvsr", "sid": 8}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "BkeUECAvsr", "sid": 9}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "BkeUECAvsr", "sid": 10}, {"labels": {"alignments": [62, 63], "responsetype": "concede-criticism", "coarseresponse": "concur"}, "text_id": "BkeUECAvsr", "sid": 11}, {"labels": {"alignments": [62, 63], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "BkeUECAvsr", "sid": 12}, {"labels": {"alignments": [62, 63], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "BkeUECAvsr", "sid": 13}, {"labels": {"alignments": [62, 63], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "BkeUECAvsr", "sid": 14}, {"labels": {"alignments": [62, 63], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "BkeUECAvsr", "sid": 15}, {"labels": {"alignments": [62, 63], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BkeUECAvsr", "sid": 16}, {"labels": {"alignments": [62, 63], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BkeUECAvsr", "sid": 17}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "BkeUECAvsr", "sid": 18}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "BkeUECAvsr", "sid": 19}], "metadata": {"anno": "anno10", "review": "Hyxp9P_RuH", "rebuttal": "BkeUECAvsr", "conference": "ICLR2020", "title": "Domain Aggregation Networks for Multi-Source Domain Adaptation", "reviewer": "AnonReviewer1", "forum_id": "ByljMaNKwB", "rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area."}}