{"review": [{"text_id": "HklXxIdqn7", "sid": 0, "sentence": "The author's present a dual learning framework that, instead of using a single mapping for each mapping task between two respective domains, the authors learn multiple diverse mappings."}, {"text_id": "HklXxIdqn7", "sid": 1, "sentence": "These diverse mappings are learned before the two main mappings are trained and are kept constant during the training of the two main mappings."}, {"text_id": "HklXxIdqn7", "sid": 2, "sentence": "Though I am not familiar with BLEU scores and though I didn't grasp some of the details in 3.1, the algorithm yielded consistent improvement over the given baselines."}, {"text_id": "HklXxIdqn7", "sid": 3, "sentence": "The author's included many different experiments to show this."}, {"text_id": "HklXxIdqn7", "sid": 4, "sentence": "The idea that multiple mappings will produce better results than a single mapping is reasonable given previous results on ensemble methods."}, {"text_id": "HklXxIdqn7", "sid": 5, "sentence": "For the language translation results, were there any other state-of-the-art methods that the authors could compare against? It seems they are only comparing against their own implementations."}, {"text_id": "HklXxIdqn7", "sid": 6, "sentence": "Objectively saying that the author's method is better than CycleGAN is difficult. How does their ensemble method compare to just their single-agent dual method? Is there a noticeable difference there?"}, {"text_id": "HklXxIdqn7", "sid": 7, "sentence": "Minor Comments:"}, {"text_id": "HklXxIdqn7", "sid": 8, "sentence": "Dual-1 and Dual-5 are introduced without explanation."}, {"text_id": "HklXxIdqn7", "sid": 9, "sentence": "Perhaps I missed it, but I believe Dan Ciresan's paper \"Multi-Column Deep Neural Networks for Image Classification\" should be cited."}, {"text_id": "HklXxIdqn7", "sid": 10, "sentence": "###"}, {"text_id": "HklXxIdqn7", "sid": 11, "sentence": "After reading author feedback"}, {"text_id": "HklXxIdqn7", "sid": 12, "sentence": "Thank you for the feedback."}, {"text_id": "HklXxIdqn7", "sid": 13, "sentence": "After reading the updated paper I still believe that 6 is the right score for this paper."}, {"text_id": "HklXxIdqn7", "sid": 14, "sentence": "The method produces better results using ensemble learning."}, {"text_id": "HklXxIdqn7", "sid": 15, "sentence": "While the results seem impressive, the method to obtain them is not very novel; nonetheless, I would not have a problem with it being accepted, but I don't think it would be a loss if it were not accepted."}], "reviewlabels": [{"text_id": "HklXxIdqn7", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HklXxIdqn7", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HklXxIdqn7", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HklXxIdqn7", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HklXxIdqn7", "sid": 4, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HklXxIdqn7", "sid": 5, "labels": {"coarse": "Request", "fine": "Request.Clarification", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HklXxIdqn7", "sid": 6, "labels": {"coarse": "Request", "fine": "Request.Clarification", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HklXxIdqn7", "sid": 7, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HklXxIdqn7", "sid": 8, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Replicability", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HklXxIdqn7", "sid": 9, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Meaningful Comparison", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HklXxIdqn7", "sid": 10, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "HklXxIdqn7", "sid": 11, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "HklXxIdqn7", "sid": 12, "labels": {"coarse": "Social", "fine": "Social", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HklXxIdqn7", "sid": 13, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HklXxIdqn7", "sid": 14, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HklXxIdqn7", "sid": 15, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "rJxe6Bpf07", "sid": 0, "sentence": "Thank you for your review and valuable comments!"}, {"text_id": "rJxe6Bpf07", "sid": 1, "sentence": "Summary: our response includes: (1) Clarification on language translation baselines; (2) Discussion on image translation evaluation; (3) Reference and clarification."}, {"text_id": "rJxe6Bpf07", "sid": 2, "sentence": "** Language Translation Baselines **"}, {"text_id": "rJxe6Bpf07", "sid": 3, "sentence": "1. For the baseline models reported:"}, {"text_id": "rJxe6Bpf07", "sid": 4, "sentence": "1.1) We use the transformer model with \"transformer_big\" setting [1], which is a strong baseline that outperforms almost all previously popular NMT models based on CNN [2] and LSTM [3]."}, {"text_id": "rJxe6Bpf07", "sid": 5, "sentence": "Transformer is the state-of-the-art NMT architecture."}, {"text_id": "rJxe6Bpf07", "sid": 6, "sentence": "Our numbers of the baseline transformer model match the results reported in [1]."}, {"text_id": "rJxe6Bpf07", "sid": 7, "sentence": "1.2) In addition to the standard baseline models, we also compare our method against all the relevant algorithms including knowledge distillation (KD) and back translation (BT)."}, {"text_id": "rJxe6Bpf07", "sid": 8, "sentence": "1.3) As can be seen in many well-known and recent NMT works ([4], [5])"}, {"text_id": "rJxe6Bpf07", "sid": 9, "sentence": ", it is a common practice to use transformer as the robust baseline model."}, {"text_id": "rJxe6Bpf07", "sid": 10, "sentence": "Furthermore, it is also shown from these works that it is hard to improve over the transformer baseline, and 0.5-1 BLEU score improvement is already considered substantial."}, {"text_id": "rJxe6Bpf07", "sid": 11, "sentence": "2. We further add newly obtained results on the WMT18 challenge."}, {"text_id": "rJxe6Bpf07", "sid": 12, "sentence": "We compare our method with both the champion translation system MS-Marian (WMT18 En->De challenge champion)."}, {"text_id": "rJxe6Bpf07", "sid": 13, "sentence": "Our method achieves the state-of-the-art result on this task."}, {"text_id": "rJxe6Bpf07", "sid": 14, "sentence": "---------------------------------------------------------------------------"}, {"text_id": "rJxe6Bpf07", "sid": 15, "sentence": "WMT En->De"}, {"text_id": "rJxe6Bpf07", "sid": 16, "sentence": "2016"}, {"text_id": "rJxe6Bpf07", "sid": 17, "sentence": "2017"}, {"text_id": "rJxe6Bpf07", "sid": 18, "sentence": "2018"}, {"text_id": "rJxe6Bpf07", "sid": 19, "sentence": "---------------------------------------------------------------------------"}, {"text_id": "rJxe6Bpf07", "sid": 20, "sentence": "MS-Marian (ensemble)"}, {"text_id": "rJxe6Bpf07", "sid": 21, "sentence": "39.6"}, {"text_id": "rJxe6Bpf07", "sid": 22, "sentence": "31.9          48.3"}, {"text_id": "rJxe6Bpf07", "sid": 23, "sentence": "Ours (single)"}, {"text_id": "rJxe6Bpf07", "sid": 24, "sentence": "40.68"}, {"text_id": "rJxe6Bpf07", "sid": 25, "sentence": "33.47       48.89"}, {"text_id": "rJxe6Bpf07", "sid": 26, "sentence": "Ours (ensemble)"}, {"text_id": "rJxe6Bpf07", "sid": 27, "sentence": "41.23"}, {"text_id": "rJxe6Bpf07", "sid": 28, "sentence": "34.01       49.61"}, {"text_id": "rJxe6Bpf07", "sid": 29, "sentence": "---------------------------------------------------------------------------"}, {"text_id": "rJxe6Bpf07", "sid": 30, "sentence": "Please refer to Section 3.4 \"Study on generality of the algorithm\" for more details and Table 4 for full results in our updated paper."}, {"text_id": "rJxe6Bpf07", "sid": 31, "sentence": "** Image Translation Evaluation **"}, {"text_id": "rJxe6Bpf07", "sid": 32, "sentence": "For image-to-image translation tasks, we further add two quantitative measures: (1) We use the Fr\u00e9chet Inception Distance (FID) [6], which measures the distance between generated images and real images to evaluate the painting to photos translation."}, {"text_id": "rJxe6Bpf07", "sid": 33, "sentence": "(2) We use \"FCN-score\" evaluation on the cityscape dataset following [7]."}, {"text_id": "rJxe6Bpf07", "sid": 34, "sentence": "The results are reported in Table 6 and Table 7 respectively."}, {"text_id": "rJxe6Bpf07", "sid": 35, "sentence": "Multi-agent dual learning framework can achieve better quantitative results than the baselines."}, {"text_id": "rJxe6Bpf07", "sid": 36, "sentence": "We are not sure what you meant by \u201cHow does their ensemble method compare to just their single-agent dual method?"}, {"text_id": "rJxe6Bpf07", "sid": 37, "sentence": "\u201d"}, {"text_id": "rJxe6Bpf07", "sid": 38, "sentence": "."}, {"text_id": "rJxe6Bpf07", "sid": 39, "sentence": "The standard CycleGAN model (baseline) already leverages both primal and dual mappings, which is equivalent to our \u201cDual-1\u201d model in NMT experiments, i.e., the dual method with only one pair of agents f_0 and g_0."}, {"text_id": "rJxe6Bpf07", "sid": 40, "sentence": "Our model involves two additional pairs of agents (f_1 and g_1, f_2 and g_2) during training."}, {"text_id": "rJxe6Bpf07", "sid": 41, "sentence": "Unlike ensemble learning, only one agent (f_0 for forward direction, or g_0 for backward direction) is used during inference."}, {"text_id": "rJxe6Bpf07", "sid": 42, "sentence": "** Reference **"}, {"text_id": "rJxe6Bpf07", "sid": 43, "sentence": "Thanks for pointing a reference paper \"Multi-Column Deep Neural Networks for Image Classification\" (briefly, MCDNN) and we have added reference to it (Section 4)."}, {"text_id": "rJxe6Bpf07", "sid": 44, "sentence": "Although MCDNN also uses multiple agents (i.e., several columns of deep neural networks), it differs from our model in two aspects: (1) Our work leverages the duality of a pair of dual tasks while this paper does not; (2) In an MCDNN framework, during the training phase, all the columns are updated by winner-take-all rule; and during inference, all columns work like an ensemble model through weighted average."}, {"text_id": "rJxe6Bpf07", "sid": 45, "sentence": "In comparison, we only update one primal and one dual agent during training, and use one agent for inference."}, {"text_id": "rJxe6Bpf07", "sid": 46, "sentence": "** Clarity **"}, {"text_id": "rJxe6Bpf07", "sid": 47, "sentence": "Thanks for pointing out that our original introduction to the names of baselines and models is not very clear."}, {"text_id": "rJxe6Bpf07", "sid": 48, "sentence": "Please kindly refer to first paragraph in Section 3.3."}, {"text_id": "rJxe6Bpf07", "sid": 49, "sentence": "You may check our updated paper with clarification and new experimental results."}, {"text_id": "rJxe6Bpf07", "sid": 50, "sentence": "Thanks for your time and feedbacks."}, {"text_id": "rJxe6Bpf07", "sid": 51, "sentence": "[1] Vaswani, Ashish, et al. \"Attention is all you need.\" In NIPS. 2017."}, {"text_id": "rJxe6Bpf07", "sid": 52, "sentence": "[2] Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N Dauphin. Convolutional Sequence to Sequence Learning. In Proc. of ICML, 2017."}, {"text_id": "rJxe6Bpf07", "sid": 53, "sentence": "[3] Wu, Yonghui, et al. \"Google's neural machine translation system: Bridging the gap between human and machine translation.\" arXiv preprint arXiv:1609.08144 (2016)."}, {"text_id": "rJxe6Bpf07", "sid": 54, "sentence": "[4] Chen, Mia Xu, et al. \"The Best of Both Worlds: Combining Recent Advances in Neural Machine Translation.\" In Proc. of the ACL, 2018."}, {"text_id": "rJxe6Bpf07", "sid": 55, "sentence": "[5] Peter Shaw, Jakob Uszkoreit, and Ashish Vaswani. Self-attention with relative position representations. In Proc. of NAACL, 2018."}, {"text_id": "rJxe6Bpf07", "sid": 56, "sentence": "[6] Heusel, Martin, et al. \"Gans trained by a two time-scale update rule converge to a local nash equilibrium.\" In NIPS, 2017."}, {"text_id": "rJxe6Bpf07", "sid": 57, "sentence": "[7] Isola, Phillip, et al. \"Image-to-image translation with conditional adversarial networks.\" In CVPR, 2017"}, {"text_id": "rJxe6Bpf07", "sid": 58, "sentence": "Dear AnonReviewer1,"}, {"text_id": "rJxe6Bpf07", "sid": 59, "sentence": "Before the final decision concludes, do you have further questions regarding our rebuttal and updated paper?"}, {"text_id": "rJxe6Bpf07", "sid": 60, "sentence": "Our paper revision includes reorganization of the introduction to our framework (Section 3.1), the additional experiments on WMT18 English->German translation challenge (Section 3.4), the additional study on diversity of agents (Appendix A), and quantitative evaluation on image-to-image translations (Section 4.3 and 4.4) following your suggestions."}, {"text_id": "rJxe6Bpf07", "sid": 61, "sentence": "In particular, we would like to highlight that:"}, {"text_id": "rJxe6Bpf07", "sid": 62, "sentence": "(1) The calibration of BLEU score: We would like to point out that our improvement over the previous state-of-the-art baselines is substantial."}, {"text_id": "rJxe6Bpf07", "sid": 63, "sentence": "For example, on the WMT2014 En->De translation task, the performance of the transformer baseline is 28.4 BLEU score [1] (our baseline matches this performance)."}, {"text_id": "rJxe6Bpf07", "sid": 64, "sentence": "The improvement over this baseline is 0.61 in [2], 0.8 in [3] (1.3 BLEU improvement over the re-implemented 27.9 baseline in [3]) and 0.9 in [4], while ours is 1.65 BLEU score."}, {"text_id": "rJxe6Bpf07", "sid": 65, "sentence": "(2) The baselines: As we explained in the previous response, we are using the state-of-the-art transformer as our backbone model, and comparing against all the relevant algorithms including KD, BT and the traditional 2-agent dual learning (Dual-1)."}, {"text_id": "rJxe6Bpf07", "sid": 66, "sentence": "Moreover, we also show on WMT18 En->De challenge that our method can further improve the state-of-the-art model trained with extensive resources (Section 3.4 of our updated paper)."}, {"text_id": "rJxe6Bpf07", "sid": 67, "sentence": "We hope our rebuttal and paper revision could address your concerns."}, {"text_id": "rJxe6Bpf07", "sid": 68, "sentence": "We welcome further discussion and are willing to answer any further questions."}, {"text_id": "rJxe6Bpf07", "sid": 69, "sentence": "[1] Vaswani, Ashish, et al. \"Attention is all you need.\" Advances in Neural Information Processing Systems. 2017."}, {"text_id": "rJxe6Bpf07", "sid": 70, "sentence": "[2] He, Tianyu, et al. \"Layer-Wise Coordination between Encoder and Decoder for Neural Machine Translation\". Advances in Neural Information Processing Systems. 2018."}, {"text_id": "rJxe6Bpf07", "sid": 71, "sentence": "[3] Shaw, Peter, Jakob Uszkoreit, and Ashish Vaswani. \"Self-Attention with Relative Position Representations.\" In Proc. of NAACL, 2018."}, {"text_id": "rJxe6Bpf07", "sid": 72, "sentence": "[4] Anonymous. Universal transformers. In Submitted to International Conference on Learning Representations, 2019."}, {"text_id": "rJxe6Bpf07", "sid": 73, "sentence": "URL https://openreview.net/forum?id=HyzdRiR9Y7."}, {"text_id": "rJxe6Bpf07", "sid": 74, "sentence": "Under review as a conference paper at ICLR 2019"}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 0}, {"labels": {"alignments": [], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 1}, {"labels": {"alignments": [5], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 2}, {"labels": {"alignments": [5], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 3}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 4}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 5}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 6}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 7}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 8}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 9}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 10}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 11}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 12}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 13}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 14}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 15}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 16}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 17}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 18}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 19}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 20}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 21}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 22}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 23}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 24}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 25}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 26}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 27}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 28}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 29}, {"labels": {"alignments": [5], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 30}, {"labels": {"alignments": [6], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 31}, {"labels": {"alignments": [6], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 32}, {"labels": {"alignments": [6], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 33}, {"labels": {"alignments": [6], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 34}, {"labels": {"alignments": [6], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 35}, {"labels": {"alignments": [6], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 36}, {"labels": {"alignments": [6], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 37}, {"labels": {"alignments": [6], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 38}, {"labels": {"alignments": [6], "responsetype": "refute-question", "coarseresponse": "dispute"}, "text_id": "rJxe6Bpf07", "sid": 39}, {"labels": {"alignments": [6], "responsetype": "refute-question", "coarseresponse": "dispute"}, "text_id": "rJxe6Bpf07", "sid": 40}, {"labels": {"alignments": [6], "responsetype": "refute-question", "coarseresponse": "dispute"}, "text_id": "rJxe6Bpf07", "sid": 41}, {"labels": {"alignments": [9], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 42}, {"labels": {"alignments": [9], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 43}, {"labels": {"alignments": [9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 44}, {"labels": {"alignments": [9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 45}, {"labels": {"alignments": [8], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 46}, {"labels": {"alignments": [8], "responsetype": "concede-criticism", "coarseresponse": "concur"}, "text_id": "rJxe6Bpf07", "sid": 47}, {"labels": {"alignments": [8], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 48}, {"labels": {"alignments": [8], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 49}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 50}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 51}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 52}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 53}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 54}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 55}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 56}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 57}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 58}, {"labels": {"alignments": [], "responsetype": "followup", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 59}, {"labels": {"alignments": [], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 60}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 61}, {"labels": {"alignments": [], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 62}, {"labels": {"alignments": [], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 63}, {"labels": {"alignments": [], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 64}, {"labels": {"alignments": [], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 65}, {"labels": {"alignments": [], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 66}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 67}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 68}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 69}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 70}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 71}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 72}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 73}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "rJxe6Bpf07", "sid": 74}], "metadata": {"anno": "anno2", "review": "HklXxIdqn7", "rebuttal": "rJxe6Bpf07", "conference": "ICLR2019", "title": "Multi-Agent Dual Learning", "reviewer": "AnonReviewer1", "forum_id": "HyGhN2A5tm", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}}