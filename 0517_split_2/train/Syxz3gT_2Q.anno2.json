{"review": [{"text_id": "Syxz3gT_2Q", "sid": 0, "sentence": "This paper proposes a method for mathematical problem embedding, which firstly decomposes problems into concepts by an abstraction step and then trains a skip-gram model to learn concept embedding."}, {"text_id": "Syxz3gT_2Q", "sid": 1, "sentence": "A problem can be represented as the average concept (corresponding to those in the problem) embeddings."}, {"text_id": "Syxz3gT_2Q", "sid": 2, "sentence": "To handle the imbalanced dataset, a negative pre-training method is proposed to decrease false and false positives."}, {"text_id": "Syxz3gT_2Q", "sid": 3, "sentence": "Experimental results show that the proposed method works much better than baselines in similar problem detection, on an undergraduate probability data set."}, {"text_id": "Syxz3gT_2Q", "sid": 4, "sentence": "Strong points:"}, {"text_id": "Syxz3gT_2Q", "sid": 5, "sentence": "(1)\tThe idea of decomposing problems into concepts is interesting and also makes sense."}, {"text_id": "Syxz3gT_2Q", "sid": 6, "sentence": "(2)"}, {"text_id": "Syxz3gT_2Q", "sid": 7, "sentence": "The training method for imbalanced datasets is impressive."}, {"text_id": "Syxz3gT_2Q", "sid": 8, "sentence": "Concerns or suggestions:"}, {"text_id": "Syxz3gT_2Q", "sid": 9, "sentence": "1.\tThe main idea of using contents to represent a problem is quite simple and straightforward."}, {"text_id": "Syxz3gT_2Q", "sid": 10, "sentence": "The contribution of this paper seems more on the training method for imbalanced data sets."}, {"text_id": "Syxz3gT_2Q", "sid": 11, "sentence": "But there are no comparisons between the proposed training method and previous related works."}, {"text_id": "Syxz3gT_2Q", "sid": 12, "sentence": "Actually, imbalance data sets are common in machine learning problems and there are many related works."}, {"text_id": "Syxz3gT_2Q", "sid": 13, "sentence": "The comparisons are also absent in experiments."}, {"text_id": "Syxz3gT_2Q", "sid": 14, "sentence": "2.\tThe experimental data set is too small, with only 635 problems."}, {"text_id": "Syxz3gT_2Q", "sid": 15, "sentence": "It is difficult to judge the performance of the proposed model based on so small data set."}, {"text_id": "Syxz3gT_2Q", "sid": 16, "sentence": "3.\tThe proposed method, which decomposes a problem into multiple concepts, looks general for many problem settings."}, {"text_id": "Syxz3gT_2Q", "sid": 17, "sentence": "For example, representing a movie or news article by tags or topics."}, {"text_id": "Syxz3gT_2Q", "sid": 18, "sentence": "In this way, the proposed method can be tested in a broader domain and on larger datasets."}, {"text_id": "Syxz3gT_2Q", "sid": 19, "sentence": "4.\tFor the final purpose, comparing problem similarity, I am wondering what the result will be if we train a supervised model based problem-problem similarity labels?"}], "reviewlabels": [{"text_id": "Syxz3gT_2Q", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Syxz3gT_2Q", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Syxz3gT_2Q", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Syxz3gT_2Q", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Syxz3gT_2Q", "sid": 4, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Syxz3gT_2Q", "sid": 5, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Syxz3gT_2Q", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "Syxz3gT_2Q", "sid": 7, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "Syxz3gT_2Q", "sid": 8, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Syxz3gT_2Q", "sid": 9, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Syxz3gT_2Q", "sid": 10, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Syxz3gT_2Q", "sid": 11, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Meaningful Comparison", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Syxz3gT_2Q", "sid": 12, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Syxz3gT_2Q", "sid": 13, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Meaningful Comparison", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Syxz3gT_2Q", "sid": 14, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Syxz3gT_2Q", "sid": 15, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Syxz3gT_2Q", "sid": 16, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Syxz3gT_2Q", "sid": 17, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Syxz3gT_2Q", "sid": 18, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Syxz3gT_2Q", "sid": 19, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Soundness/Correctness", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "B1l3_3TepQ", "sid": 0, "sentence": "1- The idea of using concepts to represent a problem is simple, but using it along with neural network based embedding gives us the opportunity to gain concept continuity as discussed on the last paragraph on page 7 and table 2, which is an active field of research in education."}, {"text_id": "B1l3_3TepQ", "sid": 1, "sentence": "The focus of this work is on problem embedding and its application in a recommendation system that uses problem embedding to project students\u2019 performance for the problems they solved onto the problems that they have not solved yet."}, {"text_id": "B1l3_3TepQ", "sid": 2, "sentence": "Using the evaluation on unseen problems, a problem is recommended that is within the capacity of students close to their boundary to help them learn, and at the same time we cover all the concepts necessary for them to learn."}, {"text_id": "B1l3_3TepQ", "sid": 3, "sentence": "In the meanwhile, we got the interesting idea of negative pre-training on training with imbalanced training data and tested our hypothesis and included in the paper."}, {"text_id": "B1l3_3TepQ", "sid": 4, "sentence": "Due to space limit, we did not include the literature review and comparison of other methods in terms of memory use and training complexity, but you can find them in the response of a previous comment below titled \u201cResponse to Question on Negative Pre-Training\u201d on this page to see the comparison."}, {"text_id": "B1l3_3TepQ", "sid": 5, "sentence": "We can include the literature review for training on imbalanced data sets as well as comparison of other methods with negative pre-training in terms of memory use and training complexity in the final version."}, {"text_id": "B1l3_3TepQ", "sid": 6, "sentence": "In summary, a) oversampling extremely suffers from over-fitting, b) SMOTE method that generates synthetic data sample is not feasible in word space, so the generated synthetic data (that are mathematical problems) are not of use for our training purpose, c) borderline-SMOTE both suffers from the same issue as SMOTE and its high complexity for finding the pairwise distance between all data samples, which is a burden in high dimensional data, and d) hybrid methods need m >> 1 weak learners in contrast to negative pre-training that uses a single learner."}, {"text_id": "B1l3_3TepQ", "sid": 7, "sentence": "Memory use and training time is an issue for hybrid method when the weak learners are deep neural networks with too many parameters."}, {"text_id": "B1l3_3TepQ", "sid": 8, "sentence": "We are currently running a broader experiment for negative pre-training on other data sets to gain more insight on it, but for the purpose of the task proposed in this work, it outperforms one-shot learning, which cannot be said that is the state-of-the art, but is a common practice. There is no notion of state-of-the-art in training on imbalanced data sets since due to our best knowledge, there is no method that outperforms all the other ones, and the performance of different methods depends more on the nature of the data set."}, {"text_id": "B1l3_3TepQ", "sid": 9, "sentence": "2- The data set being small"}, {"text_id": "B1l3_3TepQ", "sid": 10, "sentence": "is the nature of the application since creating mathematical problems is a creative process, so it is hard to have a very big data set."}, {"text_id": "B1l3_3TepQ", "sid": 11, "sentence": "The Prob2Vec method is performing well on this not relatively big data set, which is our goal, but if we have a bigger data set (as we have right now with more than 2400 problems), Prob2Vec may even have a better performance since with more data we can have a more precise concept and problem embedding."}, {"text_id": "B1l3_3TepQ", "sid": 12, "sentence": "3- Thanks for your suggestion."}, {"text_id": "B1l3_3TepQ", "sid": 13, "sentence": "4- It is difficult for humans to determine a similarity score consistent across a large enough training set, so it is not feasible to simply apply supervised methods to learn a similarity score for problems."}, {"text_id": "B1l3_3TepQ", "sid": 14, "sentence": "Even if problem-problem similarity annotation is feasible, a lot of effort should go into the annotation, which is not scalable."}], "rebuttallabels": [{"labels": {"alignments": [9, 10, 11, 12, 13], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "B1l3_3TepQ", "sid": 0}, {"labels": {"alignments": [9, 10, 11, 12, 13], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "B1l3_3TepQ", "sid": 1}, {"labels": {"alignments": [9, 10, 11, 12, 13], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "B1l3_3TepQ", "sid": 2}, {"labels": {"alignments": [9, 10, 11, 12, 13], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "B1l3_3TepQ", "sid": 3}, {"labels": {"alignments": [9, 10, 11, 12, 13], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "B1l3_3TepQ", "sid": 4}, {"labels": {"alignments": [9, 10, 11, 12, 13], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "B1l3_3TepQ", "sid": 5}, {"labels": {"alignments": [9, 10, 11, 12, 13], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "B1l3_3TepQ", "sid": 6}, {"labels": {"alignments": [9, 10, 11, 12, 13], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "B1l3_3TepQ", "sid": 7}, {"labels": {"alignments": [9, 10, 11, 12, 13], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "B1l3_3TepQ", "sid": 8}, {"labels": {"alignments": [14, 15], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "B1l3_3TepQ", "sid": 9}, {"labels": {"alignments": [14, 15], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "B1l3_3TepQ", "sid": 10}, {"labels": {"alignments": [14, 15], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "B1l3_3TepQ", "sid": 11}, {"labels": {"alignments": [16, 17, 18], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "B1l3_3TepQ", "sid": 12}, {"labels": {"alignments": [19], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "B1l3_3TepQ", "sid": 13}, {"labels": {"alignments": [19], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "B1l3_3TepQ", "sid": 14}], "metadata": {"anno": "anno2", "review": "Syxz3gT_2Q", "rebuttal": "B1l3_3TepQ", "conference": "ICLR2019", "title": "Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring", "reviewer": "AnonReviewer2", "forum_id": "SJl8gnAqtX", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}}