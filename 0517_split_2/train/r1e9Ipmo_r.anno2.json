{"review": [{"text_id": "r1e9Ipmo_r", "sid": 0, "sentence": "Overview:"}, {"text_id": "r1e9Ipmo_r", "sid": 1, "sentence": "This paper considers unsupervised (or self-supervised) discrete representation learning of speech using a combination of a recent vector quantized neural network discritization method and future time step prediction."}, {"text_id": "r1e9Ipmo_r", "sid": 2, "sentence": "Discrete representations are fine-tuned by using these as input to a BERT model; the resulting representations are then used instead of conventional speech features as the input to speech recognition models."}, {"text_id": "r1e9Ipmo_r", "sid": 3, "sentence": "New state-of-the-art results are achieved on two datasets."}, {"text_id": "r1e9Ipmo_r", "sid": 4, "sentence": "Strengths:"}, {"text_id": "r1e9Ipmo_r", "sid": 5, "sentence": "The core strength of this paper is in the results that are achieved on standard speech recognition benchmarks."}, {"text_id": "r1e9Ipmo_r", "sid": 6, "sentence": "The results indicate that, while discritization in itself does not give improvements, coupling this with the BERT-objective results in speech features which are better in downstream speech recognition than standard features. I think the main technical novelty is in combining discritization with future time step prediction (but see the weakness below)."}, {"text_id": "r1e9Ipmo_r", "sid": 7, "sentence": "Weaknesses:"}, {"text_id": "r1e9Ipmo_r", "sid": 8, "sentence": "The main weakness of the paper is that it does not situate itself within existing literature in this area."}, {"text_id": "r1e9Ipmo_r", "sid": 9, "sentence": "Over the last few years, researchers in the speech community have invested significant effort in learning better speech representations, and this is not discussed."}, {"text_id": "r1e9Ipmo_r", "sid": 10, "sentence": "See e.g. [1]."}, {"text_id": "r1e9Ipmo_r", "sid": 11, "sentence": "Even more importantly, very recently there has been a number of papers investigating discrete representations of speech; see the review [2]."}, {"text_id": "r1e9Ipmo_r", "sid": 12, "sentence": "Some of these papers specifically use VQ-VAEs [3]."}, {"text_id": "r1e9Ipmo_r", "sid": 13, "sentence": "[4] actually compares VQ-VAE and the Gumbel-Softmax approach."}, {"text_id": "r1e9Ipmo_r", "sid": 14, "sentence": "These studies should be mentioned."}, {"text_id": "r1e9Ipmo_r", "sid": 15, "sentence": "This paper is different in that it incorporates future time step prediction."}, {"text_id": "r1e9Ipmo_r", "sid": 16, "sentence": "But context prediction has also been considered before, also for speech [5, 6, 7]."}, {"text_id": "r1e9Ipmo_r", "sid": 17, "sentence": "This paper can be situated as a new contribution combining these two strands of research."}, {"text_id": "r1e9Ipmo_r", "sid": 18, "sentence": "In the longer run it would be extremely beneficial to the community if this approach is applied to the standard benchmarks as set out in [2]."}, {"text_id": "r1e9Ipmo_r", "sid": 19, "sentence": "As a minor weakness, some parts of the paper is not described in enough detail and the motivation is weak or not exactly clear (see detailed comments below)."}, {"text_id": "r1e9Ipmo_r", "sid": 20, "sentence": "Overall assessment:"}, {"text_id": "r1e9Ipmo_r", "sid": 21, "sentence": "I think the results as well as the new combination of existing approaches in the paper warrants publication. But it should be amended significantly to situate itself within the existing literature. I therefore award a \"weak accept\"."}, {"text_id": "r1e9Ipmo_r", "sid": 22, "sentence": "Detailed questions and suggestions:"}, {"text_id": "r1e9Ipmo_r", "sid": 23, "sentence": "- Section 1: As motivation for this work, it is stated that \"we aim to make well performing NLP algorithms more widely applicable\"."}, {"text_id": "r1e9Ipmo_r", "sid": 24, "sentence": "As noted above, some NLP-like ideas (such as prediction of future speech segments, stemming from text-based language modelling) have already been considered within the speech community."}, {"text_id": "r1e9Ipmo_r", "sid": 25, "sentence": "Rather than motivating the work in this way, it might be helpful to focus the contribution as a combination of future time step prediction and discretization (both of which have been considered in previous work, but not in combination)."}, {"text_id": "r1e9Ipmo_r", "sid": 26, "sentence": "- Section 4: Would it be possible to train the vq-wav2vec model jointly with BERT, i.e. as one model? I suspect it would be difficult since, for the masking objective, the discrete units are already required, but maybe there is a scheme where this could work."}, {"text_id": "r1e9Ipmo_r", "sid": 27, "sentence": "- Section 2.2: Similarly to the above question, would there be a way to incorporate the BERT principles directly into an end-to-end model, e.g. by randomly masking some of the continuous input speech?"}, {"text_id": "r1e9Ipmo_r", "sid": 28, "sentence": "- Section 3.3: What exactly does \"mode collapse\" refer to in this context? Would this be using only one codebook entry, for instance?"}, {"text_id": "r1e9Ipmo_r", "sid": 29, "sentence": "- Section 6: It seems that in all cases to obtain improvements from discritization, BERT is required on top of the vq-wav2vec discrete symbols."}, {"text_id": "r1e9Ipmo_r", "sid": 30, "sentence": "Is it possible that the output acoustic model is simply better-matched to continuous rather than discrete input (direct vq-wav2vec gives discrete while BERT gives continuous)? Would it make sense to train the wav2vec acoustic model on top of the vqvae codebook entries (e) instead of directly on the symbols?"}, {"text_id": "r1e9Ipmo_r", "sid": 31, "sentence": "Typos, grammar and style:"}, {"text_id": "r1e9Ipmo_r", "sid": 32, "sentence": "- \"gumbel\" -> \"Gumbel\" (throughout; or just be consistent in capitalization)"}, {"text_id": "r1e9Ipmo_r", "sid": 33, "sentence": "- \"which can be mitigated my workarounds\" -> \"which can be mitigated *by*"}, {"text_id": "r1e9Ipmo_r", "sid": 34, "sentence": "workarounds\""}, {"text_id": "r1e9Ipmo_r", "sid": 35, "sentence": "- \"work around\" -> \"workaround\""}, {"text_id": "r1e9Ipmo_r", "sid": 36, "sentence": "Missing references:"}, {"text_id": "r1e9Ipmo_r", "sid": 37, "sentence": "1. Versteegh, M., Anguera, X., Jansen, A. & Dupoux, E. (2016). The Zero Resource Speech Challenge 2015: Proposed Approaches and Results. In SLTU-2016 Procedia Computer Science, 81, (pp 67-72)."}, {"text_id": "r1e9Ipmo_r", "sid": 38, "sentence": "2. https://arxiv.org/abs/1904.11469"}, {"text_id": "r1e9Ipmo_r", "sid": 39, "sentence": "3. https://arxiv.org/abs/1905.11449"}, {"text_id": "r1e9Ipmo_r", "sid": 40, "sentence": "4. https://arxiv.org/abs/1904.07556"}, {"text_id": "r1e9Ipmo_r", "sid": 41, "sentence": "5. https://arxiv.org/abs/1904.03240"}, {"text_id": "r1e9Ipmo_r", "sid": 42, "sentence": "6. https://arxiv.org/abs/1807.03748 (this paper is cited)"}, {"text_id": "r1e9Ipmo_r", "sid": 43, "sentence": "7. https://arxiv.org/abs/1803.08976"}, {"text_id": "r1e9Ipmo_r", "sid": 44, "sentence": "Edit: Based on the feedback from the authors, I changed my rating from a 'weak accept' to an 'accept'."}], "reviewlabels": [{"text_id": "r1e9Ipmo_r", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 4, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 5, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 7, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 8, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Meaningful Comparison", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 9, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Meaningful Comparison", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 10, "labels": {"coarse": "Structuring", "fine": "Structuring.Quote", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 11, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 12, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 13, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 14, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Meaningful Comparison", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 15, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 16, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 17, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 18, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 19, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Motivation/Impact", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 20, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 21, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Meaningful Comparison", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 22, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 23, "labels": {"coarse": "Structuring", "fine": "Structuring.Quote", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 24, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 25, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Soundness/Correctness", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 26, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 27, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 28, "labels": {"coarse": "Request", "fine": "Request.Clarification", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 29, "labels": {"coarse": "Structuring", "fine": "Structuring.Quote", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 30, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 31, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 32, "labels": {"coarse": "Request", "fine": "Request.Typo", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 33, "labels": {"coarse": "Request", "fine": "Request.Typo", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "r1e9Ipmo_r", "sid": 34, "labels": {"coarse": "Request", "fine": "Request.Typo", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "r1e9Ipmo_r", "sid": 35, "labels": {"coarse": "Request", "fine": "Request.Typo", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 36, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 37, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 38, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 39, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 40, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 41, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 42, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 43, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1e9Ipmo_r", "sid": 44, "labels": {"coarse": "Social", "fine": "Social", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "ryllakFnsS", "sid": 0, "sentence": "Thank you for the fruitful comments!"}, {"text_id": "ryllakFnsS", "sid": 1, "sentence": "We addressed your main concern and updated Section 1 of the paper to better situate it in the existing literature."}, {"text_id": "ryllakFnsS", "sid": 2, "sentence": ">> Would it be possible to train the vq-wav2vec model jointly with BERT, i.e. as one model? [...] Similarly to the above question, would there be a way to incorporate the BERT principles directly into an end-to-end model, e.g. by randomly masking some of the continuous input speech?"}, {"text_id": "ryllakFnsS", "sid": 3, "sentence": "The focus of this paper is a quantization approach for audio."}, {"text_id": "ryllakFnsS", "sid": 4, "sentence": "Replacing the two-step training process by an adaptation of BERT to continuous data (using a wav2vec/CPC-like objective function instead of the cross entropy) is an interesting direction for future work (and we amended the future work section accordingly)."}, {"text_id": "ryllakFnsS", "sid": 5, "sentence": "However, our current paper is a proof of concept that a pre-training scheme based on masked inputs (BERT) can improve over previous methods in the speech domain."}, {"text_id": "ryllakFnsS", "sid": 6, "sentence": ">> What exactly does \"mode collapse\" refer to in this context?"}, {"text_id": "ryllakFnsS", "sid": 7, "sentence": "In several configurations (especially for one and two groups) considerably less codewords than theoretically possible are used."}, {"text_id": "ryllakFnsS", "sid": 8, "sentence": "We loosely refer to mode collapse as the phenomenon when very few codewords per group are used (cf. Appendix A)."}, {"text_id": "ryllakFnsS", "sid": 9, "sentence": "We updated the paper to also refer to the appendix where we outline the number of codewords that the model uses."}, {"text_id": "ryllakFnsS", "sid": 10, "sentence": "We observed that in the \u201cfew group regime\u201d (G=1...4), only a few of the available centroids per group are used and refer to this phenomenon as mode collapse \u2014 for BERT training, this is actually favorable e.g. in the G=2, V=320 setting as it yields a codebook of acceptable size for NLP model training (13.5k/23k)."}, {"text_id": "ryllakFnsS", "sid": 11, "sentence": "Mode collapse could potentially be circumvented by strategies like embedding re-initialization used in classical k-means and this is an interesting avenue for future work."}, {"text_id": "ryllakFnsS", "sid": 12, "sentence": ">> [...] BERT is required on top of the vq-wav2vec discrete symbols."}, {"text_id": "ryllakFnsS", "sid": 13, "sentence": "Is it possible that the output acoustic model is simply better-matched to continuous rather than discrete input (direct vq-wav2vec gives discrete while BERT gives continuous)? Would it make sense to train the wav2vec acoustic model on top of the vqvae codebook entries (e) instead of directly on the symbols?"}, {"text_id": "ryllakFnsS", "sid": 14, "sentence": "We actually did what you suggest: when we train acoustic models on top of vq-wav2vec, we input the dense embedding vectors corresponding to the discrete codewords."}, {"text_id": "ryllakFnsS", "sid": 15, "sentence": "On the other hand, we also trained an NLP sequence to sequence (Section 6.3) which takes the quantized audio codes as input and then generates the transcriptions."}, {"text_id": "ryllakFnsS", "sid": 16, "sentence": "This gives reasonable accuracy and suggests that the discrete codes by themselves, and without the learned continuous representations, are useful."}, {"text_id": "ryllakFnsS", "sid": 17, "sentence": "We clarified this in the updated version of the paper."}, {"text_id": "ryllakFnsS", "sid": 18, "sentence": "We believe the reason the dense embeddings for the discrete codewords work less well"}, {"text_id": "ryllakFnsS", "sid": 19, "sentence": "is because they do not encode as much detailed context information as a representation built by wav2vec or BERT."}, {"text_id": "ryllakFnsS", "sid": 20, "sentence": "The information in the codebook is ultimately less detailed than a context vector specific to the current input sequence."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "ryllakFnsS", "sid": 0}, {"labels": {"alignments": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "ryllakFnsS", "sid": 1}, {"labels": {"alignments": [26, 27], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "ryllakFnsS", "sid": 2}, {"labels": {"alignments": [26, 27], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryllakFnsS", "sid": 3}, {"labels": {"alignments": [26, 27], "responsetype": "future", "coarseresponse": "concur"}, "text_id": "ryllakFnsS", "sid": 4}, {"labels": {"alignments": [26, 27], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryllakFnsS", "sid": 5}, {"labels": {"alignments": [28], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "ryllakFnsS", "sid": 6}, {"labels": {"alignments": [28], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryllakFnsS", "sid": 7}, {"labels": {"alignments": [28], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryllakFnsS", "sid": 8}, {"labels": {"alignments": [28], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryllakFnsS", "sid": 9}, {"labels": {"alignments": [28], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryllakFnsS", "sid": 10}, {"labels": {"alignments": [28], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryllakFnsS", "sid": 11}, {"labels": {"alignments": [29, 30], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "ryllakFnsS", "sid": 12}, {"labels": {"alignments": [29, 30], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "ryllakFnsS", "sid": 13}, {"labels": {"alignments": [29, 30], "responsetype": "done_manu_No", "coarseresponse": "concur"}, "text_id": "ryllakFnsS", "sid": 14}, {"labels": {"alignments": [29, 30], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryllakFnsS", "sid": 15}, {"labels": {"alignments": [29, 30], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryllakFnsS", "sid": 16}, {"labels": {"alignments": [29, 30], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "ryllakFnsS", "sid": 17}, {"labels": {"alignments": [29, 30], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryllakFnsS", "sid": 18}, {"labels": {"alignments": [29, 30], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryllakFnsS", "sid": 19}, {"labels": {"alignments": [29, 30], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryllakFnsS", "sid": 20}], "metadata": {"anno": "anno2", "review": "r1e9Ipmo_r", "rebuttal": "ryllakFnsS", "conference": "ICLR2020", "title": "vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations", "reviewer": "AnonReviewer1", "forum_id": "rylwJxrYDS", "rating": "8: Accept", "experience_assessment": "I have published in this field for several years."}}