{"review": [{"text_id": "r1eaptK5hm", "sid": 0, "sentence": "The paper proposes to learn task-level modules progressively to perform the task of VQA."}, {"text_id": "r1eaptK5hm", "sid": 1, "sentence": "Such task-level modules include object/attribute prediction, image captioning, relationship detection, object counting, and finally VQA model."}, {"text_id": "r1eaptK5hm", "sid": 2, "sentence": "The benefit of using modules for reasoning allows one to visualize the reasoning process more easily to understand the model better."}, {"text_id": "r1eaptK5hm", "sid": 3, "sentence": "The results are mainly shown on VQA 2.0 set, with a good amount of analysis."}, {"text_id": "r1eaptK5hm", "sid": 4, "sentence": "- I think overall this is a good paper, with clear organization, detailed description of the approach, solid analysis of the approach and cool visualization."}, {"text_id": "r1eaptK5hm", "sid": 5, "sentence": "I especially appreciate that analysis is done taking into consideration of extra computation cost of the large model; the extra data used for visual relationship detection."}, {"text_id": "r1eaptK5hm", "sid": 6, "sentence": "I do not have major comments about the paper itself, although I did not check the technical details super carefully."}, {"text_id": "r1eaptK5hm", "sid": 7, "sentence": "- One thing I am confused about is the residual model, which seems quite important for the pipeline but I cannot find details describing it and much analysis on this component."}, {"text_id": "r1eaptK5hm", "sid": 8, "sentence": "- I am in general curious to see if it will be beneficial to fine-tune the modules themselves can further improve performance. It maybe hard to do it entirely end-to-end, but maybe it is fine to fine-tune just a few top layers (like what Jiang et al did)?"}, {"text_id": "r1eaptK5hm", "sid": 9, "sentence": "- One great benefit of having a module-based model is feed in the *ground truth* output for some of the modules."}, {"text_id": "r1eaptK5hm", "sid": 10, "sentence": "For example, what benefit we can get if we have perfect object detection? Where can we get if we have perfect relationships?"}, {"text_id": "r1eaptK5hm", "sid": 11, "sentence": "This can help us not only better understand the models, but also the dataset (VQA) and the task in general."}], "reviewlabels": [{"text_id": "r1eaptK5hm", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1eaptK5hm", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1eaptK5hm", "sid": 2, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1eaptK5hm", "sid": 3, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1eaptK5hm", "sid": 4, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "P-Positive"}, "secondarylabels": [{"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "P-Positive"}], "merge-with-prior": false}, {"text_id": "r1eaptK5hm", "sid": 5, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1eaptK5hm", "sid": 6, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1eaptK5hm", "sid": 7, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1eaptK5hm", "sid": 8, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1eaptK5hm", "sid": 9, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1eaptK5hm", "sid": 10, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1eaptK5hm", "sid": 11, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "SJlY63MSpX", "sid": 0, "sentence": "We thank the reviewer for the comments and feedback."}, {"text_id": "SJlY63MSpX", "sid": 1, "sentence": "We will also include the suggested experiment that shows the plug-and-play nature of PMN."}, {"text_id": "SJlY63MSpX", "sid": 2, "sentence": "1. Residual modules"}, {"text_id": "SJlY63MSpX", "sid": 3, "sentence": "- Residual modules are small neural networks (e.g., an MLP for Mvqa, Sec. 3.4, (4)) that a task module may use when other lower level modules are incapable of providing a solution to a given query."}, {"text_id": "SJlY63MSpX", "sid": 4, "sentence": "For example, consider the question \u201cis this person going to be happy?\u201d on an image of a person opening a present."}, {"text_id": "SJlY63MSpX", "sid": 5, "sentence": "Lower level modules of Mvqa may not be sufficient to solve the question."}, {"text_id": "SJlY63MSpX", "sid": 6, "sentence": "Therefore, Mvqa would make use of its residual module, which would essentially learn to \u201cpick up\u201d all queries that lower level modules cannot answer."}, {"text_id": "SJlY63MSpX", "sid": 7, "sentence": "2. Effect of fine-tuning"}, {"text_id": "SJlY63MSpX", "sid": 8, "sentence": "- While it might be beneficial to fine-tune the modules for a specific parent task we want each module to be an expert for their own task as it facilitates a plug-and-play architecture."}, {"text_id": "SJlY63MSpX", "sid": 9, "sentence": "Fine-tuning may push the modules towards blindly improving parent module\u2019s performance but (i) badly affect interpretability of inputs and outputs; and (ii) may also reduce the lower module\u2019s performance on its own task."}, {"text_id": "SJlY63MSpX", "sid": 10, "sentence": "Most importantly, it would not scale with the number of tasks, as for each task the agent would need to keep several fine-tuned modules of the lower tasks in memory."}, {"text_id": "SJlY63MSpX", "sid": 11, "sentence": "3. Feeding in the ground-truth"}, {"text_id": "SJlY63MSpX", "sid": 12, "sentence": "- Thanks for this great suggestion."}, {"text_id": "SJlY63MSpX", "sid": 13, "sentence": "We performed an experiment where we evaluate the benefits that the VQA model may achieve by using ground-truth captions instead of captions generated by the caption module."}, {"text_id": "SJlY63MSpX", "sid": 14, "sentence": "Our preliminary experiments show a gain of about 2.0% which is a relatively high gain for VQA."}, {"text_id": "SJlY63MSpX", "sid": 15, "sentence": "This points to important properties of the PMN allowing human-in-the-loop type of continual learning, where a human teacher can pinpoint flaws in the reasoning process and potentially help the model to fix them."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "SJlY63MSpX", "sid": 0}, {"labels": {"alignments": [9, 10], "responsetype": "concede-criticism", "coarseresponse": "concur"}, "text_id": "SJlY63MSpX", "sid": 1}, {"labels": {"alignments": [7], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlY63MSpX", "sid": 2}, {"labels": {"alignments": [7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlY63MSpX", "sid": 3}, {"labels": {"alignments": [7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlY63MSpX", "sid": 4}, {"labels": {"alignments": [7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlY63MSpX", "sid": 5}, {"labels": {"alignments": [7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlY63MSpX", "sid": 6}, {"labels": {"alignments": [8], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlY63MSpX", "sid": 7}, {"labels": {"alignments": [8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlY63MSpX", "sid": 8}, {"labels": {"alignments": [8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlY63MSpX", "sid": 9}, {"labels": {"alignments": [8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlY63MSpX", "sid": 10}, {"labels": {"alignments": [9, 10, 11], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlY63MSpX", "sid": 11}, {"labels": {"alignments": [9, 10, 11], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "SJlY63MSpX", "sid": 12}, {"labels": {"alignments": [9, 10, 11], "responsetype": "done_manu_No", "coarseresponse": "concur"}, "text_id": "SJlY63MSpX", "sid": 13}, {"labels": {"alignments": [9, 10, 11], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlY63MSpX", "sid": 14}, {"labels": {"alignments": [9, 10, 11], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlY63MSpX", "sid": 15}], "metadata": {"anno": "anno3", "review": "r1eaptK5hm", "rebuttal": "SJlY63MSpX", "conference": "ICLR2019", "title": "Visual Reasoning by Progressive Module Networks", "reviewer": "AnonReviewer2", "forum_id": "B1fpDsAqt7", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}}