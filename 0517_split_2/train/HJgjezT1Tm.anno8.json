{"review": [{"text_id": "HJgjezT1Tm", "sid": 0, "sentence": "Summary:"}, {"text_id": "HJgjezT1Tm", "sid": 1, "sentence": "The manuscript proposes a modification of generators in GANs which improves performance under two popular metrics for multiple architectures, loss, benchmarks, regularizers, and hyperparameter settings."}, {"text_id": "HJgjezT1Tm", "sid": 2, "sentence": "Using the conditional batch normalization mechanism, the input noise vector is allowed to modulate layers of the generator."}, {"text_id": "HJgjezT1Tm", "sid": 3, "sentence": "As this modulation only depends on the noise vector, this technique does not require additional annotations."}, {"text_id": "HJgjezT1Tm", "sid": 4, "sentence": "In addition to the extensive experimentation on different settings showing performance improvements, the authors also present an ablation study, that shows the impact of the method when applied to different layers."}, {"text_id": "HJgjezT1Tm", "sid": 5, "sentence": "Strengths:"}, {"text_id": "HJgjezT1Tm", "sid": 6, "sentence": "- The idea is simple."}, {"text_id": "HJgjezT1Tm", "sid": 7, "sentence": "The experimentation is extensive and results are convincing in that they show a clear improvement in performance using the method in a large majority of settings."}, {"text_id": "HJgjezT1Tm", "sid": 8, "sentence": "- I also like the ablation study showing the impact of the method applied at different layers."}, {"text_id": "HJgjezT1Tm", "sid": 9, "sentence": "Requests for clarification/additional information:"}, {"text_id": "HJgjezT1Tm", "sid": 10, "sentence": "- I might have missed that, but are the authors offering an interpretation of their observation that the performance of the self-modulation model performs worse in the combination of spectral normalization and the SNDC architecture?"}, {"text_id": "HJgjezT1Tm", "sid": 11, "sentence": "- The ablation study shows that the impact is highest when modulation is applied to the last layer (if only one layer is modulated)."}, {"text_id": "HJgjezT1Tm", "sid": 12, "sentence": "It seems modulation on layer 4 comes in as a close second."}, {"text_id": "HJgjezT1Tm", "sid": 13, "sentence": "I am curious about why that might be."}, {"text_id": "HJgjezT1Tm", "sid": 14, "sentence": "- I would like to see some more interpretation on why this method works."}, {"text_id": "HJgjezT1Tm", "sid": 15, "sentence": "- Did the authors inspect generated samples of the baseline and the proposed method? Is there a notable qualitative difference?"}, {"text_id": "HJgjezT1Tm", "sid": 16, "sentence": "Overall, the idea is simple, the explanation is clear and experimentation is extensive. I would like to see more commentary on why this method might have long-term impact (or not)."}], "reviewlabels": [{"text_id": "HJgjezT1Tm", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgjezT1Tm", "sid": 1, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgjezT1Tm", "sid": 2, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgjezT1Tm", "sid": 3, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgjezT1Tm", "sid": 4, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgjezT1Tm", "sid": 5, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgjezT1Tm", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgjezT1Tm", "sid": 7, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgjezT1Tm", "sid": 8, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgjezT1Tm", "sid": 9, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgjezT1Tm", "sid": 10, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgjezT1Tm", "sid": 11, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgjezT1Tm", "sid": 12, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgjezT1Tm", "sid": 13, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgjezT1Tm", "sid": 14, "labels": {"coarse": "Request", "fine": "Request.Clarification", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgjezT1Tm", "sid": 15, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgjezT1Tm", "sid": 16, "labels": {"coarse": "Request", "fine": "Request.Clarification", "asp": "Motivation/Impact", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "Bkgu7f_Dp7", "sid": 0, "sentence": "We would like to thank the reviewer for the time and useful feedback."}, {"text_id": "Bkgu7f_Dp7", "sid": 1, "sentence": "Our response is given below."}, {"text_id": "Bkgu7f_Dp7", "sid": 2, "sentence": "- Interpretation of self-modulation model performs worse in the combination of spectral normalization and the SNDC architecture."}, {"text_id": "Bkgu7f_Dp7", "sid": 3, "sentence": "Overall, self-modulation appears to yield the most consistent improvement for the deeper ResNet architecture, than the shallower, more poorly performing, SNDC architecture."}, {"text_id": "Bkgu7f_Dp7", "sid": 4, "sentence": "Self-modulation doesn\u2019t help in the SNDC/Spectral Norm setting on the Bedroom data, where the SNDC architecture appears to perform very poorly compared to ResNet."}, {"text_id": "Bkgu7f_Dp7", "sid": 5, "sentence": "For the other three datasets, self-modulation helps in this setting though."}, {"text_id": "Bkgu7f_Dp7", "sid": 6, "sentence": "- The ablation study shows that the impact is highest when modulation is applied to the last layer (if only one layer is modulated)."}, {"text_id": "Bkgu7f_Dp7", "sid": 7, "sentence": "It seems modulation on layer 4 comes in as a close second."}, {"text_id": "Bkgu7f_Dp7", "sid": 8, "sentence": "I am curious about why that might be."}, {"text_id": "Bkgu7f_Dp7", "sid": 9, "sentence": "Figure 4 in the Appendix contains the equivalent of Figure 2(c) for all datasets."}, {"text_id": "Bkgu7f_Dp7", "sid": 10, "sentence": "Considering all datasets: (1) Adding self-modulation to all layers performs best."}, {"text_id": "Bkgu7f_Dp7", "sid": 11, "sentence": "(2) In terms of median performance, adding it to the layer farthest from the input is the most effective."}, {"text_id": "Bkgu7f_Dp7", "sid": 12, "sentence": "We believe that the apparent significance of layer 4 in Figure 2(c) is statistical noise."}, {"text_id": "Bkgu7f_Dp7", "sid": 13, "sentence": "- I would like to see some more interpretation on why this method works."}, {"text_id": "Bkgu7f_Dp7", "sid": 14, "sentence": "We consider self-modulation as an architectural change in the line of changes such as residual connections or gating: simple, yet widely applicable and robust."}, {"text_id": "Bkgu7f_Dp7", "sid": 15, "sentence": "As a first step, we provide a careful empirical evaluation of its benefits."}, {"text_id": "Bkgu7f_Dp7", "sid": 16, "sentence": "While we have provided some diagnostics statistics, understanding deeply why this method helps will fuel interesting future research."}, {"text_id": "Bkgu7f_Dp7", "sid": 17, "sentence": "Similar to residual connections, gating, dropout, and many other recent advances, more fundamental understanding will happen asynchronously and should not gate its adoption and usefulness for the community."}, {"text_id": "Bkgu7f_Dp7", "sid": 18, "sentence": "- Did the authors inspect generated samples of the baseline and the proposed method? Is there a notable qualitative difference?"}, {"text_id": "Bkgu7f_Dp7", "sid": 19, "sentence": "A 10% change in FID is visually noticeable."}, {"text_id": "Bkgu7f_Dp7", "sid": 20, "sentence": "However, we note that FID rewards both improvements in sample quality (precision) and mode coverage (recall), as discussed in Sec 5 of [1]."}, {"text_id": "Bkgu7f_Dp7", "sid": 21, "sentence": "While we can easily assess the former by visual inspection, the latter is extremely challenging."}, {"text_id": "Bkgu7f_Dp7", "sid": 22, "sentence": "Therefore, an improvement in FID may not always be easily visible, but may indicate a better generative model of the data."}, {"text_id": "Bkgu7f_Dp7", "sid": 23, "sentence": "[1] https://arxiv.org/abs/1806.00035"}, {"text_id": "Bkgu7f_Dp7", "sid": 24, "sentence": "- Overall, the idea is simple, the explanation is clear and experimentation is extensive. I would like to see more commentary on why this method might have long-term impact (or not)."}, {"text_id": "Bkgu7f_Dp7", "sid": 25, "sentence": "We view this contribution as a simple yet generic architecture modification which leads to performance improvements."}, {"text_id": "Bkgu7f_Dp7", "sid": 26, "sentence": "Similarly to residual connections, we would like to see it used in GAN generator architectures, and more generally in decoder architectures in the long term."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "Bkgu7f_Dp7", "sid": 0}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "Bkgu7f_Dp7", "sid": 1}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Bkgu7f_Dp7", "sid": 2}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Bkgu7f_Dp7", "sid": 3}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Bkgu7f_Dp7", "sid": 4}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Bkgu7f_Dp7", "sid": 5}, {"labels": {"alignments": [11], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "Bkgu7f_Dp7", "sid": 6}, {"labels": {"alignments": [12], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "Bkgu7f_Dp7", "sid": 7}, {"labels": {"alignments": [13], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "Bkgu7f_Dp7", "sid": 8}, {"labels": {"alignments": [11, 12, 13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Bkgu7f_Dp7", "sid": 9}, {"labels": {"alignments": [11, 12, 13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Bkgu7f_Dp7", "sid": 10}, {"labels": {"alignments": [11, 12, 13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Bkgu7f_Dp7", "sid": 11}, {"labels": {"alignments": [11, 12, 13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Bkgu7f_Dp7", "sid": 12}, {"labels": {"alignments": [14], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "Bkgu7f_Dp7", "sid": 13}, {"labels": {"alignments": [14], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Bkgu7f_Dp7", "sid": 14}, {"labels": {"alignments": [14], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Bkgu7f_Dp7", "sid": 15}, {"labels": {"alignments": [14], "responsetype": "future", "coarseresponse": "concur"}, "text_id": "Bkgu7f_Dp7", "sid": 16}, {"labels": {"alignments": [14], "responsetype": "future", "coarseresponse": "concur"}, "text_id": "Bkgu7f_Dp7", "sid": 17}, {"labels": {"alignments": [15], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "Bkgu7f_Dp7", "sid": 18}, {"labels": {"alignments": [15], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Bkgu7f_Dp7", "sid": 19}, {"labels": {"alignments": [15], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Bkgu7f_Dp7", "sid": 20}, {"labels": {"alignments": [15], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Bkgu7f_Dp7", "sid": 21}, {"labels": {"alignments": [15], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Bkgu7f_Dp7", "sid": 22}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "Bkgu7f_Dp7", "sid": 23}, {"labels": {"alignments": [16], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "Bkgu7f_Dp7", "sid": 24}, {"labels": {"alignments": [16], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Bkgu7f_Dp7", "sid": 25}, {"labels": {"alignments": [16], "responsetype": "future", "coarseresponse": "concur"}, "text_id": "Bkgu7f_Dp7", "sid": 26}], "metadata": {"anno": "anno8", "review": "HJgjezT1Tm", "rebuttal": "Bkgu7f_Dp7", "conference": "ICLR2019", "title": "On Self Modulation for Generative Adversarial Networks", "reviewer": "AnonReviewer2", "forum_id": "Hkl5aoR5tm", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}}