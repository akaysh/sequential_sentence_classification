{"review": [{"text_id": "B1g4z20Vs7", "sid": 0, "sentence": "This paper proposes an approach for mitigating issues associated with high-frequency/amplitude control signals that may be obtained when one applies reinforcement learning algorithms to continuous control tasks."}, {"text_id": "B1g4z20Vs7", "sid": 1, "sentence": "The approach taken by the paper is to solve a constrained optimization problem, where the constraint imposes a (potentially state-dependent) lower bound on the reward."}, {"text_id": "B1g4z20Vs7", "sid": 2, "sentence": "This is done by using a Lagrangian relaxation that learns the parameters of a control policy that satisfies the desired constraints (and also learns the Lagrange multipliers)."}, {"text_id": "B1g4z20Vs7", "sid": 3, "sentence": "The presented approach is demonstrated on a cart-pole swing-up task as well as a quadruped locomotion task."}, {"text_id": "B1g4z20Vs7", "sid": 4, "sentence": "Strengths:"}, {"text_id": "B1g4z20Vs7", "sid": 5, "sentence": "+ The paper is generally clear and readable."}, {"text_id": "B1g4z20Vs7", "sid": 6, "sentence": "+ The simulation results for the Minitaur quadruped robot are performed using a realistic model of the robot."}, {"text_id": "B1g4z20Vs7", "sid": 7, "sentence": "Major concern:"}, {"text_id": "B1g4z20Vs7", "sid": 8, "sentence": "- My biggest concern is that the technical contributions of the paper are not clear at all."}, {"text_id": "B1g4z20Vs7", "sid": 9, "sentence": "The motivation for the work (avoiding high amplitude/frequency control inputs) is certainly now new; this has always been a concern of control theorists and roboticists (e.g., when considering minimum-time optimal control problems, or control schemes such as sliding mode control)."}, {"text_id": "B1g4z20Vs7", "sid": 10, "sentence": "The idea of using a constrained formulation is not novel either (constrained MDPs have been thoroughly studied since Altman (1999))."}, {"text_id": "B1g4z20Vs7", "sid": 11, "sentence": "The technical approach of using a Lagrangian relaxation is the standard way one goes about handling constrained optimization problems, and thus I do not see any novelty there either."}, {"text_id": "B1g4z20Vs7", "sid": 12, "sentence": "Overall, the paper does not make a compelling case for the novelty of the problem or approach."}, {"text_id": "B1g4z20Vs7", "sid": 13, "sentence": "Other concerns:"}, {"text_id": "B1g4z20Vs7", "sid": 14, "sentence": "- For the cart-pole task, the paper states that the reward is modified \"to exclude any cost objective\"."}, {"text_id": "B1g4z20Vs7", "sid": 15, "sentence": "Results are then presented for this modified reward showing that it results in high-frequency control signals (and that the proposed constrained approach avoids this)."}, {"text_id": "B1g4z20Vs7", "sid": 16, "sentence": "I don't think this is really a fair comparison; I would have liked to have seen results for the unmodified reward function."}, {"text_id": "B1g4z20Vs7", "sid": 17, "sentence": "- The claim made in the first line of the abstract (applying RL algorithms to continuous control problems often leads to bang-bang control)"}, {"text_id": "B1g4z20Vs7", "sid": 18, "sentence": "is very broad and should be watered down."}, {"text_id": "B1g4z20Vs7", "sid": 19, "sentence": "This is the case only when one considers a poorly-designed cost function that doesn't take into account realistic factors such as actuator limits."}, {"text_id": "B1g4z20Vs7", "sid": 20, "sentence": "- In the last paragraph of Section 3.3, the paper proposes making the lower-bound on the reward state-dependent."}, {"text_id": "B1g4z20Vs7", "sid": 21, "sentence": "However, this can be tricky in practice since it requires having an estimate for Q_r(s,a) as a function of the state (in order to ensure that the state-dependent lower bound can indeed be satisfied)."}, {"text_id": "B1g4z20Vs7", "sid": 22, "sentence": "Typos:"}, {"text_id": "B1g4z20Vs7", "sid": 23, "sentence": "- Pg. 5, Section 3.4: \"...this is would achieve...\""}, {"text_id": "B1g4z20Vs7", "sid": 24, "sentence": "- Pg. 6: ...thedse value of 90...\""}], "reviewlabels": [{"text_id": "B1g4z20Vs7", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1g4z20Vs7", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1g4z20Vs7", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1g4z20Vs7", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1g4z20Vs7", "sid": 4, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1g4z20Vs7", "sid": 5, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1g4z20Vs7", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1g4z20Vs7", "sid": 7, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1g4z20Vs7", "sid": 8, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Motivation/Impact", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1g4z20Vs7", "sid": 9, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1g4z20Vs7", "sid": 10, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1g4z20Vs7", "sid": 11, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1g4z20Vs7", "sid": 12, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1g4z20Vs7", "sid": 13, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1g4z20Vs7", "sid": 14, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1g4z20Vs7", "sid": 15, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1g4z20Vs7", "sid": 16, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Meaningful Comparison", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1g4z20Vs7", "sid": 17, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "B1g4z20Vs7", "sid": 18, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "B1g4z20Vs7", "sid": 19, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "B1g4z20Vs7", "sid": 20, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1g4z20Vs7", "sid": 21, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1g4z20Vs7", "sid": 22, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1g4z20Vs7", "sid": 23, "labels": {"coarse": "Request", "fine": "Request.Typo", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1g4z20Vs7", "sid": 24, "labels": {"coarse": "Request", "fine": "Request.Typo", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "SJgudF2KCX", "sid": 0, "sentence": "Thank you for your comments. Please find below our response to your questions and concerns."}, {"text_id": "SJgudF2KCX", "sid": 1, "sentence": "1) Technical contributions"}, {"text_id": "SJgudF2KCX", "sid": 2, "sentence": "We are glad that the reviewer agrees that we are tackling a long standing and important problem and acknowledge the fact that neither the definition of constrained MDPs nor the application of Lagrangian relaxation to solve these problems is novel by itself."}, {"text_id": "SJgudF2KCX", "sid": 3, "sentence": "We should have stated our exact technical contributions more clearly and have adapted the paper to do so."}, {"text_id": "SJgudF2KCX", "sid": 4, "sentence": "For completeness we will list these below:"}, {"text_id": "SJgudF2KCX", "sid": 5, "sentence": "a) We introduce pointwise, per-state constraints to learn more consistent behavior compared a single global constraint, and regress the resulting state-dependent Lagrangian multipliers using a neural network to exploit generalization across similar states."}, {"text_id": "SJgudF2KCX", "sid": 6, "sentence": "b) Instead of recombining the reward and cost directly on the environment side and learning a single value estimate, we train a critic network to output both return and penalty value estimates as well as the Lagrangian multipliers themselves, effectively providing more structure to the critic."}, {"text_id": "SJgudF2KCX", "sid": 7, "sentence": "We only combine the different terms appropriately for the actor update."}, {"text_id": "SJgudF2KCX", "sid": 8, "sentence": "c) We show that we can train a single, bound-conditional policy that can optimize penalty across a range of bounds and can be used to dynamically trade off reward and penalty."}, {"text_id": "SJgudF2KCX", "sid": 9, "sentence": "2) Comparison with the original benchmark reward"}, {"text_id": "SJgudF2KCX", "sid": 10, "sentence": "We have extended the results on Cartpole to include the original reward as defined in the DM Control Suite (incl. bonus for low control)."}, {"text_id": "SJgudF2KCX", "sid": 11, "sentence": "We found that compared to the original setting, our method is able to reduce the average control norm by over 50% across the entire episode, and by over 80% after the swingup phase, without significant reduction in the average return as measured without control bonus."}, {"text_id": "SJgudF2KCX", "sid": 12, "sentence": "3) Claims about bang-bang control in continuous RL"}, {"text_id": "SJgudF2KCX", "sid": 13, "sentence": "The reviewer is right in that the claim of RL often leading to bang-bang control is too strongly worded."}, {"text_id": "SJgudF2KCX", "sid": 14, "sentence": "This is only the case when the objective function is not well-designed and one is naively optimizing for success only."}, {"text_id": "SJgudF2KCX", "sid": 15, "sentence": "Designing a proper objective function is however often not trivial and more of an art, requiring several iterations to achieve the desired behavior."}, {"text_id": "SJgudF2KCX", "sid": 16, "sentence": "This work tries to remove some of the complexities in designing such a function."}, {"text_id": "SJgudF2KCX", "sid": 17, "sentence": "4) State-dependent lower bound"}, {"text_id": "SJgudF2KCX", "sid": 18, "sentence": "Defining a state-dependent bound is indeed not trivial and requires knowledge of what is feasible in the system, and as such we leave this up to future work."}, {"text_id": "SJgudF2KCX", "sid": 19, "sentence": "In this paper we have made the approximation that the state distribution is stationary and the discount is large enough to assume that the value is more or less constant."}, {"text_id": "SJgudF2KCX", "sid": 20, "sentence": "While this holds for locomotion tasks, this does not apply in e.g. the swingup phase of the cartpole task and as a result the penalty is completely ignored during this phase."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "SJgudF2KCX", "sid": 0}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJgudF2KCX", "sid": 1}, {"labels": {"alignments": [10, 11], "responsetype": "concede-criticism", "coarseresponse": "concur"}, "text_id": "SJgudF2KCX", "sid": 2}, {"labels": {"alignments": [10, 11], "responsetype": "concede-criticism", "coarseresponse": "concur"}, "text_id": "SJgudF2KCX", "sid": 3}, {"labels": {"alignments": [10, 11], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJgudF2KCX", "sid": 4}, {"labels": {"alignments": [10, 11], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJgudF2KCX", "sid": 5}, {"labels": {"alignments": [10, 11], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJgudF2KCX", "sid": 6}, {"labels": {"alignments": [10, 11], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJgudF2KCX", "sid": 7}, {"labels": {"alignments": [10, 11], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJgudF2KCX", "sid": 8}, {"labels": {"alignments": [14, 15, 16], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJgudF2KCX", "sid": 9}, {"labels": {"alignments": [14, 15, 16], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "SJgudF2KCX", "sid": 10}, {"labels": {"alignments": [14, 15, 16], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJgudF2KCX", "sid": 11}, {"labels": {"alignments": [17, 18, 19], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJgudF2KCX", "sid": 12}, {"labels": {"alignments": [17, 18, 19], "responsetype": "concede-criticism", "coarseresponse": "concur"}, "text_id": "SJgudF2KCX", "sid": 13}, {"labels": {"alignments": [17, 18, 19], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJgudF2KCX", "sid": 14}, {"labels": {"alignments": [17, 18, 19], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJgudF2KCX", "sid": 15}, {"labels": {"alignments": [17, 18, 19], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJgudF2KCX", "sid": 16}, {"labels": {"alignments": [20, 21], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJgudF2KCX", "sid": 17}, {"labels": {"alignments": [20, 21], "responsetype": "future", "coarseresponse": "concur"}, "text_id": "SJgudF2KCX", "sid": 18}, {"labels": {"alignments": [20, 21], "responsetype": "future", "coarseresponse": "concur"}, "text_id": "SJgudF2KCX", "sid": 19}, {"labels": {"alignments": [20, 21], "responsetype": "future", "coarseresponse": "concur"}, "text_id": "SJgudF2KCX", "sid": 20}], "metadata": {"anno": "anno3", "review": "B1g4z20Vs7", "rebuttal": "SJgudF2KCX", "conference": "ICLR2019", "title": "Success at any cost: value constrained model-free continuous control", "reviewer": "AnonReviewer1", "forum_id": "rJlJ-2CqtX", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}}