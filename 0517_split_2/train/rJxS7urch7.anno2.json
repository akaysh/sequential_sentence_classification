{"review": [{"text_id": "rJxS7urch7", "sid": 0, "sentence": "While the invertible model structure itself is essentially the same as Real-NVP, the use of observation variables in the framework with theoretically sound bidirectional training for safe use of the seemingly na\u00efve inclusion of y (i.e., y and z can be independent)."}, {"text_id": "rJxS7urch7", "sid": 1, "sentence": "Its abilities to model the posterior distributions of the inputs are supported by both quantitative and qualitative experiments."}, {"text_id": "rJxS7urch7", "sid": 2, "sentence": "The demonstration on practical examples is a plus."}, {"text_id": "rJxS7urch7", "sid": 3, "sentence": "The advantage of INN, however, is not crystal clear to me versus other generative methods such as GAN and VAE."}, {"text_id": "rJxS7urch7", "sid": 4, "sentence": "This is an interesting paper overall, so I am looking forward for further discussions."}, {"text_id": "rJxS7urch7", "sid": 5, "sentence": "Pros:"}, {"text_id": "rJxS7urch7", "sid": 6, "sentence": "1.\tExtensive analyses of the possibility of modeling posterior distributions with an INN have been shown."}, {"text_id": "rJxS7urch7", "sid": 7, "sentence": "Detailed experiment setups are provided in the appendix."}, {"text_id": "rJxS7urch7", "sid": 8, "sentence": "2.\tThe theoretical guarantee (with some assumptions) of the true posterior might be beneficial in practice for relatively low-dimensional or less complex tasks."}, {"text_id": "rJxS7urch7", "sid": 9, "sentence": "Comments/Questions:"}, {"text_id": "rJxS7urch7", "sid": 10, "sentence": "1.\tFrom the generative model point of view, could the authors elaborate on the comparison against cGAN (aside from the descriptions in Appendix 2)? It is quoted \u201ccGAN\u2026often lack satisfactory diversity in practice\u201d."}, {"text_id": "rJxS7urch7", "sid": 11, "sentence": "Also, can cGAN be used estimate the density of X (posterior or not)?"}, {"text_id": "rJxS7urch7", "sid": 12, "sentence": "2."}, {"text_id": "rJxS7urch7", "sid": 13, "sentence": "For the bidirectional training, did the ratios of the losses (L_z, L_y, L_x) have to be changed, or the iterations of forward/backward trainings have to be changed (e.g., 1 forward, 1 backward vs. 2 forward, 1 backward)?"}, {"text_id": "rJxS7urch7", "sid": 14, "sentence": "This question comes from my observation that the nature of the losses, especially for L_y vs. L_y,L_x (i.e., SL vs. USL) seem to be different."}, {"text_id": "rJxS7urch7", "sid": 15, "sentence": "3.\t\u201cwe find it advantageous to pad both the in- and output of the network with equal number of zeros\u201d: Is this to effectively increase the intermediate network dimensions?"}, {"text_id": "rJxS7urch7", "sid": 16, "sentence": "Also, does this imply that for both forward and inverse process those zero-padded entries always come out to be zero?"}, {"text_id": "rJxS7urch7", "sid": 17, "sentence": "It seems that there needs some way to enforce them to be zero to ensure that the propagation happens only among the entries belonging to the variables of interests (x, y and z)."}, {"text_id": "rJxS7urch7", "sid": 18, "sentence": "4.\tIt seems that most of the experiments are done in relatively small dimensional data."}, {"text_id": "rJxS7urch7", "sid": 19, "sentence": "This is not necessarily a drawback, I am curious if this model could succeed on higher dimensional data (e.g., image), especially with the observation y."}], "reviewlabels": [{"text_id": "rJxS7urch7", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxS7urch7", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxS7urch7", "sid": 2, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxS7urch7", "sid": 3, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxS7urch7", "sid": 4, "labels": {"coarse": "Social", "fine": "Social", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxS7urch7", "sid": 5, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxS7urch7", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxS7urch7", "sid": 7, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxS7urch7", "sid": 8, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Motivation/Impact", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxS7urch7", "sid": 9, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxS7urch7", "sid": 10, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Meaningful Comparison", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxS7urch7", "sid": 11, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxS7urch7", "sid": 12, "labels": {"coarse": "Request", "fine": "Request.Clarification", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "rJxS7urch7", "sid": 13, "labels": {"coarse": "Request", "fine": "Request.Clarification", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "rJxS7urch7", "sid": 14, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxS7urch7", "sid": 15, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxS7urch7", "sid": 16, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Soundness/Correctness", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxS7urch7", "sid": 17, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxS7urch7", "sid": 18, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxS7urch7", "sid": 19, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "SylKBy6Eam", "sid": 0, "sentence": "Thank you very much for your time, and your constructive comments, we are looking forward to further discussions!"}, {"text_id": "SylKBy6Eam", "sid": 1, "sentence": "We answer your questions and concerns in the following."}, {"text_id": "SylKBy6Eam", "sid": 2, "sentence": "> \"The advantage of INN is not crystal clear to me versus other generative methods such as GAN and VAE.\""}, {"text_id": "SylKBy6Eam", "sid": 3, "sentence": "It is indeed possible to adapt other network types to the task of predicting conditional posteriors."}, {"text_id": "SylKBy6Eam", "sid": 4, "sentence": "We are currently setting up experiments for detailed analysis of the respective advantages and disadvantages and will report about these results in a future paper."}, {"text_id": "SylKBy6Eam", "sid": 5, "sentence": "In the present paper, we focus on demonstrating that high-quality posteriors can actually be learned using bi-directional training as facilitated by INNs."}, {"text_id": "SylKBy6Eam", "sid": 6, "sentence": "Concerning the comments/questions:"}, {"text_id": "SylKBy6Eam", "sid": 7, "sentence": "1."}, {"text_id": "SylKBy6Eam", "sid": 8, "sentence": "> \"could the authors elaborate on the comparison against cGAN\""}, {"text_id": "SylKBy6Eam", "sid": 9, "sentence": "cGAN generators are at an inherent disadvantage relative to INNs, because they never see ground-truth pairs (x,y) directly -- they are only informed about them indirectly via discriminator gradients."}, {"text_id": "SylKBy6Eam", "sid": 10, "sentence": "This it not a problem for simple relationships, e.g. between images x and attributes y, and cGANs work very well there."}, {"text_id": "SylKBy6Eam", "sid": 11, "sentence": "However, it makes learning of complicated forward processes much harder and may cause the resulting posteriors to be inaccurate."}, {"text_id": "SylKBy6Eam", "sid": 12, "sentence": "Moreover, INNs are forced to embed every training point x somewhere in the latent space, whereas cGAN generators may fail to allocate latent space for some x, because this is never explicitly penalized."}, {"text_id": "SylKBy6Eam", "sid": 13, "sentence": "This can lead to mode collapse and insufficient diversity."}, {"text_id": "SylKBy6Eam", "sid": 14, "sentence": "> \"Can cGAN be used to estimate the density of X (posterior or not)?\""}, {"text_id": "SylKBy6Eam", "sid": 15, "sentence": "cGANs can in principle do this by choosing a generator architecture with tractable Jacobian (using e.g. coupling layers or autoregressive flow), but we are not aware of published results about this possibility."}, {"text_id": "SylKBy6Eam", "sid": 16, "sentence": "2."}, {"text_id": "SylKBy6Eam", "sid": 17, "sentence": "> \"For the bidirectional training, did the ratios of the losses (L_z, L_y, L_x) have to be changed, or the iterations of forward/backward trainings have to be changed (e.g., 1 forward, 1 backward vs. 2 forward, 1 backward)?\""}, {"text_id": "SylKBy6Eam", "sid": 18, "sentence": "Yes, the weights of the losses are considered as hyperparameters, because the magnitude of MMD-based losses depends on the chosen kernel function."}, {"text_id": "SylKBy6Eam", "sid": 19, "sentence": "Hyperparameter optimization suggested an up-weighting of MMD-based losses by a factor of 5, to give them approximately equal impact as the supervised loss."}, {"text_id": "SylKBy6Eam", "sid": 20, "sentence": "For the iterations, we accumulated gradients over one forward and one inverse network execution before each parameter update."}, {"text_id": "SylKBy6Eam", "sid": 21, "sentence": "We also tried alternating parameter updates after each forward and backward pass, which resulted in equal accuracy, but was a bit slower."}, {"text_id": "SylKBy6Eam", "sid": 22, "sentence": "We did not experiment with other ratios than 1:1."}, {"text_id": "SylKBy6Eam", "sid": 23, "sentence": "3."}, {"text_id": "SylKBy6Eam", "sid": 24, "sentence": "> \"Is this to effectively increase the intermediate network dimensions?\""}, {"text_id": "SylKBy6Eam", "sid": 25, "sentence": "This is precisely the reason: It improves the representational power of the INN, as mentioned in Sec. 3.2 and discussed in our response to reviewer 1."}, {"text_id": "SylKBy6Eam", "sid": 26, "sentence": "At present, we find this is only necessary for the toy problem in Fig. 2."}, {"text_id": "SylKBy6Eam", "sid": 27, "sentence": "> \"It seems that there needs some way to enforce them to be zero to ensure that the propagation happens only among the entries belonging to the variables of interests (x, y and z).\""}, {"text_id": "SylKBy6Eam", "sid": 28, "sentence": "This is correct."}, {"text_id": "SylKBy6Eam", "sid": 29, "sentence": "We explicitly prevent information from being hidden in the padding dimensions in the following way:"}, {"text_id": "SylKBy6Eam", "sid": 30, "sentence": "A squared loss ensures that the amplitudes are close to zero."}, {"text_id": "SylKBy6Eam", "sid": 31, "sentence": "In an additional inverse training pass, we overwrite the padding dimensions with noise of the same amplitude, and minimize their effect via a reconstruction loss."}, {"text_id": "SylKBy6Eam", "sid": 32, "sentence": "We will add this to the relevant paragraph in the paper."}, {"text_id": "SylKBy6Eam", "sid": 33, "sentence": "4."}, {"text_id": "SylKBy6Eam", "sid": 34, "sentence": "> \"I am curious if this model could succeed on higher dimensional data\""}, {"text_id": "SylKBy6Eam", "sid": 35, "sentence": "Works such as [1, 2, 3] (also cited in our paper) have shown that the coupling layer architecture in general works well with images."}, {"text_id": "SylKBy6Eam", "sid": 36, "sentence": "These works use maximum likelihood training, i.e. exploit the tractable Jacobians to maximize the likelihood of the data embedding in latent space."}, {"text_id": "SylKBy6Eam", "sid": 37, "sentence": "To scale-up our approach, we may need to replace MMD loss with maximum likelihood as well, and first experiments with this show promising results, see"}, {"text_id": "SylKBy6Eam", "sid": 38, "sentence": "https://i.imgur.com/ft09Pk9.png ."}, {"text_id": "SylKBy6Eam", "sid": 39, "sentence": "[1] Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio. Density estimation using Real NVP. arXiv:1605.08803, 2016."}, {"text_id": "SylKBy6Eam", "sid": 40, "sentence": "[2] Diederik P Kingma and Prafulla Dhariwal."}, {"text_id": "SylKBy6Eam", "sid": 41, "sentence": "Glow: Generative flow with invertible 1x1 convolutions. arXiv:1807.03039, 2018"}, {"text_id": "SylKBy6Eam", "sid": 42, "sentence": "[3] Schirrmeister, Robin Tibor, et al. \"Generative Reversible Networks.\" arXiv:1806.01610, 2018"}, {"text_id": "SylKBy6Eam", "sid": 43, "sentence": "We have uploaded a revised version of the paper, thank you again for your suggestions."}, {"text_id": "SylKBy6Eam", "sid": 44, "sentence": "The changes and additions are highlighted in red font for convenience."}, {"text_id": "SylKBy6Eam", "sid": 45, "sentence": "Please also note that by adding these changes, our page count increased by half a page beyond the recommended 8 pages."}, {"text_id": "SylKBy6Eam", "sid": 46, "sentence": "If this presents a problem, we can attempt shorten the paper accordingly."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "SylKBy6Eam", "sid": 0}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SylKBy6Eam", "sid": 1}, {"labels": {"alignments": [3], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SylKBy6Eam", "sid": 2}, {"labels": {"alignments": [3], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SylKBy6Eam", "sid": 3}, {"labels": {"alignments": [3], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "SylKBy6Eam", "sid": 4}, {"labels": {"alignments": [3], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SylKBy6Eam", "sid": 5}, {"labels": {"alignments": [9], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SylKBy6Eam", "sid": 6}, {"labels": {"alignments": [10], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SylKBy6Eam", "sid": 7}, {"labels": {"alignments": [10], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SylKBy6Eam", "sid": 8}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SylKBy6Eam", "sid": 9}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SylKBy6Eam", "sid": 10}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SylKBy6Eam", "sid": 11}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SylKBy6Eam", "sid": 12}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SylKBy6Eam", "sid": 13}, {"labels": {"alignments": [11], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SylKBy6Eam", "sid": 14}, {"labels": {"alignments": [11], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SylKBy6Eam", "sid": 15}, {"labels": {"alignments": [12], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SylKBy6Eam", "sid": 16}, {"labels": {"alignments": [13], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SylKBy6Eam", "sid": 17}, {"labels": {"alignments": [13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SylKBy6Eam", "sid": 18}, {"labels": {"alignments": [13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SylKBy6Eam", "sid": 19}, {"labels": {"alignments": [13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SylKBy6Eam", "sid": 20}, {"labels": {"alignments": [13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SylKBy6Eam", "sid": 21}, {"labels": {"alignments": [13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SylKBy6Eam", "sid": 22}, {"labels": {"alignments": [15], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SylKBy6Eam", "sid": 23}, {"labels": {"alignments": [15], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SylKBy6Eam", "sid": 24}, {"labels": {"alignments": [15], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SylKBy6Eam", "sid": 25}, {"labels": {"alignments": [15], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SylKBy6Eam", "sid": 26}, {"labels": {"alignments": [17], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SylKBy6Eam", "sid": 27}, {"labels": {"alignments": [17], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SylKBy6Eam", "sid": 28}, {"labels": {"alignments": [17], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SylKBy6Eam", "sid": 29}, {"labels": {"alignments": [17], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SylKBy6Eam", "sid": 30}, {"labels": {"alignments": [17], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SylKBy6Eam", "sid": 31}, {"labels": {"alignments": [17], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "SylKBy6Eam", "sid": 32}, {"labels": {"alignments": [18, 19], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SylKBy6Eam", "sid": 33}, {"labels": {"alignments": [18, 19], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SylKBy6Eam", "sid": 34}, {"labels": {"alignments": [18, 19], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SylKBy6Eam", "sid": 35}, {"labels": {"alignments": [18, 19], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SylKBy6Eam", "sid": 36}, {"labels": {"alignments": [18, 19], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SylKBy6Eam", "sid": 37}, {"labels": {"alignments": [18, 19], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SylKBy6Eam", "sid": 38}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "SylKBy6Eam", "sid": 39}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "SylKBy6Eam", "sid": 40}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "SylKBy6Eam", "sid": 41}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "SylKBy6Eam", "sid": 42}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "SylKBy6Eam", "sid": 43}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "SylKBy6Eam", "sid": 44}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "SylKBy6Eam", "sid": 45}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "SylKBy6Eam", "sid": 46}], "metadata": {"anno": "anno2", "review": "rJxS7urch7", "rebuttal": "SylKBy6Eam", "conference": "ICLR2019", "title": "Analyzing Inverse Problems with Invertible Neural Networks", "reviewer": "AnonReviewer3", "forum_id": "rJed6j0cKX", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}}