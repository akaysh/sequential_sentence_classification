{"review": [{"text_id": "HyecCk_TFH", "sid": 0, "sentence": "[Summary]"}, {"text_id": "HyecCk_TFH", "sid": 1, "sentence": "The paper presents a video classification framework that employs 4D convolution to capture longer term temporal structure than the popular 3D convolution schemes."}, {"text_id": "HyecCk_TFH", "sid": 2, "sentence": "This is achieved by treating the compositional space of local 3D video snippets as an individual dimension where an individual convolution is applied."}, {"text_id": "HyecCk_TFH", "sid": 3, "sentence": "The 4D convolution is integrated in resnet blocks and implemented via first applying 3D convolution to regular spatio-temporal video volumes and then the compositional space convolution, to leverage existing 3D operators."}, {"text_id": "HyecCk_TFH", "sid": 4, "sentence": "Empirical evaluation on three benchmarks against other baselines suggested the advantage of the proposed method."}, {"text_id": "HyecCk_TFH", "sid": 5, "sentence": "[Decision]"}, {"text_id": "HyecCk_TFH", "sid": 6, "sentence": "Overall, the paper addresses an important problem in computer vision (video action recognition) with an interesting."}, {"text_id": "HyecCk_TFH", "sid": 7, "sentence": "I found the motivation and solution are reasonable (despite some questions pending more elaboration), and results also look promising, thus give it a weak accept (conditional on the answers though)."}, {"text_id": "HyecCk_TFH", "sid": 8, "sentence": "[Comments]"}, {"text_id": "HyecCk_TFH", "sid": 9, "sentence": "At the conceptual level, the idea of jointly modeling local video events is not novel, and can date back to at least ten years ago in the paper \u201cLearning realistic human actions from movies\u201d, where the temporal pyramid matching was combined with the bag-of-visual-words framework to capture long-term temporal structure."}, {"text_id": "HyecCk_TFH", "sid": 10, "sentence": "The problem with this strategy is that the rigid composition only works for actions that can be split into consecutive temporal parts with prefixed duration and anchor points in time, which is clearly challenged by many works later when more complicated video events are studied."}, {"text_id": "HyecCk_TFH", "sid": 11, "sentence": "It seems to me that the proposed framework also falls in this category, with a treatment from deep learning."}, {"text_id": "HyecCk_TFH", "sid": 12, "sentence": "It is definitely worth some discussion on this path."}, {"text_id": "HyecCk_TFH", "sid": 13, "sentence": "That said, I would like to see more analysis on the behavior of the proposed method under various interesting cases not tested yet."}, {"text_id": "HyecCk_TFH", "sid": 14, "sentence": "Despite the claim that the proposed method can capture long-term video patterns, the static compositional nature seems to work best for activities with well-defined local events and clear temporal boundaries."}, {"text_id": "HyecCk_TFH", "sid": 15, "sentence": "These assumptions hold mostly true for the three datasets used in the experiment, and also are suggested by results in table 2(e), where 3 parts are necessary to achieve optimal results."}, {"text_id": "HyecCk_TFH", "sid": 16, "sentence": "How does the proposed method perform in more complicated tasks such as"}, {"text_id": "HyecCk_TFH", "sid": 17, "sentence": "- action detection or localization (e.g., in benchmarks JHMDB or UCF101-24)."}, {"text_id": "HyecCk_TFH", "sid": 18, "sentence": "- complex video event modeling (e.g., recognizing activities in extended video of TRECVID)."}, {"text_id": "HyecCk_TFH", "sid": 19, "sentence": "Will it still be more favorable than other concerning baselines?"}, {"text_id": "HyecCk_TFH", "sid": 20, "sentence": "Besides, on the computation side, it would be complexity, an explicit comparison of complexity makes it easier to evaluate the performance when compared to other state-of-the-art methods."}, {"text_id": "HyecCk_TFH", "sid": 21, "sentence": "[Area to improve]"}, {"text_id": "HyecCk_TFH", "sid": 22, "sentence": "Better literature review to reflect the relevant previous video action recognitions, especially those on video compositional models."}, {"text_id": "HyecCk_TFH", "sid": 23, "sentence": "Proof reading"}, {"text_id": "HyecCk_TFH", "sid": 24, "sentence": "- The word in the title should be \u201cConvolutional\u201d, right?"}], "reviewlabels": [{"text_id": "HyecCk_TFH", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyecCk_TFH", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyecCk_TFH", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyecCk_TFH", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyecCk_TFH", "sid": 4, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyecCk_TFH", "sid": 5, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyecCk_TFH", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Motivation/Impact", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyecCk_TFH", "sid": 7, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyecCk_TFH", "sid": 8, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyecCk_TFH", "sid": 9, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyecCk_TFH", "sid": 10, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "HyecCk_TFH", "sid": 11, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "HyecCk_TFH", "sid": 12, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "HyecCk_TFH", "sid": 13, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyecCk_TFH", "sid": 14, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyecCk_TFH", "sid": 15, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyecCk_TFH", "sid": 16, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Replicability", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "HyecCk_TFH", "sid": 17, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Replicability", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "HyecCk_TFH", "sid": 18, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Replicability", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "HyecCk_TFH", "sid": 19, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Replicability", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyecCk_TFH", "sid": 20, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyecCk_TFH", "sid": 21, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyecCk_TFH", "sid": 22, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyecCk_TFH", "sid": 23, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyecCk_TFH", "sid": 24, "labels": {"coarse": "Request", "fine": "Request.Typo", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "BkexWBXKor", "sid": 0, "sentence": "Thank you for your comments and suggestions."}, {"text_id": "BkexWBXKor", "sid": 1, "sentence": "We will address the issues you mentioned."}, {"text_id": "BkexWBXKor", "sid": 2, "sentence": "1.\tThank you for the insightful suggestion."}, {"text_id": "BkexWBXKor", "sid": 3, "sentence": "We now have added related work about video compositional methods in section 2.3 in the second version of the paper."}, {"text_id": "BkexWBXKor", "sid": 4, "sentence": "2."}, {"text_id": "BkexWBXKor", "sid": 5, "sentence": "In the original version of the paper, all experiments are conducted on trimmed video classification datasets."}, {"text_id": "BkexWBXKor", "sid": 6, "sentence": "Although most papers in this field only report results on the trimmed video datasets, we do agree that more complicate cases should be tested."}, {"text_id": "BkexWBXKor", "sid": 7, "sentence": "Additionally, we evaluated our V4D for untrimmed video classification on ActivityNet v1.3, which contains videos of 5 to 10 minutes and typically large time lapses of the videos are not related with any activity of interest."}, {"text_id": "BkexWBXKor", "sid": 8, "sentence": "The very competitive result is reported in the appendix of the second version of paper, which demonstrated the generalization and robustness of our V4D."}, {"text_id": "BkexWBXKor", "sid": 9, "sentence": "In fact, unlike previous video compositional methods, even when local events are not well aligned or misclassified, long-term modelling with 4D convolution and video-level aggregation with global average pooling are very likely to correct the partial error."}, {"text_id": "BkexWBXKor", "sid": 10, "sentence": "3.About complexity, in the original version of the paper, we have reported parameters and FLOPs of V4D and compared it with other baseline methods in Table 2."}, {"text_id": "BkexWBXKor", "sid": 11, "sentence": "4. We have already corrected the typo in title in the second version of the paper. Yet it seems that we are not able to modify the title on OpenReview. Thank you for pointing it out."}, {"text_id": "BkexWBXKor", "sid": 12, "sentence": "Hopefully our rebuttal could stress your concerns. If there are still any possible issues, please don\u2019t hesitate to tell us and we will response as soon as possible."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "BkexWBXKor", "sid": 0}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "BkexWBXKor", "sid": 1}, {"labels": {"alignments": [9, 10], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "BkexWBXKor", "sid": 2}, {"labels": {"alignments": [9, 10, 11, 12], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "BkexWBXKor", "sid": 3}, {"labels": {"alignments": [13, 14, 15, 16], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "BkexWBXKor", "sid": 4}, {"labels": {"alignments": [13, 14, 15, 16], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BkexWBXKor", "sid": 5}, {"labels": {"alignments": [13, 14, 15, 16], "responsetype": "concede-criticism", "coarseresponse": "concur"}, "text_id": "BkexWBXKor", "sid": 6}, {"labels": {"alignments": [13, 14, 15, 16], "responsetype": "done_manu_No", "coarseresponse": "concur"}, "text_id": "BkexWBXKor", "sid": 7}, {"labels": {"alignments": [13, 14, 15, 16], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "BkexWBXKor", "sid": 8}, {"labels": {"alignments": [13, 14, 15, 16], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BkexWBXKor", "sid": 9}, {"labels": {"alignments": [20], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "BkexWBXKor", "sid": 10}, {"labels": {"alignments": [24], "responsetype": "done_manu_No", "coarseresponse": "concur"}, "text_id": "BkexWBXKor", "sid": 11}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "BkexWBXKor", "sid": 12}], "metadata": {"anno": "anno3", "review": "HyecCk_TFH", "rebuttal": "BkexWBXKor", "conference": "ICLR2020", "title": "V4D: 4D Convolutional Neural Networks for Video-level Representation Learning", "reviewer": "AnonReviewer2", "forum_id": "SJeLopEYDH", "rating": "6: Weak Accept", "experience_assessment": "I have published one or two papers in this area."}}