{"review": [{"text_id": "rklz9YLKh7", "sid": 0, "sentence": "The paper design a low variance gradient for distributions associated with continuous or discrete random variables."}, {"text_id": "rklz9YLKh7", "sid": 1, "sentence": "The gradient is designed in the way to approximate the  property of reparameterization gradient."}, {"text_id": "rklz9YLKh7", "sid": 2, "sentence": "The paper is comprehensive and includes mathematical details."}, {"text_id": "rklz9YLKh7", "sid": 3, "sentence": "I have following comments/questions"}, {"text_id": "rklz9YLKh7", "sid": 4, "sentence": "1. What is the \\kappa in \u201cvariable-nabla\u201d stands for? What is the gradient w.r.t. \\kappa?"}, {"text_id": "rklz9YLKh7", "sid": 5, "sentence": "2. In Eq(8), does the outer expectation w.r.t . y_{-v} be approximated by one sample? If so, it is using the local expectation method."}, {"text_id": "rklz9YLKh7", "sid": 6, "sentence": "How does that differs from Titsias & Lazaro-Gredilla(2015) both mathematically and experimentally?"}, {"text_id": "rklz9YLKh7", "sid": 7, "sentence": "3. Assume y_v is M-way categorical distribution, Eq(8) evaluates f by 2*V*M times which can be computationally expensive."}, {"text_id": "rklz9YLKh7", "sid": 8, "sentence": "What is the computation complexity of GO? How to explain the fast speed shown in the experiments?"}, {"text_id": "rklz9YLKh7", "sid": 9, "sentence": "4. A most simple way to reduce the variance of REINFORCE gradient is to take multiple Monte-Carlo samples at the cost of more computation with multiple function f evaluations."}, {"text_id": "rklz9YLKh7", "sid": 10, "sentence": "Assume GO gradient needs to evaluate f N times, how does the performance compared with the REINFORCE gradient with N Monte-Carlo samples?"}, {"text_id": "rklz9YLKh7", "sid": 11, "sentence": "5. In the discrete VAE experiment, upon brief checking the results in Grathwohl(2017), it shows validation ELBO for MNIST as (114.32,111.12), OMNIGLOT as (122.11,128.20) from which two cases are better than GO."}, {"text_id": "rklz9YLKh7", "sid": 12, "sentence": "Does the hyper parameter setting favor the GO gradient in the reported experiments?"}, {"text_id": "rklz9YLKh7", "sid": 13, "sentence": "Error bar may also be needed for comparison."}, {"text_id": "rklz9YLKh7", "sid": 14, "sentence": "What about the performance of GO gradient in the 2 stochastic layer setting in Grathwohl(2017)?"}, {"text_id": "rklz9YLKh7", "sid": 15, "sentence": "6. The paper claims GO has less parameters than REBAR/RELAX. But in Figure 9, GO has more severe overfitting. How to explain this contradicts between the model complexity and overfitting?"}], "reviewlabels": [{"text_id": "rklz9YLKh7", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rklz9YLKh7", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rklz9YLKh7", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rklz9YLKh7", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rklz9YLKh7", "sid": 4, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rklz9YLKh7", "sid": 5, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rklz9YLKh7", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rklz9YLKh7", "sid": 7, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rklz9YLKh7", "sid": 8, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rklz9YLKh7", "sid": 9, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rklz9YLKh7", "sid": 10, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rklz9YLKh7", "sid": 11, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Meaningful Comparison", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rklz9YLKh7", "sid": 12, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rklz9YLKh7", "sid": 13, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Meaningful Comparison", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rklz9YLKh7", "sid": 14, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rklz9YLKh7", "sid": 15, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "ryxx8ZbFa7", "sid": 0, "sentence": "Thank you for your time and effort of reviewing our paper. Please see our response below."}, {"text_id": "ryxx8ZbFa7", "sid": 1, "sentence": "\\kappa is an assistant notation to remove the ambiguity of the two \\gammas in G_{\\gamma}^{q_{\\gamma} (y)}. \\kappa stands for the parameter/variable of which the gradient information is needed."}, {"text_id": "ryxx8ZbFa7", "sid": 2, "sentence": "For example,"}, {"text_id": "ryxx8ZbFa7", "sid": 3, "sentence": "(i) g_{\\kappa}^{q_{\\gamma}(y)} = frac{-1}{q_{\\gamma}(y)} \\nabla_{\\kappa} Q_{\\gamma}(y)}, where \\kappa is \\gamma, as in Theorem 1;"}, {"text_id": "ryxx8ZbFa7", "sid": 4, "sentence": "(ii) g_{\\kappa}^{q_{\\gamma}(y|\\lambda)} = frac{-1}{q_{\\gamma}(y|\\lambda)} \\nabla_{\\kappa} Q_{\\gamma}(y |\\lambda), where \\kappa could be \\gamma or \\lambda."}, {"text_id": "ryxx8ZbFa7", "sid": 5, "sentence": "Eqs. (7) and (8) are the foundations GO is built on, but they are not our GO."}, {"text_id": "ryxx8ZbFa7", "sid": 6, "sentence": "GO is defined in Eq. (9) of Theorem 1."}, {"text_id": "ryxx8ZbFa7", "sid": 7, "sentence": "For Eq. (9), yes, y_{-v} is selected from one sample y in the experiments."}, {"text_id": "ryxx8ZbFa7", "sid": 8, "sentence": "But GO is not the local expectation gradient (Titsias & Lazaro-Gredilla, 2015), because GO uses different information (the derivative of the CDF and the difference of the expected function)."}, {"text_id": "ryxx8ZbFa7", "sid": 9, "sentence": "As pointed out in the last paragraph of Sec. 3, when y_v has finite support and the computational cost is acceptable, one could use the local idea from Titsias & Lazaro-Gredilla(2015) for lower variance, namely analytically evaluate a part of expectations in Eq. (9)."}, {"text_id": "ryxx8ZbFa7", "sid": 10, "sentence": "For a detailed example, please refer to Appendix I."}, {"text_id": "ryxx8ZbFa7", "sid": 11, "sentence": "The main difference between the local expectation gradient and the proposed GO is that the latter is applicable to where the former might not be applicable, such as where y_v has infinite support or the computational cost for the local expectation is prohibitive."}, {"text_id": "ryxx8ZbFa7", "sid": 12, "sentence": "Please note our GO is defined in Eq. (9)."}, {"text_id": "ryxx8ZbFa7", "sid": 13, "sentence": "As pointed out in the last paragraph of Sec. 3, calculating Dy[f(y)] (requiring V+1 f evaluations) could be computationally expensive."}, {"text_id": "ryxx8ZbFa7", "sid": 14, "sentence": "We also stated there, \u201cfor f(y) often used in practice special properties hold that can be exploited for ef\ufb01cient parallel computing\u201d."}, {"text_id": "ryxx8ZbFa7", "sid": 15, "sentence": "We took the VAE experiment in Sec 7.2 as an example and gave in Appendix I its detailed analysis/implementation, in which you might be interested."}, {"text_id": "ryxx8ZbFa7", "sid": 16, "sentence": "More specifically, the two bullets after Table 4, should be able to address your question on fast speed."}, {"text_id": "ryxx8ZbFa7", "sid": 17, "sentence": "Also, as noted in the penultimate paragraph of Sec. 7.2, less parameters (without neural-network-parameterized control variant) could be another reason for GO\u2019s efficiency."}, {"text_id": "ryxx8ZbFa7", "sid": 18, "sentence": "As for computation complexity, since different random variables (RVs) have different variable-nabla (as shown in Table 3 in Appendix), GO has different computation complexity for different RVs."}, {"text_id": "ryxx8ZbFa7", "sid": 19, "sentence": "After choosing a specific RV, one should be able to obtain GO\u2019s computation complexity straightforwardly."}, {"text_id": "ryxx8ZbFa7", "sid": 20, "sentence": "For quantitative evaluation, the running time for each experiment has been given in the corresponding Appendix."}, {"text_id": "ryxx8ZbFa7", "sid": 21, "sentence": "Please check there if interested."}, {"text_id": "ryxx8ZbFa7", "sid": 22, "sentence": "Thank you for pointing out the concern on multi-sample-based REINFORCE."}, {"text_id": "ryxx8ZbFa7", "sid": 23, "sentence": "We have added another curve labeled REINFORCE2 to the one-dimensional NB experiments (see Fig. 8 for complete results), where the number 2 means using 2 samples to estimate the REINFORCE gradient."}, {"text_id": "ryxx8ZbFa7", "sid": 24, "sentence": "In this case, REINFORCE2 uses 2 samples and 2 f evaluations in each iteration, whereas GO uses 1 sample and 2 f evaluations."}, {"text_id": "ryxx8ZbFa7", "sid": 25, "sentence": "As expected, REINFORCE2 still exhibits higher variance than GO even in this simple one-dimensional setting."}, {"text_id": "ryxx8ZbFa7", "sid": 26, "sentence": "Multi-sample-based REINFORCE for other experiments is believed unnecessary, because (i) the variance of REINFORCE is well-known to increase with dimensionality; (ii) after all, if multi-sample-based REINFORCE works well in practice, why we need variance-reduction techniques?"}, {"text_id": "ryxx8ZbFa7", "sid": 27, "sentence": "Please refer to Sec. 7.2 and Appendix I, the author released code from Grathwohl(2017) (github.com/duvenaud/relax) were run to obtain the results of REBAR and RELAX."}, {"text_id": "ryxx8ZbFa7", "sid": 28, "sentence": "We adopted the same hyperparameter settings therein for our GO."}, {"text_id": "ryxx8ZbFa7", "sid": 29, "sentence": "So, we do not think the hyperparameter settings favor our GO in the reported experiments."}, {"text_id": "ryxx8ZbFa7", "sid": 30, "sentence": "Please refer to the first paragraph of Sec. 7.2, \u201cSince the statistical back-propagation in Theorem 3 cannot handle discrete internal variables, we focus on the single-latent-layer settings (1 layer of 200 Bernoulli random variables).\u201d"}, {"text_id": "ryxx8ZbFa7", "sid": 31, "sentence": "If you are interested, as stated in the last paragraph of Sec 7.2, we presented in Appendix B.4 a procedure to assist our methods in handling discrete internal RVs."}, {"text_id": "ryxx8ZbFa7", "sid": 32, "sentence": "We believe that procedure might be useful for the inference of models with discrete internal RVs (like the multi-layer discrete VAE)."}, {"text_id": "ryxx8ZbFa7", "sid": 33, "sentence": "Please refer to the last paragraph of Appendix I, where we explained this misunderstanding in detail."}, {"text_id": "ryxx8ZbFa7", "sid": 34, "sentence": "In short, GO does not suffer more from overfitting; one reason is GO can provide higher validation ELBO."}, {"text_id": "ryxx8ZbFa7", "sid": 35, "sentence": "Actually, we believe it is GO\u2019s efficiency that causes this misunderstanding."}, {"text_id": "ryxx8ZbFa7", "sid": 36, "sentence": "We hope your concerns have been addressed. If not, further discussion would be welcomed."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "ryxx8ZbFa7", "sid": 0}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 1}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 2}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 3}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 4}, {"labels": {"alignments": [5, 6], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 5}, {"labels": {"alignments": [5, 6], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 6}, {"labels": {"alignments": [5, 6], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 7}, {"labels": {"alignments": [5, 6, 7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 8}, {"labels": {"alignments": [7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 9}, {"labels": {"alignments": [7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 10}, {"labels": {"alignments": [7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 11}, {"labels": {"alignments": [7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 12}, {"labels": {"alignments": [7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 13}, {"labels": {"alignments": [7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 14}, {"labels": {"alignments": [7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 15}, {"labels": {"alignments": [7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 16}, {"labels": {"alignments": [7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 17}, {"labels": {"alignments": [7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 18}, {"labels": {"alignments": [7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 19}, {"labels": {"alignments": [7, 8], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 20}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "ryxx8ZbFa7", "sid": 21}, {"labels": {"alignments": [9, 10], "responsetype": "concede-criticism", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 22}, {"labels": {"alignments": [9, 10], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 23}, {"labels": {"alignments": [9, 10], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 24}, {"labels": {"alignments": [9, 10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 25}, {"labels": {"alignments": [9, 10], "responsetype": "followup", "coarseresponse": "nonarg"}, "text_id": "ryxx8ZbFa7", "sid": 26}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "ryxx8ZbFa7", "sid": 27}, {"labels": {"alignments": [12, 13, 14], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 28}, {"labels": {"alignments": [12, 13, 14], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 29}, {"labels": {"alignments": [12, 13, 14], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 30}, {"labels": {"alignments": [12, 13, 14], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 31}, {"labels": {"alignments": [12, 13, 14], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 32}, {"labels": {"alignments": [15], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 33}, {"labels": {"alignments": [15], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 34}, {"labels": {"alignments": [15], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ryxx8ZbFa7", "sid": 35}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "ryxx8ZbFa7", "sid": 36}], "metadata": {"anno": "anno12", "review": "rklz9YLKh7", "rebuttal": "ryxx8ZbFa7", "conference": "ICLR2019", "title": "GO Gradient for Expectation-Based Objectives", "reviewer": "AnonReviewer3", "forum_id": "ryf6Fs09YX", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}}