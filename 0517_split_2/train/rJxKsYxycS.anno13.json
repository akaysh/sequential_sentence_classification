{"review": [{"text_id": "rJxKsYxycS", "sid": 0, "sentence": "The authors propose to meta-learn, using MAML, the mean of an elementwise, input-dependent, multiplicative noise to improve generalization in few-shot learning."}, {"text_id": "rJxKsYxycS", "sid": 1, "sentence": "The motivation is that meta-learning the noise allows to learn how to best perturb examples in order to improve generlization."}, {"text_id": "rJxKsYxycS", "sid": 2, "sentence": "This claim is supported by ample experimental evidence and comparisons against many baselines, as well as additional ablation studies w.r.t design choices of the algorithm itself."}, {"text_id": "rJxKsYxycS", "sid": 3, "sentence": "The paper is well written and easy to read."}, {"text_id": "rJxKsYxycS", "sid": 4, "sentence": "Consequently, I think this is a nice paper and should be accepted."}, {"text_id": "rJxKsYxycS", "sid": 5, "sentence": "Edit (leaving everything else unchanged for now): After reading R3's assessment, I agree with them that it's worrying that the Deterministic Meta-Dropout performs better than baseline MAML - maybe it's an effect of a larger number of parameters in the model?"}, {"text_id": "rJxKsYxycS", "sid": 6, "sentence": "Edit:"}, {"text_id": "rJxKsYxycS", "sid": 7, "sentence": "Thank you for your response."}, {"text_id": "rJxKsYxycS", "sid": 8, "sentence": "I will leave my score as is."}, {"text_id": "rJxKsYxycS", "sid": 9, "sentence": "I would strongly encourage the authors to incorporate the baseline \"(1)\" as proposed by R3 in a future version of the paper as I agree with them that this is a relevant baseline."}], "reviewlabels": [{"text_id": "rJxKsYxycS", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxKsYxycS", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxKsYxycS", "sid": 2, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxKsYxycS", "sid": 3, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxKsYxycS", "sid": 4, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxKsYxycS", "sid": 5, "labels": {"coarse": "Request", "fine": "Request.Clarification", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxKsYxycS", "sid": 6, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxKsYxycS", "sid": 7, "labels": {"coarse": "Social", "fine": "Social", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxKsYxycS", "sid": 8, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxKsYxycS", "sid": 9, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "rJgYVv-PoB", "sid": 0, "sentence": "We sincerely appreciate your constructive comments."}, {"text_id": "rJgYVv-PoB", "sid": 1, "sentence": "We respond to your main concerns below:"}, {"text_id": "rJgYVv-PoB", "sid": 2, "sentence": "1. The Deterministic Meta-Dropout performs better than baseline MAML - maybe it's an effect of a larger number of parameters in the model?"}, {"text_id": "rJgYVv-PoB", "sid": 3, "sentence": "- To demonstrate that strong generalization performance of Meta-Dropout is not the effect of using larger number of model parameters, we doubled the number of channels for the base model and report its performances (MAML(x2))."}, {"text_id": "rJgYVv-PoB", "sid": 4, "sentence": "Models\t\t   #param.\tOmni-1shot\tOmni-5shot\tmimg-1shot\tmimg-5shot"}, {"text_id": "rJgYVv-PoB", "sid": 5, "sentence": "MAML\t\t   x1\t        \t95.23+-0.17\t98.38+-0.07\t49.58+-0.65\t64.55+-0.52"}, {"text_id": "rJgYVv-PoB", "sid": 6, "sentence": "MAML(x2)"}, {"text_id": "rJgYVv-PoB", "sid": 7, "sentence": "x4"}, {"text_id": "rJgYVv-PoB", "sid": 8, "sentence": "94.96+-0.16\t98.36+-0.08"}, {"text_id": "rJgYVv-PoB", "sid": 9, "sentence": "48.19+-0.64"}, {"text_id": "rJgYVv-PoB", "sid": 10, "sentence": "65.84+-0.52"}, {"text_id": "rJgYVv-PoB", "sid": 11, "sentence": "Meta-SGD         x2"}, {"text_id": "rJgYVv-PoB", "sid": 12, "sentence": "96.16+-0.14"}, {"text_id": "rJgYVv-PoB", "sid": 13, "sentence": "98.54+-0.07"}, {"text_id": "rJgYVv-PoB", "sid": 14, "sentence": "48.30+-0.64"}, {"text_id": "rJgYVv-PoB", "sid": 15, "sentence": "65.55+-0.56"}, {"text_id": "rJgYVv-PoB", "sid": 16, "sentence": "Meta-dropout  x2"}, {"text_id": "rJgYVv-PoB", "sid": 17, "sentence": "96.63+-0.13\t98.73+-0.06"}, {"text_id": "rJgYVv-PoB", "sid": 18, "sentence": "51.93+-0.67"}, {"text_id": "rJgYVv-PoB", "sid": 19, "sentence": "67.42+-0.52"}, {"text_id": "rJgYVv-PoB", "sid": 20, "sentence": "The number of parameters of MAML(chx2) is four times of that of MAML, while Meta-dropout is only doubled."}, {"text_id": "rJgYVv-PoB", "sid": 21, "sentence": "Nonetheless, MAML(chx2) does not improve on MAML, demonstrating that the effectiveness of meta-dropout does not simply come from using larger number of parameters."}, {"text_id": "rJgYVv-PoB", "sid": 22, "sentence": "Meta-SGD also doubles the number of parameters in the base MAML model, but is significantly outperformed by Meta-dropout."}, {"text_id": "rJgYVv-PoB", "sid": 23, "sentence": "We want to emphasize that Deterministic meta-dropout is also one of our models, and that its good performance does not hurt our claim on the effectiveness of the multiplicative noise."}, {"text_id": "rJgYVv-PoB", "sid": 24, "sentence": "This is because meta-dropout consists of two parts: meta-learned deterministic multiplicative perturbation and random noise."}, {"text_id": "rJgYVv-PoB", "sid": 25, "sentence": "Thus the deterministic meta-dropout still \u201clearns to perturb\u201d, although not random, and is actually a core component of meta-dropout (See Table 3 in the revision)."}, {"text_id": "rJgYVv-PoB", "sid": 26, "sentence": "Please also see our response to the Reviewer #3, comment #4."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "rJgYVv-PoB", "sid": 0}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJgYVv-PoB", "sid": 1}, {"labels": {"alignments": [5], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJgYVv-PoB", "sid": 2}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJgYVv-PoB", "sid": 3}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJgYVv-PoB", "sid": 4}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJgYVv-PoB", "sid": 5}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJgYVv-PoB", "sid": 6}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJgYVv-PoB", "sid": 7}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJgYVv-PoB", "sid": 8}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJgYVv-PoB", "sid": 9}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJgYVv-PoB", "sid": 10}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJgYVv-PoB", "sid": 11}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJgYVv-PoB", "sid": 12}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJgYVv-PoB", "sid": 13}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJgYVv-PoB", "sid": 14}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJgYVv-PoB", "sid": 15}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJgYVv-PoB", "sid": 16}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJgYVv-PoB", "sid": 17}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJgYVv-PoB", "sid": 18}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJgYVv-PoB", "sid": 19}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJgYVv-PoB", "sid": 20}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJgYVv-PoB", "sid": 21}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJgYVv-PoB", "sid": 22}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJgYVv-PoB", "sid": 23}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJgYVv-PoB", "sid": 24}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJgYVv-PoB", "sid": 25}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJgYVv-PoB", "sid": 26}], "metadata": {"anno": "anno13", "review": "rJxKsYxycS", "rebuttal": "rJgYVv-PoB", "conference": "ICLR2020", "title": "Meta Dropout: Learning to Perturb Latent Features for Generalization", "reviewer": "AnonReviewer2", "forum_id": "BJgd81SYwr", "rating": "8: Accept", "experience_assessment": "I have read many papers in this area."}}