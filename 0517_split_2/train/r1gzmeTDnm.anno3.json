{"review": [{"text_id": "r1gzmeTDnm", "sid": 0, "sentence": "Summary:"}, {"text_id": "r1gzmeTDnm", "sid": 1, "sentence": "The authors present a video prediction model called SAVP that combines a Variational Auto-Encoder (VAE) model with a Generative Adversarial Network (GAN) to produce more realistic and diverse future samples."}, {"text_id": "r1gzmeTDnm", "sid": 2, "sentence": "Deterministic models and certain loss functions such as Mean Squared Error (MSE) will produce"}, {"text_id": "r1gzmeTDnm", "sid": 3, "sentence": "blurry results when making uncertain predictions."}, {"text_id": "r1gzmeTDnm", "sid": 4, "sentence": "GAN predictions on the other hand usually are more visually appealing but often lack diversity, producing just a few modes."}, {"text_id": "r1gzmeTDnm", "sid": 5, "sentence": "The authors propose to combine a VAE model with a GAN objective to combine their strengths: good quality samples (GAN) that cover multiple possible futures (VAE)."}, {"text_id": "r1gzmeTDnm", "sid": 6, "sentence": "Strengths:"}, {"text_id": "r1gzmeTDnm", "sid": 7, "sentence": "[+] GANs are notoriously unstable to train, especially for video."}, {"text_id": "r1gzmeTDnm", "sid": 8, "sentence": "The authors formulate a VAE-GAN model and successfully implement it."}, {"text_id": "r1gzmeTDnm", "sid": 9, "sentence": "Weaknesses:"}, {"text_id": "r1gzmeTDnm", "sid": 10, "sentence": "[-] The combination of VAEs and GANs, while new for videos, had already been proposed for image generation as indicated in the Related Work section and its formulation for video prediction is relatively straightforward given existing VAE (Denton & Fergus 2018) and GAN models (Tulyakov et al. 2018)."}, {"text_id": "r1gzmeTDnm", "sid": 11, "sentence": "[-] The results indicate that SAVP offers a trade-off between the properties of GANs and VAEs, but does not go beyond its individual parts."}, {"text_id": "r1gzmeTDnm", "sid": 12, "sentence": "For example, the experiment of Figure 5 does not show SAVP being significantly more diverse than GANs for KTH (as compared to VAEs)."}, {"text_id": "r1gzmeTDnm", "sid": 13, "sentence": "Furthermore, Figure 6 and Figure 7 in general show SAVP performing worse than SVG (Denton & Fergus 2018), a VAE model with a significantly less complex generator, including for the metric (VGG cosine similarity) that the authors introduce arguing that PSNR and SSIM do not necessarily indicate prediction quality."}, {"text_id": "r1gzmeTDnm", "sid": 14, "sentence": "While the use of a GAN in general will make the results less blurry and visually appealing, it does not necessarily mean that the samples it generates are going to be plausible or better."}, {"text_id": "r1gzmeTDnm", "sid": 15, "sentence": "Since a direct application of video prediction is model-based planning, it seems that plausibility might be as important as sample quality."}, {"text_id": "r1gzmeTDnm", "sid": 16, "sentence": "This work proposes to combine VAEs and GANs in a single model to get the benefits of both models."}, {"text_id": "r1gzmeTDnm", "sid": 17, "sentence": "However, the experiments conducted generally show that SAVP offers only a trade-off between the visual quality of GANs and the coverage of VAEs, and does not show a clear advantage over current VAE models (Denton & Fergus, 2018) that with simpler architectures obtain similar results."}, {"text_id": "r1gzmeTDnm", "sid": 18, "sentence": "While the presentation is clear and the evaluation of the model is thorough, I am unsure of the significance of the proposed method."}, {"text_id": "r1gzmeTDnm", "sid": 19, "sentence": "In order to better assess this model and compare it to its individual parts and other VAE models, could the authors:"}, {"text_id": "r1gzmeTDnm", "sid": 20, "sentence": "1) Compare SAVP to the SVG-LP/FP model on a controlled synthetic dataset such as Stochastic Moving MNIST (Denton & Fergus, 2018)?"}, {"text_id": "r1gzmeTDnm", "sid": 21, "sentence": "2) Comment on the plausibility of the samples generated by SAVP? Do some samples show imagined objects \u2013 implausible interactions for the robotic arm dataset? If so, what would be the advantage over blurry but plausible generations of a VAE?"}], "reviewlabels": [{"text_id": "r1gzmeTDnm", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1gzmeTDnm", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1gzmeTDnm", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "r1gzmeTDnm", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "r1gzmeTDnm", "sid": 4, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1gzmeTDnm", "sid": 5, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1gzmeTDnm", "sid": 6, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1gzmeTDnm", "sid": 7, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1gzmeTDnm", "sid": 8, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1gzmeTDnm", "sid": 9, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1gzmeTDnm", "sid": 10, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Other", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1gzmeTDnm", "sid": 11, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "r1gzmeTDnm", "sid": 12, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "r1gzmeTDnm", "sid": 13, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1gzmeTDnm", "sid": 14, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "r1gzmeTDnm", "sid": 15, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "r1gzmeTDnm", "sid": 16, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1gzmeTDnm", "sid": 17, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Meaningful Comparison", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1gzmeTDnm", "sid": 18, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Motivation/Impact", "pol": "N-Negative"}, "secondarylabels": [{"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "P-Positive"}], "merge-with-prior": false}, {"text_id": "r1gzmeTDnm", "sid": 19, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1gzmeTDnm", "sid": 20, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "r1gzmeTDnm", "sid": 21, "labels": {"coarse": "Request", "fine": "Request.Clarification", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "rJexhWRXCm", "sid": 0, "sentence": "We thank reviewer 1 for the detailed feedback."}, {"text_id": "rJexhWRXCm", "sid": 1, "sentence": "In this response, we clarify the accuracy-realism trade-off, revise the accuracy metrics, indicate reruns and new experiments, and address the individual questions."}, {"text_id": "rJexhWRXCm", "sid": 2, "sentence": "We updated Section 4.4 to indicate that it is to be expected that, although our SAVP model improves on diversity and realism, it also performs worse in accuracy compared to pure VAE models (both our own ablation and SVG)."}, {"text_id": "rJexhWRXCm", "sid": 3, "sentence": "A recent result [1] proves that there is a fundamental tradeoff between accuracy and realism, for all problems with inherent ambiguity."}, {"text_id": "rJexhWRXCm", "sid": 4, "sentence": "In fact, a recent challenge held at ECCV 2018 in such a problem [2] evaluates all algorithms on both of these axes, as neither adequately captures performance."}, {"text_id": "rJexhWRXCm", "sid": 5, "sentence": "Although the SVG generator is simpler than ours, ours is just a simple variation from Ebert et al. (2017)."}, {"text_id": "rJexhWRXCm", "sid": 6, "sentence": "Since proposing a strong generator architecture is not the goal of this paper,"}, {"text_id": "rJexhWRXCm", "sid": 7, "sentence": "any video generator (including the one from Denton & Fergus (2018)) could be used with our losses."}, {"text_id": "rJexhWRXCm", "sid": 8, "sentence": "We added this clarification to Section 3.4."}, {"text_id": "rJexhWRXCm", "sid": 9, "sentence": "Instead, we provide a systematic analysis of the effect of the loss function on this task (which could be applied to any generator)."}, {"text_id": "rJexhWRXCm", "sid": 10, "sentence": "It's also worth noting that with a simpler feed-forward posterior and a unit Gaussian prior, our VAE ablation and SVG achieve similar performance on various metrics."}, {"text_id": "rJexhWRXCm", "sid": 11, "sentence": "We added Section 3.5 to point out the differences between the VAE component of our model and prior work."}, {"text_id": "rJexhWRXCm", "sid": 12, "sentence": "We have included a revised plot in Figure 14 (note that this temporary plot will be incorporated into Figure 6), where we use the official implementation of SSIM and replace the VGG metric with the LPIPS metric (Zhang et al., 2018)."}, {"text_id": "rJexhWRXCm", "sid": 13, "sentence": "LPIPS linearly calibrates AlexNet feature space to better match human perceptual similarity judgements."}, {"text_id": "rJexhWRXCm", "sid": 14, "sentence": "Aside for the first two predicted frames, our VAE ablation and the SVG model both achieve similar SSIM and LPIPS."}, {"text_id": "rJexhWRXCm", "sid": 15, "sentence": "After examining the KTH results further, we realized that our results are likely weaker than they should have been, because we did not use the same preprocessing as prior work."}, {"text_id": "rJexhWRXCm", "sid": 16, "sentence": "The experiments from our original submission cropped the videos into a square before resizing, and thus discarded information from the sides of the video."}, {"text_id": "rJexhWRXCm", "sid": 17, "sentence": "We are currently rerunning the KTH experiments and we plan to update the results in the paper."}, {"text_id": "rJexhWRXCm", "sid": 18, "sentence": "We also didn't choose particular hyperparameters to ensure diversity for our models, and we expect some improvement in diversity in the new sets of experiments."}, {"text_id": "rJexhWRXCm", "sid": 19, "sentence": "Although the combination of VAEs and GANs have been explored recently for conditional image generation (Zhang et al. 2018), the video prediction task is substantially different, with unique challenges, due to spatiotemporal relationships and inherent compounding uncertainty of the future."}, {"text_id": "rJexhWRXCm", "sid": 20, "sentence": "Furthermore, while the individual components have indeed been known for video prediction, their combination is novel and not present in prior work, and we demonstrate that this produces state-of-the-art results in terms of diversity and realism."}, {"text_id": "rJexhWRXCm", "sid": 21, "sentence": "In addition, this work provides a detailed comparison of the effect of the losses on the various metrics."}, {"text_id": "rJexhWRXCm", "sid": 22, "sentence": "Furthermore, we are currently running experiments for various weightings of the KL loss and the adversarial loss, and we plan to include additional results that illustrate the trade-offs based on these hyperparameters."}, {"text_id": "rJexhWRXCm", "sid": 23, "sentence": "Although MoCoGAN performs well for videos with a single frame-centered actor, it struggles with multiple simultaneously moving entities."}, {"text_id": "rJexhWRXCm", "sid": 24, "sentence": "The authors of MoCoGAN also mentioned in personal correspondence that the conditional version (i.e. video prediction) was significantly harder to train."}, {"text_id": "rJexhWRXCm", "sid": 25, "sentence": "We noticed the same in earlier iterations of our model."}, {"text_id": "rJexhWRXCm", "sid": 26, "sentence": "In our case, we found that the model would degenerate to static videos or videos with a cyclic flickering artifact, which are issues that aren't a problem in conditional image generation."}, {"text_id": "rJexhWRXCm", "sid": 27, "sentence": "We added details to Section 3.4 describing the importance of a few components, such as spectral normalization and not conditioning the discriminator in the ground-truth context frames."}, {"text_id": "rJexhWRXCm", "sid": 28, "sentence": "The purpose of adding adversarial losses to a pure VAE is to improve on blurry predictions where the latent variables alone cannot capture the uncertainty of the data."}, {"text_id": "rJexhWRXCm", "sid": 29, "sentence": "However, that is typically not the case of synthetic datasets."}, {"text_id": "rJexhWRXCm", "sid": 30, "sentence": "In early experiments, we trained our pure VAE model on the stochastic shape movement dataset from Babaeizadeh et al. (2018), and our pure VAE was able to model the dataset without any blur and with perfect separation of the possible futures."}, {"text_id": "rJexhWRXCm", "sid": 31, "sentence": "We agree that plausibility is indeed important, and that's what our human subject studies try to capture."}, {"text_id": "rJexhWRXCm", "sid": 32, "sentence": "Since we provide predictions of the whole sequence to the human evaluator, we are not only evaluating for image realism but also for plausibility of the dynamics."}, {"text_id": "rJexhWRXCm", "sid": 33, "sentence": "Unlike the VAE models that implausibly erase the small objects that are being pushed in the BAIR dataset, our SAVP model moves those objects in a more plausible way."}, {"text_id": "rJexhWRXCm", "sid": 34, "sentence": "[1] Yochai Blau and Tomer Michaeli. The perception-distortion tradeoff. In Conference on Vision and Pattern Recognition (CVPR), 2018. https://arxiv.org/abs/1711.06077"}, {"text_id": "rJexhWRXCm", "sid": 35, "sentence": "[2] Yochai Blau, Roey Mechrez, Radu Timofte, Tomer Michaeli, and Lihi Zelnik-Manor. 2018 PIRM Challenge on Perceptual Image Super-resolution. In Perceptual Image Restoration and Manipulation (PIRM) workshop at ECCV 2018."}, {"text_id": "rJexhWRXCm", "sid": 36, "sentence": "https://arxiv.org/abs/1809.07517"}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "rJexhWRXCm", "sid": 0}, {"labels": {"alignments": [], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "rJexhWRXCm", "sid": 1}, {"labels": {"alignments": [11, 12, 13], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 2}, {"labels": {"alignments": [11, 12, 13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 3}, {"labels": {"alignments": [11, 12, 13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 4}, {"labels": {"alignments": [11, 12, 13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 5}, {"labels": {"alignments": [11, 12, 13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 6}, {"labels": {"alignments": [11, 12, 13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 7}, {"labels": {"alignments": [11, 12, 13], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 8}, {"labels": {"alignments": [11, 12, 13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 9}, {"labels": {"alignments": [11, 12, 13], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 10}, {"labels": {"alignments": [16, 17, 18], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 11}, {"labels": {"alignments": [16, 17, 18], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 12}, {"labels": {"alignments": [15, 16, 17, 18], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 13}, {"labels": {"alignments": [15, 16, 17, 18], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 14}, {"labels": {"alignments": [15, 16, 17, 18], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 15}, {"labels": {"alignments": [15, 16, 17, 18], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 16}, {"labels": {"alignments": [15, 16, 17, 18], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 17}, {"labels": {"alignments": [15, 16, 17, 18], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 18}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 19}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 20}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 21}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 22}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 23}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 24}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 25}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 26}, {"labels": {"alignments": [10], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 27}, {"labels": {"alignments": [10, 14, 15, 16, 17, 18], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 28}, {"labels": {"alignments": [10, 14, 15, 16, 17, 18], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 29}, {"labels": {"alignments": [10, 14, 15, 16, 17, 18], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 30}, {"labels": {"alignments": [10, 21], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 31}, {"labels": {"alignments": [10, 21], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 32}, {"labels": {"alignments": [10, 21], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJexhWRXCm", "sid": 33}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "rJexhWRXCm", "sid": 34}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "rJexhWRXCm", "sid": 35}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "rJexhWRXCm", "sid": 36}], "metadata": {"anno": "anno3", "review": "r1gzmeTDnm", "rebuttal": "rJexhWRXCm", "conference": "ICLR2019", "title": "Stochastic Adversarial Video Prediction", "reviewer": "AnonReviewer1", "forum_id": "HyEl3o05Fm", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}}