{"review": [{"text_id": "ryg_N1TK2Q", "sid": 0, "sentence": "This paper studies the dynamics-based curiosity intrinsic reward where the agent is rewarded highly in states where the forward dynamic prediction errors are high in an embedding space (either due to complexity of the state or unfamiliarity)."}, {"text_id": "ryg_N1TK2Q", "sid": 1, "sentence": "Overall I like the paper, it's systematic and follows a series of practical considerations and step-by-step experimentations."}, {"text_id": "ryg_N1TK2Q", "sid": 2, "sentence": "One of the main area which is missing in the paper is the comparison to two other class of RL methods: count-based exploration and novelty search."}, {"text_id": "ryg_N1TK2Q", "sid": 3, "sentence": "While the section 4 has a discussion on related papers, there's no systematic experimental comparison across these methods."}, {"text_id": "ryg_N1TK2Q", "sid": 4, "sentence": "In sec. 4, there's a reference to an initial set of experiments with count-based methods without much details."}, {"text_id": "ryg_N1TK2Q", "sid": 5, "sentence": "Another area of improvement is the experiments around VAE."}, {"text_id": "ryg_N1TK2Q", "sid": 6, "sentence": "While the paper shows experimentally that they aren't as successful as the RFs or IDFs, there's no further discussion on the reasons for poor performance."}, {"text_id": "ryg_N1TK2Q", "sid": 7, "sentence": "Also it's not clear from the details in the paper what are the architectures for the VAE and RFs (there's a reference to the code but would've been better to have sufficient details in the paper)."}, {"text_id": "ryg_N1TK2Q", "sid": 8, "sentence": "An interesting area for future work could be on early stopping techniques for embedding training - it seems that RFs perform well without any training while in some scenarios the IDFs work overall the best."}, {"text_id": "ryg_N1TK2Q", "sid": 9, "sentence": "So it would be interesting to explore how much training is needed for the embedding model."}, {"text_id": "ryg_N1TK2Q", "sid": 10, "sentence": "RFs are never trained and IDFs are continuously trained."}, {"text_id": "ryg_N1TK2Q", "sid": 11, "sentence": "So maybe somewhere in between could be the sweet spot with training for a short while and then fixing the features."}], "reviewlabels": [{"text_id": "ryg_N1TK2Q", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryg_N1TK2Q", "sid": 1, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryg_N1TK2Q", "sid": 2, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Meaningful Comparison", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryg_N1TK2Q", "sid": 3, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Meaningful Comparison", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryg_N1TK2Q", "sid": 4, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryg_N1TK2Q", "sid": 5, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryg_N1TK2Q", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Meaningful Comparison", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryg_N1TK2Q", "sid": 7, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryg_N1TK2Q", "sid": 8, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Soundness/Correctness", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryg_N1TK2Q", "sid": 9, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Soundness/Correctness", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryg_N1TK2Q", "sid": 10, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryg_N1TK2Q", "sid": 11, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "rJxwGHYQRm", "sid": 0, "sentence": "We thank you for the constructive feedback and are glad that you enjoyed the paper."}, {"text_id": "rJxwGHYQRm", "sid": 1, "sentence": "Here we discuss some of your comments."}, {"text_id": "rJxwGHYQRm", "sid": 2, "sentence": "R1: \"missing in the paper is the comparison to two other class of RL methods: count-based exploration... In sec. 4, there's a reference to an initial set of experiments with count-based methods without much details.\""}, {"text_id": "rJxwGHYQRm", "sid": 3, "sentence": "=> We chose to focus on dynamics-based approaches in this paper because we found them more straightforward to efficiently parallelize than the published pseudo-count methods."}, {"text_id": "rJxwGHYQRm", "sid": 4, "sentence": "This allows us to be able to run more and larger experiments on many environments."}, {"text_id": "rJxwGHYQRm", "sid": 5, "sentence": "Interestingly, increased parallelization also significantly helped the exploration strategies as shown in Figure 3(a)."}, {"text_id": "rJxwGHYQRm", "sid": 6, "sentence": "Further, we will add the details of preliminary experiments using pseudo-count in the supplementary."}, {"text_id": "rJxwGHYQRm", "sid": 7, "sentence": "In particular, we were not able to find any official public implementation of the pseudo-count methods."}, {"text_id": "rJxwGHYQRm", "sid": 8, "sentence": "We experimented with a third party implementation trying to see if it could play Breakout without extrinsic rewards, but did not achieve sufficient success and found it to be too slow for scaling it up to a large-scale study."}, {"text_id": "rJxwGHYQRm", "sid": 9, "sentence": "R1: \"the experiments around VAE... While the paper shows experimentally that they aren't as successful... there's no further discussion on the reasons for poor performance.\""}, {"text_id": "rJxwGHYQRm", "sid": 10, "sentence": "=> We found that VAEs overall worked well and were sometimes better than other representation learning methods, but often were causing instability at training."}, {"text_id": "rJxwGHYQRm", "sid": 11, "sentence": "We don't claim such instability is an inherent property of the VAE feature learning method, but probably stems from the continually changing data distribution as agent makes progress."}, {"text_id": "rJxwGHYQRm", "sid": 12, "sentence": "Indeed modeling the density of a non-stationary distribution, with modes appearing and disappearing, is a challenging and an active research problem."}, {"text_id": "rJxwGHYQRm", "sid": 13, "sentence": "We will clarify this in the final version."}, {"text_id": "rJxwGHYQRm", "sid": 14, "sentence": "R1: \"An interesting area for future work could be on early stopping techniques for embedding training\u2026 maybe somewhere in between could be the sweet spot with training\""}, {"text_id": "rJxwGHYQRm", "sid": 15, "sentence": "=> Thank you for the excellent suggestion."}, {"text_id": "rJxwGHYQRm", "sid": 16, "sentence": "We agree that there may be some optimal tradeoff between features that are stable and features that adapt to the environment."}, {"text_id": "rJxwGHYQRm", "sid": 17, "sentence": "Such tradeoffs would be interesting to investigate, and might be crucial to getting learned features to perform significantly better than fixed random features."}, {"text_id": "rJxwGHYQRm", "sid": 18, "sentence": "We will add this in the discussion/future work section of paper."}, {"text_id": "rJxwGHYQRm", "sid": 19, "sentence": "R1: \"What are the architectures for the VAE and RFs (there's a reference to the code but would've been better to have sufficient details in the paper).\""}, {"text_id": "rJxwGHYQRm", "sid": 20, "sentence": "=> Thank you. We will add more details on the architectures to the appendix."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "rJxwGHYQRm", "sid": 0}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJxwGHYQRm", "sid": 1}, {"labels": {"alignments": [2, 3, 4], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJxwGHYQRm", "sid": 2}, {"labels": {"alignments": [2, 3, 4], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "rJxwGHYQRm", "sid": 3}, {"labels": {"alignments": [2, 3, 4], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "rJxwGHYQRm", "sid": 4}, {"labels": {"alignments": [2, 3, 4], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJxwGHYQRm", "sid": 5}, {"labels": {"alignments": [2, 3, 4], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "rJxwGHYQRm", "sid": 6}, {"labels": {"alignments": [2, 3, 4], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "rJxwGHYQRm", "sid": 7}, {"labels": {"alignments": [2, 3, 4], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "rJxwGHYQRm", "sid": 8}, {"labels": {"alignments": [5, 6], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJxwGHYQRm", "sid": 9}, {"labels": {"alignments": [5, 6], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxwGHYQRm", "sid": 10}, {"labels": {"alignments": [5, 6], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxwGHYQRm", "sid": 11}, {"labels": {"alignments": [5, 6], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxwGHYQRm", "sid": 12}, {"labels": {"alignments": [5, 6], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "rJxwGHYQRm", "sid": 13}, {"labels": {"alignments": [8, 9, 10, 11], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJxwGHYQRm", "sid": 14}, {"labels": {"alignments": [8, 9, 10, 11], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "rJxwGHYQRm", "sid": 15}, {"labels": {"alignments": [8, 9, 10, 11], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxwGHYQRm", "sid": 16}, {"labels": {"alignments": [8, 9, 10, 11], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJxwGHYQRm", "sid": 17}, {"labels": {"alignments": [8, 9, 10, 11], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "rJxwGHYQRm", "sid": 18}, {"labels": {"alignments": [7], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJxwGHYQRm", "sid": 19}, {"labels": {"alignments": [7], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "rJxwGHYQRm", "sid": 20}], "metadata": {"anno": "anno2", "review": "ryg_N1TK2Q", "rebuttal": "rJxwGHYQRm", "conference": "ICLR2019", "title": "Large-Scale Study of Curiosity-Driven Learning", "reviewer": "AnonReviewer1", "forum_id": "rJNwDjAqYX", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}}