{"review": [{"text_id": "rJxPUFHc3m", "sid": 0, "sentence": "In this paper the authors introduce a new technique for softmax inference."}, {"text_id": "rJxPUFHc3m", "sid": 1, "sentence": "In a multiclass setting, the idea is to take the output of a NN and turn it into a gating function to choose one expert."}, {"text_id": "rJxPUFHc3m", "sid": 2, "sentence": "Then, given the expert, output a particular category."}, {"text_id": "rJxPUFHc3m", "sid": 3, "sentence": "The first level of sparsity comes from the first expert."}, {"text_id": "rJxPUFHc3m", "sid": 4, "sentence": "The second level of sparsity comes from every expert only outputting a limited set of output categories."}, {"text_id": "rJxPUFHc3m", "sid": 5, "sentence": "The paper is easy to understand but several sections (starting from section 2) could use an english language review (e.g. \"search right\" -> \"search for the right\", \"predict next word\" -> \"predict the next word\", ...) In section 3, can you be more specific about the gains in training versus inference time?"}, {"text_id": "rJxPUFHc3m", "sid": 6, "sentence": "I believe the results all relate to inference but it would be good to get an overview of the impact of training time as well."}, {"text_id": "rJxPUFHc3m", "sid": 7, "sentence": "You motivate some of the work by the fact that the experts have overlapping outputs."}, {"text_id": "rJxPUFHc3m", "sid": 8, "sentence": "Maybe in section 3.7 you can address how often that occurs as well?"}, {"text_id": "rJxPUFHc3m", "sid": 9, "sentence": "Nits:"}, {"text_id": "rJxPUFHc3m", "sid": 10, "sentence": "- it wasn't clear how the sparsity percentage on page 3 was defined?"}, {"text_id": "rJxPUFHc3m", "sid": 11, "sentence": "- can you motivate why you are not using perplexity in section 3.2?"}], "reviewlabels": [{"text_id": "rJxPUFHc3m", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxPUFHc3m", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxPUFHc3m", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxPUFHc3m", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxPUFHc3m", "sid": 4, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxPUFHc3m", "sid": 5, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [{"coarse": "Request", "fine": "Request.Explanation", "asp": "Replicability", "pol": "N-Negative"}], "merge-with-prior": false}, {"text_id": "rJxPUFHc3m", "sid": 6, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxPUFHc3m", "sid": 7, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxPUFHc3m", "sid": 8, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxPUFHc3m", "sid": 9, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxPUFHc3m", "sid": 10, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Replicability", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJxPUFHc3m", "sid": 11, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "HJxF95J5aX", "sid": 0, "sentence": "Dear Reviewer:"}, {"text_id": "HJxF95J5aX", "sid": 1, "sentence": "Thank you for your valuable comments."}, {"text_id": "HJxF95J5aX", "sid": 2, "sentence": "We have addressed typos in the revision accordingly."}, {"text_id": "HJxF95J5aX", "sid": 3, "sentence": "And please find our response as follows."}, {"text_id": "HJxF95J5aX", "sid": 4, "sentence": "-  Can you be more specific about the gains in training versus inference time?"}, {"text_id": "HJxF95J5aX", "sid": 5, "sentence": "We would like to emphasize that the our goal is to speed up the inference time for softmax, so we do not include any comparisons in terms of training time."}, {"text_id": "HJxF95J5aX", "sid": 6, "sentence": "According to our experiments, most speedup can be achieved in few epochs (given all other layers are pre-trained) so that the training time increase is not significant compared to the original one."}, {"text_id": "HJxF95J5aX", "sid": 7, "sentence": "- You motivate some of the work by the fact that the experts have overlapping outputs. Maybe in section 3.7 you can address how often that occurs as well?"}, {"text_id": "HJxF95J5aX", "sid": 8, "sentence": "Thanks for the suggestion."}, {"text_id": "HJxF95J5aX", "sid": 9, "sentence": "We demonstrate that ambiguous words are often overlapped between clusters as illustrated in Figure 3(b)."}, {"text_id": "HJxF95J5aX", "sid": 10, "sentence": "We added one more Figure in Appendix B, Figure (b), to demonstrate the distribution of overlapping."}, {"text_id": "HJxF95J5aX", "sid": 11, "sentence": "- It wasn't clear how the sparsity percentage on page 3 was defined?"}, {"text_id": "HJxF95J5aX", "sid": 12, "sentence": "Sorry for the possible confusion."}, {"text_id": "HJxF95J5aX", "sid": 13, "sentence": "The sparsity in page 3 means the percentage of pruned words."}, {"text_id": "HJxF95J5aX", "sid": 14, "sentence": "We have added more clarifications in the revised version."}, {"text_id": "HJxF95J5aX", "sid": 15, "sentence": "- Can you motivate why you are not using perplexity in section 3.2?"}, {"text_id": "HJxF95J5aX", "sid": 16, "sentence": "We use top-k accuracy, instead of perplexity, because approximating top-k is required for most inference tasks in practice (see [1])."}, {"text_id": "HJxF95J5aX", "sid": 17, "sentence": "Perplexity captures the normalized log-likelihood of all possible words, while top-k accuracy is a better measure for inference speedup for top-k retrieval."}, {"text_id": "HJxF95J5aX", "sid": 18, "sentence": "For example, in some extreme cases, if a word only has a very small probability which makes it unpredictable at all (i.e. couldn\u2019t be retrieved by top-k for any reasonably small k)"}, {"text_id": "HJxF95J5aX", "sid": 19, "sentence": ", it could still have a huge impact in terms of perplexity, but has a much smaller impact on top-k accuracy, which seems more reasonable given the goal of top-k retrieval."}, {"text_id": "HJxF95J5aX", "sid": 20, "sentence": "[1] Asymmetric LSH (ALSH) for Sublinear Time Maximum Inner Product Search (MIPS), NIPS 2014"}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "HJxF95J5aX", "sid": 0}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "HJxF95J5aX", "sid": 1}, {"labels": {"alignments": [5], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "HJxF95J5aX", "sid": 2}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "HJxF95J5aX", "sid": 3}, {"labels": {"alignments": [5], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "HJxF95J5aX", "sid": 4}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HJxF95J5aX", "sid": 5}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HJxF95J5aX", "sid": 6}, {"labels": {"alignments": [7, 8], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "HJxF95J5aX", "sid": 7}, {"labels": {"alignments": [7, 8], "responsetype": "concede-criticism", "coarseresponse": "concur"}, "text_id": "HJxF95J5aX", "sid": 8}, {"labels": {"alignments": [7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HJxF95J5aX", "sid": 9}, {"labels": {"alignments": [7, 8], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "HJxF95J5aX", "sid": 10}, {"labels": {"alignments": [10], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "HJxF95J5aX", "sid": 11}, {"labels": {"alignments": [10], "responsetype": "concede-criticism", "coarseresponse": "concur"}, "text_id": "HJxF95J5aX", "sid": 12}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HJxF95J5aX", "sid": 13}, {"labels": {"alignments": [10], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "HJxF95J5aX", "sid": 14}, {"labels": {"alignments": [11], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "HJxF95J5aX", "sid": 15}, {"labels": {"alignments": [11], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HJxF95J5aX", "sid": 16}, {"labels": {"alignments": [11], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HJxF95J5aX", "sid": 17}, {"labels": {"alignments": [11], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HJxF95J5aX", "sid": 18}, {"labels": {"alignments": [11], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HJxF95J5aX", "sid": 19}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "HJxF95J5aX", "sid": 20}], "metadata": {"anno": "anno10", "review": "rJxPUFHc3m", "rebuttal": "HJxF95J5aX", "conference": "ICLR2019", "title": "Doubly Sparse: Sparse Mixture of Sparse Experts for Efficient Softmax Inference", "reviewer": "AnonReviewer1", "forum_id": "rJl2E3AcF7", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}}