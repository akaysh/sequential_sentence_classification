{"review": [{"text_id": "BkgPU07CFS", "sid": 0, "sentence": "The paper studies self-supervised learning from very few unlabeled images, down to the extreme case where only a single image is used for training."}, {"text_id": "BkgPU07CFS", "sid": 1, "sentence": "From the few/single image(s) available for training, a data set of the same size as some unmodified reference data set (ImageNet, Cifar-10/100) is generated through heavy data augmentation (cropping, scaling, rotation, contrast changes, adding noise)."}, {"text_id": "BkgPU07CFS", "sid": 2, "sentence": "Three popular self-supervised learning algorithms are then trained on this data sets, namely (Bi)GAN, RotNet, and DeepCluster, and the linear probing accuracy on different blocks is compared to that obtained by training the same methods on the reference data sets."}, {"text_id": "BkgPU07CFS", "sid": 3, "sentence": "The linear probing accuracy from the first few conv layers of the network trained on the single/few image data set is found to be comparable to or better than that of the same model trained on the full reference data set."}, {"text_id": "BkgPU07CFS", "sid": 4, "sentence": "I enjoyed the paper; it addresses the interesting setting of an extremely small data set which complements the large number of studies on scaling up self-supervised learning algorithms."}, {"text_id": "BkgPU07CFS", "sid": 5, "sentence": "I think it is not extremely surprising that using the proposed strategy allows to learn low level features as captured by the first few layers, but I think it is worth studying and quantifying."}, {"text_id": "BkgPU07CFS", "sid": 6, "sentence": "The experiments are carefully described and presented, and the paper is well-written."}, {"text_id": "BkgPU07CFS", "sid": 7, "sentence": "Here are a few questions and concerns:"}, {"text_id": "BkgPU07CFS", "sid": 8, "sentence": "- How much does the image matter for the single-image data set?"}, {"text_id": "BkgPU07CFS", "sid": 9, "sentence": "The selected images A and B are of very high entropy and show a lot of different objects (image A) and animals (image B). How do the results change if e.g. a landscape image or an abstract architecture photo is used?"}, {"text_id": "BkgPU07CFS", "sid": 10, "sentence": "- How general is the proposed approach? How likely is it to generalize to other approaches such as Jigsaw (Doersch et al., 2015) and Exemplar (Dosovitskiy et al., 2016)? It would be good to comment on this."}, {"text_id": "BkgPU07CFS", "sid": 11, "sentence": "- [1] found that the network architecture for self-supervised learning can matter a lot, and that by using a ResNet architecture, performance of SSL methods can be significantly improved."}, {"text_id": "BkgPU07CFS", "sid": 12, "sentence": "In particular, the linear probing accuracy appears to be often monotonic as a function of the depth of the layer it is computed from."}, {"text_id": "BkgPU07CFS", "sid": 13, "sentence": "This is in contrast to what is observed for AlexNet in Tables 2 and 3, where the conv5 accuracy is lower than the conv4."}, {"text_id": "BkgPU07CFS", "sid": 14, "sentence": "It would therefore be instructive to add experiments for ResNet to see how well the results generalize to other network architectures."}, {"text_id": "BkgPU07CFS", "sid": 15, "sentence": "- Does the MonoGAN exhibit stable training dynamics comparable to training WGAN on CIFAR-10, or do the training dynamics change on the single-image data set?"}, {"text_id": "BkgPU07CFS", "sid": 16, "sentence": "Overall, I\u2019m leaning towards accepting the paper, but it would be important to see how well the experiments generalize to i) ResNet and ii) other (lower entropy) input images."}, {"text_id": "BkgPU07CFS", "sid": 17, "sentence": "[1] Kolesnikov, A., Zhai, X. and Beyer, L., 2019. Revisiting self-supervised visual representation learning."}, {"text_id": "BkgPU07CFS", "sid": 18, "sentence": "arXiv preprint arXiv:1901.09005."}, {"text_id": "BkgPU07CFS", "sid": 19, "sentence": "---"}, {"text_id": "BkgPU07CFS", "sid": 20, "sentence": "Update after rebuttal:"}, {"text_id": "BkgPU07CFS", "sid": 21, "sentence": "I thank the authors for their detailed response."}, {"text_id": "BkgPU07CFS", "sid": 22, "sentence": "I appreciate the efforts of the authors into investigating the issues raised, the described experiments sound promising."}, {"text_id": "BkgPU07CFS", "sid": 23, "sentence": "Unfortunately, the new results are not presented in the revision."}, {"text_id": "BkgPU07CFS", "sid": 24, "sentence": "I will therefore keep my rating."}], "reviewlabels": [{"text_id": "BkgPU07CFS", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgPU07CFS", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgPU07CFS", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgPU07CFS", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgPU07CFS", "sid": 4, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgPU07CFS", "sid": 5, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgPU07CFS", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgPU07CFS", "sid": 7, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgPU07CFS", "sid": 8, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgPU07CFS", "sid": 9, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgPU07CFS", "sid": 10, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgPU07CFS", "sid": 11, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgPU07CFS", "sid": 12, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgPU07CFS", "sid": 13, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgPU07CFS", "sid": 14, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgPU07CFS", "sid": 15, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgPU07CFS", "sid": 16, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgPU07CFS", "sid": 17, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "BkgPU07CFS", "sid": 18, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "BkgPU07CFS", "sid": 19, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgPU07CFS", "sid": 20, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgPU07CFS", "sid": 21, "labels": {"coarse": "Social", "fine": "Social", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgPU07CFS", "sid": 22, "labels": {"coarse": "Social", "fine": "Social", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgPU07CFS", "sid": 23, "labels": {"coarse": "Social", "fine": "Social", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BkgPU07CFS", "sid": 24, "labels": {"coarse": "Social", "fine": "Social", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "BJx7C1bfjH", "sid": 0, "sentence": "We thank the reviewer for their time and their clear understanding of the key aspects of the paper."}, {"text_id": "BJx7C1bfjH", "sid": 1, "sentence": "We address the reviewer\u2019s questions in the following:"}, {"text_id": "BJx7C1bfjH", "sid": 2, "sentence": ">  How much does the image matter for the single-image data set?"}, {"text_id": "BJx7C1bfjH", "sid": 3, "sentence": "The reviewer raises an important point about the tested single images."}, {"text_id": "BJx7C1bfjH", "sid": 4, "sentence": "Less crowded images could lead to many patches having no gradients (e.g. showing only the sky), leading to a failure of at least RotNet, if not also BiGAN on many samples of the augmented dataset."}, {"text_id": "BJx7C1bfjH", "sid": 5, "sentence": "Our image choices were thus motivated by striving for simplicity and not further adding a pipeline that would, for example, extract only patches with sufficiently large image gradients."}, {"text_id": "BJx7C1bfjH", "sid": 6, "sentence": "We are training DeepCluster now on a significantly less busy image and will report results in the coming days."}, {"text_id": "BJx7C1bfjH", "sid": 7, "sentence": ">  How general is the proposed approach?"}, {"text_id": "BJx7C1bfjH", "sid": 8, "sentence": "We believe that this method will work well for pretext tasks that rely on learning via detecting and learning invariances, such as Exemplar [1], Colorization [2], and Noise-as-targets [3]."}, {"text_id": "BJx7C1bfjH", "sid": 9, "sentence": "Methods such as Context [4] and Jigsaw [5] could potentially work less well as they would potentially easily find a way to cheat given the limited amount of original data of one image."}, {"text_id": "BJx7C1bfjH", "sid": 10, "sentence": "However, as the authors note in the paper cited by the reviewer, the accuracy of a pretext task does not translate to downstream task performances, so even a method that is simple on one image\u2019s patches does not necessarily fail."}, {"text_id": "BJx7C1bfjH", "sid": 11, "sentence": "This is an interesting avenue for research and we hope that this paper could inspire follow-up work on this topic."}, {"text_id": "BJx7C1bfjH", "sid": 12, "sentence": "> [1] found that the network architecture for self-supervised learning can matter a lot, and that by using a ResNet architecture, performance of SSL methods can be significantly improved."}, {"text_id": "BJx7C1bfjH", "sid": 13, "sentence": "Indeed, the paper mentioned by the reviewer shows that the performance of various self-supervised methods for ResNets does not degrade with the depth as it does for VGG and AlexNets due to the skip-connections."}, {"text_id": "BJx7C1bfjH", "sid": 14, "sentence": "However, as ResNets have not been originally used to train the methods analyzed in our paper, we have stayed in the bounds that are required for fair comparisons and only used AlexNet."}, {"text_id": "BJx7C1bfjH", "sid": 15, "sentence": "We agree with the reviewer that it would be good to check if ResNets, in general, can also be trained in such a manner (e.g. could global pooling destroy the signal?), so we are running an experiment on a ResNet-18 and will report results in the upcoming days."}, {"text_id": "BJx7C1bfjH", "sid": 16, "sentence": "> Does the MonoGAN exhibit stable training dynamics comparable to training WGAN on CIFAR-10, or do the training dynamics change on the single-image data set?"}, {"text_id": "BJx7C1bfjH", "sid": 17, "sentence": "MonoGAN trained without any exploding gradients or other problems frequently encountered by GANs."}, {"text_id": "BJx7C1bfjH", "sid": 18, "sentence": "As we have suggested in the paper, this might be due to the fact that image-patches from one image follow a simpler distribution than in-the-wild images of a complete dataset."}, {"text_id": "BJx7C1bfjH", "sid": 19, "sentence": "\u2014"}, {"text_id": "BJx7C1bfjH", "sid": 20, "sentence": "[1] A. Dosovitskiy et al. \"Discriminative unsupervised feature learning with exemplar convolutional neural networks.\" TPAMI 2015"}, {"text_id": "BJx7C1bfjH", "sid": 21, "sentence": "[2] R. Zhang et al. \"Colorful image colorization.\" ECCV 2016."}, {"text_id": "BJx7C1bfjH", "sid": 22, "sentence": "[3] P. Bojanowski et al. \"Unsupervised learning by predicting noise.\" ICML 2017."}, {"text_id": "BJx7C1bfjH", "sid": 23, "sentence": "[4] D. Pathak et al. \u201cContext Encoders: Feature Learning by Inpainting\". CVPR 2016."}, {"text_id": "BJx7C1bfjH", "sid": 24, "sentence": "[5] M. Noroozi \"Unsupervised learning for visual representations by solving jigsaw puzzles.\" ECCV 2016"}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "BJx7C1bfjH", "sid": 0}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "BJx7C1bfjH", "sid": 1}, {"labels": {"alignments": [8, 9], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "BJx7C1bfjH", "sid": 2}, {"labels": {"alignments": [8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJx7C1bfjH", "sid": 3}, {"labels": {"alignments": [8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJx7C1bfjH", "sid": 4}, {"labels": {"alignments": [8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJx7C1bfjH", "sid": 5}, {"labels": {"alignments": [8, 9], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "BJx7C1bfjH", "sid": 6}, {"labels": {"alignments": [10], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "BJx7C1bfjH", "sid": 7}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJx7C1bfjH", "sid": 8}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJx7C1bfjH", "sid": 9}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJx7C1bfjH", "sid": 10}, {"labels": {"alignments": [10], "responsetype": "future", "coarseresponse": "concur"}, "text_id": "BJx7C1bfjH", "sid": 11}, {"labels": {"alignments": [11], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "BJx7C1bfjH", "sid": 12}, {"labels": {"alignments": [11, 12, 13, 14], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "BJx7C1bfjH", "sid": 13}, {"labels": {"alignments": [11, 12, 13, 14], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "BJx7C1bfjH", "sid": 14}, {"labels": {"alignments": [11, 12, 13, 14], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "BJx7C1bfjH", "sid": 15}, {"labels": {"alignments": [15], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "BJx7C1bfjH", "sid": 16}, {"labels": {"alignments": [15], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJx7C1bfjH", "sid": 17}, {"labels": {"alignments": [15], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJx7C1bfjH", "sid": 18}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "BJx7C1bfjH", "sid": 19}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "BJx7C1bfjH", "sid": 20}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "BJx7C1bfjH", "sid": 21}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "BJx7C1bfjH", "sid": 22}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "BJx7C1bfjH", "sid": 23}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "BJx7C1bfjH", "sid": 24}], "metadata": {"anno": "anno10", "review": "BkgPU07CFS", "rebuttal": "BJx7C1bfjH", "conference": "ICLR2020", "title": "A critical analysis of self-supervision, or what we can learn from a single image", "reviewer": "AnonReviewer3", "forum_id": "B1esx6EYvr", "rating": "6: Weak Accept", "experience_assessment": "I have published one or two papers in this area."}}