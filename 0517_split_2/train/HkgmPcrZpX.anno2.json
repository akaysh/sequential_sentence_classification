{"review": [{"text_id": "HkgmPcrZpX", "sid": 0, "sentence": "This paper develops a mean field theory for batch normalization (BN) in fully-connected networks with randomly initialized weights."}, {"text_id": "HkgmPcrZpX", "sid": 1, "sentence": "There are a number of interesting predictions made in this paper on the basis of this analysis."}, {"text_id": "HkgmPcrZpX", "sid": 2, "sentence": "The main technical results of the paper are Theorems 5-8 which compute the statistics of the covariance of the activations and the gradients."}, {"text_id": "HkgmPcrZpX", "sid": 3, "sentence": "Comments:"}, {"text_id": "HkgmPcrZpX", "sid": 4, "sentence": "1. The observation that gradients explode in spite of BN is quite counter-intuitive. Can you give an intuitive explanation of why this occurs?"}, {"text_id": "HkgmPcrZpX", "sid": 5, "sentence": "2. In a similar vein, there a number of highly technical results in the paper and it would be great if the authors provide an intuitive explanation of their theorems."}, {"text_id": "HkgmPcrZpX", "sid": 6, "sentence": "3. Can the statistics of activations be controlled using activation functions or operations which break the symmetry?"}, {"text_id": "HkgmPcrZpX", "sid": 7, "sentence": "For instance, are BSB1 fixed points good for training neural networks?"}, {"text_id": "HkgmPcrZpX", "sid": 8, "sentence": "4. Mean field analysis, although it lends an insight into the statistics of the activations, needs to connected with empirical observations."}, {"text_id": "HkgmPcrZpX", "sid": 9, "sentence": "For instance, when the authors observe that the structure of the fixed point is such that activations are of identical norm equally spread apart in terms of angle, this is quite far from practice."}, {"text_id": "HkgmPcrZpX", "sid": 10, "sentence": "It would be good to mention this in the introduction or the conclusions."}], "reviewlabels": [{"text_id": "HkgmPcrZpX", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgmPcrZpX", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgmPcrZpX", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgmPcrZpX", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgmPcrZpX", "sid": 4, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgmPcrZpX", "sid": 5, "labels": {"coarse": "Request", "fine": "Request.Clarification", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgmPcrZpX", "sid": 6, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgmPcrZpX", "sid": 7, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgmPcrZpX", "sid": 8, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgmPcrZpX", "sid": 9, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgmPcrZpX", "sid": 10, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Soundness/Correctness", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "BJlt5Odvam", "sid": 0, "sentence": "Thank you for your careful review and useful comments!"}, {"text_id": "BJlt5Odvam", "sid": 1, "sentence": "Overall, in response to your review and that of referee 3 we will include a more intuitive discussion of our results in the next revision of our text."}, {"text_id": "BJlt5Odvam", "sid": 2, "sentence": "To reply to your other specific comments,"}, {"text_id": "BJlt5Odvam", "sid": 3, "sentence": "1) The intuition for batchnorm can be put in a more general setting."}, {"text_id": "BJlt5Odvam", "sid": 4, "sentence": "If a function f: X -> Y tends to spread out small clusters in the input space almost evenly in the output space, then one can expect that its gradients will be large typically."}, {"text_id": "BJlt5Odvam", "sid": 5, "sentence": "In our case, a batchnorm network can be understood as a function that sends a batch of inputs to a batch of outputs."}, {"text_id": "BJlt5Odvam", "sid": 6, "sentence": "In the appendix, we showed that the correlation between two different batches tend to a constant value independent of the input batches."}, {"text_id": "BJlt5Odvam", "sid": 7, "sentence": "No matter how close two input batches are, the output batches will have the same \u201cdistance\u201d from each other -- small movements in the input space leads to large movements in the output space."}, {"text_id": "BJlt5Odvam", "sid": 8, "sentence": "Thus we can expect the gradients to be large as well."}, {"text_id": "BJlt5Odvam", "sid": 9, "sentence": "We have added a new figure to the Appendix to further support this intuition."}, {"text_id": "BJlt5Odvam", "sid": 10, "sentence": "In it, we pass through a linear batchnorm network 2 minibatches."}, {"text_id": "BJlt5Odvam", "sid": 11, "sentence": "Both minibatches contain points on the same circle and 1 point off the circle that is unique to each minibatch."}, {"text_id": "BJlt5Odvam", "sid": 12, "sentence": "While the circle in each minibatch will remain an ellipse as they are propagated through the network, the angle between the planes spanned by them increasingly becomes chaotic with depth."}, {"text_id": "BJlt5Odvam", "sid": 13, "sentence": "3) As observed in [1] and [2], depthwise convergence to covariance fixed points is bad for training, and the best networks are either moderately deep or initialized such that the depthwise convergence rate to the fixed point is as slow as possible."}, {"text_id": "BJlt5Odvam", "sid": 14, "sentence": "We observe that deep networks whose activation statistics resemble a non-BSB1 fixed point typically feature worse gradient explosion than BSB1 networks."}, {"text_id": "BJlt5Odvam", "sid": 15, "sentence": "This seems to be because the nonlinearities that induce these fixed points increase rapidly (for example, polynomials with high degrees), so that the corresponding derivatives are also large, causing gradient explosion."}, {"text_id": "BJlt5Odvam", "sid": 16, "sentence": "(The reason that rapidly increasing nonlinearities don\u2019t converge to BSB1 fixed points is that, after a spontaneous symmetry-breaking, begins a \u201cwinner-take-all\u201d covariance dynamics, in which the activations of a few examples in the batch suddenly dominates those of the others in the batch, and this dominance persists across each layer.)"}, {"text_id": "BJlt5Odvam", "sid": 17, "sentence": "4) We were a bit confused by what was meant by \u201cpractice\u201d here."}, {"text_id": "BJlt5Odvam", "sid": 18, "sentence": "We have thoroughly verified that for realistic input distributions (MNIST and CIFAR10) and common initialization strategies (weights that are randomly distributed) our theory makes accurate prediction."}, {"text_id": "BJlt5Odvam", "sid": 19, "sentence": "Moreover, we have shown that these predictions can be connected to practice in the sense that they predict whether or not the network can be trained."}, {"text_id": "BJlt5Odvam", "sid": 20, "sentence": "Having said this, if by practice you meant that the neural network is accurately described by our theory during training then we do not expect this to be true. We are happy to emphasize this in the camera ready."}, {"text_id": "BJlt5Odvam", "sid": 21, "sentence": "If this did not properly address your question, please feel free to let us to know and we will improve this response!"}, {"text_id": "BJlt5Odvam", "sid": 22, "sentence": "[1] S. S. Schoenholz, J. Gilmer, S. Ganguli, J. Sohl-Dickstein."}, {"text_id": "BJlt5Odvam", "sid": 23, "sentence": "Deep Information Propagation (https://arxiv.org/abs/1611.01232)"}, {"text_id": "BJlt5Odvam", "sid": 24, "sentence": "[2] L. Xiao, Y. Bahri, J. Sohl-Dickstein, S. S. Schoenholz, J. Pennington. Dynamical Isometry and a Mean Field Theory of CNNs: How to Train 10,000-Layer Vanilla Convolutional Neural Networks (https://arxiv.org/abs/1806.05393)"}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "BJlt5Odvam", "sid": 0}, {"labels": {"alignments": [], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "BJlt5Odvam", "sid": 1}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "BJlt5Odvam", "sid": 2}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJlt5Odvam", "sid": 3}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJlt5Odvam", "sid": 4}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJlt5Odvam", "sid": 5}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJlt5Odvam", "sid": 6}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJlt5Odvam", "sid": 7}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJlt5Odvam", "sid": 8}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJlt5Odvam", "sid": 9}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJlt5Odvam", "sid": 10}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJlt5Odvam", "sid": 11}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJlt5Odvam", "sid": 12}, {"labels": {"alignments": [6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJlt5Odvam", "sid": 13}, {"labels": {"alignments": [6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJlt5Odvam", "sid": 14}, {"labels": {"alignments": [6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJlt5Odvam", "sid": 15}, {"labels": {"alignments": [6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BJlt5Odvam", "sid": 16}, {"labels": {"alignments": [8, 9, 10], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "BJlt5Odvam", "sid": 17}, {"labels": {"alignments": [8, 9, 10], "responsetype": "refute-question", "coarseresponse": "dispute"}, "text_id": "BJlt5Odvam", "sid": 18}, {"labels": {"alignments": [8, 9, 10], "responsetype": "refute-question", "coarseresponse": "dispute"}, "text_id": "BJlt5Odvam", "sid": 19}, {"labels": {"alignments": [8, 9, 10], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "BJlt5Odvam", "sid": 20}, {"labels": {"alignments": [8, 9, 10], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "BJlt5Odvam", "sid": 21}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "BJlt5Odvam", "sid": 22}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "BJlt5Odvam", "sid": 23}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "BJlt5Odvam", "sid": 24}], "metadata": {"anno": "anno2", "review": "HkgmPcrZpX", "rebuttal": "BJlt5Odvam", "conference": "ICLR2019", "title": "A Mean Field Theory of Batch Normalization", "reviewer": "AnonReviewer1", "forum_id": "SyMDXnCcF7", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}}