{"review": [{"text_id": "SklswyoFnX", "sid": 0, "sentence": "The paper focuses on the generalization performance of RNNs and its variant in a theoretical perspective."}, {"text_id": "SklswyoFnX", "sid": 1, "sentence": "Compared to the previous result (Zhang et al., 2018) for RNNs, this paper refines the generalization bounds for vanilla RNNs in all cases and fills the blank for RNN variants like MGU and LSTM."}, {"text_id": "SklswyoFnX", "sid": 2, "sentence": "Specifically, in the work of Zhang et al. (2018), the complexity term quadratically depends on the layer (or say, current sequence length, denoted by t in original paper), making it less instructive."}, {"text_id": "SklswyoFnX", "sid": 3, "sentence": "This paper improves it to at most linear dependence and can achieve at logarithmic dependence in some cases, which should be accredited."}, {"text_id": "SklswyoFnX", "sid": 4, "sentence": "The key step in the proof is Lemma 2."}, {"text_id": "SklswyoFnX", "sid": 5, "sentence": "In Lemma 2, the spectral norms of weight matrices and the number of weight parameters are decoupled."}, {"text_id": "SklswyoFnX", "sid": 6, "sentence": "With Lemma 2, it is natural to construct a epsilon-net for RNNs and then upper bound the empirical Rademacher complexity by Dudley\u2019s entropy integral, since such methodology is not so novel."}, {"text_id": "SklswyoFnX", "sid": 7, "sentence": "Bartlett, et al. (2017) developed this technique to analyze the generalization bound for neural networks in a margin-based multiclass classification."}, {"text_id": "SklswyoFnX", "sid": 8, "sentence": "However, it seems a little unexplainable to apply a technique developed from classification to analyze RNNs, since the main task of RNNs never should be classification."}, {"text_id": "SklswyoFnX", "sid": 9, "sentence": "I wonder the motivation of analyzing generalization of RNNs by the techniques established by Bartlett."}], "reviewlabels": [{"text_id": "SklswyoFnX", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SklswyoFnX", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SklswyoFnX", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SklswyoFnX", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SklswyoFnX", "sid": 4, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SklswyoFnX", "sid": 5, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SklswyoFnX", "sid": 6, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SklswyoFnX", "sid": 7, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SklswyoFnX", "sid": 8, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SklswyoFnX", "sid": 9, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "Hyx17yRtAQ", "sid": 0, "sentence": "1. Comment:"}, {"text_id": "Hyx17yRtAQ", "sid": 1, "sentence": "However, it seems a little unexplainable to apply a technique developed from classification to analyze RNNs, since the main task of RNNs never should be classification."}, {"text_id": "Hyx17yRtAQ", "sid": 2, "sentence": "1. Response:"}, {"text_id": "Hyx17yRtAQ", "sid": 3, "sentence": "We study seq2seq classification tasks since they have been widely used in real world applications for RNNs."}, {"text_id": "Hyx17yRtAQ", "sid": 4, "sentence": "To name a few, in speech recognition, [1] hybridizes hidden Markov model with RNNs to label unsegmented sequence data; In computer vision, [2, 3] demonstrate scene labeling with LSTM and RNNs, achieving higher accuracy than baseline methods; In healthcare, [4] proposes a model, Doctor AI, to perform multiple label prediction (one for each disease or medication category)."}, {"text_id": "Hyx17yRtAQ", "sid": 5, "sentence": "In addition, [5, 6] both apply RNNs to real-world healthcare datasets (MIMIC-III, PhysioNet, and ICU data) for mortality prediction and other multiple classifications tasks."}, {"text_id": "Hyx17yRtAQ", "sid": 6, "sentence": "We establish bounds for classification because it is typical in learning theory and is easy to compare among existing literature."}, {"text_id": "Hyx17yRtAQ", "sid": 7, "sentence": "On the other hand, our analysis applies in other tasks as long as a suitable Lipschitz loss function is chosen."}, {"text_id": "Hyx17yRtAQ", "sid": 8, "sentence": "Specifically, Lemma 4 establishes an upper bound for empirical Rademacher complexity of general Lipschitz loss functions (the last line in Appendix A.4)."}, {"text_id": "Hyx17yRtAQ", "sid": 9, "sentence": "By replacing the loss function in Lemma 1, we can derive generalization bounds for various tasks other than classification."}, {"text_id": "Hyx17yRtAQ", "sid": 10, "sentence": "References"}, {"text_id": "Hyx17yRtAQ", "sid": 11, "sentence": "[1] Graves, Alex, Santiago Fern\u00e1ndez, Faustino Gomez, and J\u00fcrgen Schmidhuber. \"Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks.\" In Proceedings of the 23rd international conference on Machine learning, pp. 369-376. ACM, 2006."}, {"text_id": "Hyx17yRtAQ", "sid": 12, "sentence": "[2] Byeon, Wonmin, Thomas M. Breuel, Federico Raue, and Marcus Liwicki. \"Scene labeling with lstm recurrent neural networks.\" In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3547-3555. 2015."}, {"text_id": "Hyx17yRtAQ", "sid": 13, "sentence": "[3] Socher, Richard, Cliff C. Lin, Chris Manning, and Andrew Y. Ng. \"Parsing natural scenes and natural language with recursive neural networks.\" In Proceedings of the 28th international conference on machine learning (ICML-11), pp. 129-136. 2011."}, {"text_id": "Hyx17yRtAQ", "sid": 14, "sentence": "[4] Choi, Edward, Mohammad Taha Bahadori, Andy Schuetz, Walter F. Stewart, and Jimeng Sun. \"Doctor ai: Predicting clinical events via recurrent neural networks.\" In Machine Learning for Healthcare Conference, pp. 301-318. 2016."}, {"text_id": "Hyx17yRtAQ", "sid": 15, "sentence": "[5] Che, Zhengping, Sanjay Purushotham, Kyunghyun Cho, David Sontag, and Yan Liu. \"Recurrent neural networks for multivariate time series with missing values.\" Scientific reports 8, no. 1 (2018): 6085."}, {"text_id": "Hyx17yRtAQ", "sid": 16, "sentence": "[6] Xu, Yanbo, Siddharth Biswal, Shriprasad R. Deshpande, Kevin O. Maher, and Jimeng Sun. \"RAIM: Recurrent Attentive and Intensive Model of Multimodal Patient Monitoring Data.\" In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 2565-2573. ACM, 2018."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "Hyx17yRtAQ", "sid": 0}, {"labels": {"alignments": [8], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "Hyx17yRtAQ", "sid": 1}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "Hyx17yRtAQ", "sid": 2}, {"labels": {"alignments": [8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Hyx17yRtAQ", "sid": 3}, {"labels": {"alignments": [8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Hyx17yRtAQ", "sid": 4}, {"labels": {"alignments": [8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Hyx17yRtAQ", "sid": 5}, {"labels": {"alignments": [8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Hyx17yRtAQ", "sid": 6}, {"labels": {"alignments": [8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Hyx17yRtAQ", "sid": 7}, {"labels": {"alignments": [8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Hyx17yRtAQ", "sid": 8}, {"labels": {"alignments": [8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Hyx17yRtAQ", "sid": 9}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "Hyx17yRtAQ", "sid": 10}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "Hyx17yRtAQ", "sid": 11}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "Hyx17yRtAQ", "sid": 12}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "Hyx17yRtAQ", "sid": 13}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "Hyx17yRtAQ", "sid": 14}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "Hyx17yRtAQ", "sid": 15}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "Hyx17yRtAQ", "sid": 16}], "metadata": {"anno": "anno10", "review": "SklswyoFnX", "rebuttal": "Hyx17yRtAQ", "conference": "ICLR2019", "title": "On Generalization Bounds of a Family of Recurrent Neural Networks", "reviewer": "AnonReviewer2", "forum_id": "Skf-oo0qt7", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}}