{"review": [{"text_id": "SJekKHZ93Q", "sid": 0, "sentence": "In this work the authors propose an extension of mixture density networks to the continuous domain, named compound density networks."}, {"text_id": "SJekKHZ93Q", "sid": 1, "sentence": "Specifically the paper builds on top of the idea of the ensemble neural networks (NNs) and introduces a stochastic neural network for handling the mixing components."}, {"text_id": "SJekKHZ93Q", "sid": 2, "sentence": "The mixing distribution is also parameterised by a neural network."}, {"text_id": "SJekKHZ93Q", "sid": 3, "sentence": "The authors claim that the proposed model can result in better uncertainty estimates and the experiments attempt to demonstrate the benefits of the approach, especially in cases of having to deal with adversarial attacks."}, {"text_id": "SJekKHZ93Q", "sid": 4, "sentence": "The paper in general is well written and easy to follow."}, {"text_id": "SJekKHZ93Q", "sid": 5, "sentence": "I have some concerns regarding the presentation of the main objective and the lack of justification in certain parts of the methodology."}, {"text_id": "SJekKHZ93Q", "sid": 6, "sentence": "Let me elaborate."}, {"text_id": "SJekKHZ93Q", "sid": 7, "sentence": "First of all, I don\u2019t understand how the main equation of the compound density network in Equation (3) is different from the general case of a Bayesian neural network? Can the authors please comment on that?"}, {"text_id": "SJekKHZ93Q", "sid": 8, "sentence": "I also find weird the way that the authors arrive to their final objective in Equation (5)."}, {"text_id": "SJekKHZ93Q", "sid": 9, "sentence": "They start from Equation (4) which is incorrectly denoted as the log-marginal distribution while it is the same conditional distribution introduced in Equation (3) with the extra summation for all the available data points."}, {"text_id": "SJekKHZ93Q", "sid": 10, "sentence": "Then they continue to Equation (5) which they present as the combination of the true likelihood with a KL regularisation term."}, {"text_id": "SJekKHZ93Q", "sid": 11, "sentence": "However, what the authors implicitly did was to perform variational inference for maximising their likelihood by introducing a variational distribution q(\\theta) = p(\\theta | g(x_n; \\psi)."}, {"text_id": "SJekKHZ93Q", "sid": 12, "sentence": "Is there a reason why the authors do not introduce their objective by following the variational framework?"}, {"text_id": "SJekKHZ93Q", "sid": 13, "sentence": "Furthermore, in the beginning of Section 3.1 the authors present their idea on probabilistic hypernetoworks which \u201cmaps x to a distribution over parameters instead of specific value \\theta.\u201d How is this different from the case that we were considering so far? If we had a point estimate for \\theta we would not require to take an expectation in Equation (3) in the first place."}, {"text_id": "SJekKHZ93Q", "sid": 14, "sentence": "My biggest concern in the methodology, however, has to do with the selection of the matrix variate normal prior for the weights and the imposition of diagonal covariances (diag(a) and diag(b))."}, {"text_id": "SJekKHZ93Q", "sid": 15, "sentence": "The Kronecker product between two diagonal matrices results in another diagonal matrix, i.e., diagonal covariance, which implies that the weights within a layer are given by an independent multivariate Gaussian."}, {"text_id": "SJekKHZ93Q", "sid": 16, "sentence": "What is the purpose then for introducing the matrix variate Gaussian?"}, {"text_id": "SJekKHZ93Q", "sid": 17, "sentence": "I would expect that you would like to impose additional structure to the weights."}, {"text_id": "SJekKHZ93Q", "sid": 18, "sentence": "I expect the authors to comment on that."}, {"text_id": "SJekKHZ93Q", "sid": 19, "sentence": "Regarding the experimental evaluation of the model rather confusing."}, {"text_id": "SJekKHZ93Q", "sid": 20, "sentence": "The authors have proposed a model that due to the mixing is better suited for predictions with heteroscedastic noise and can better quantify the aleatoric uncertainty."}, {"text_id": "SJekKHZ93Q", "sid": 21, "sentence": "However, the selected experiments on the cubic regression toy data (Section 5.1) and the out-of-distribution classification (Section 5.2) are clear examples of system\u2019s noise, i.e. epistemic uncertainty."}, {"text_id": "SJekKHZ93Q", "sid": 22, "sentence": "The generative process of the toy data clearly states that there is no heteroscedastic noise to handle."}, {"text_id": "SJekKHZ93Q", "sid": 23, "sentence": "The same applies for the notMNIST data which belong to a completely different data set compared to MNIST and thus out of sample prediction cannot benefit from the mixing; i.e., variations have to be explained by system\u2019s noise."}, {"text_id": "SJekKHZ93Q", "sid": 24, "sentence": "So overall I have the feeling that the authors have not succeeded to evaluate the model\u2019s power with these two experiments and we cannot draw any strong conclusions regarding the benefit of the proposed mixing approach."}, {"text_id": "SJekKHZ93Q", "sid": 25, "sentence": "To continue with the experimental evaluation, I found the plots with the predictive uncertainty in Figure 3 a bit confusing."}, {"text_id": "SJekKHZ93Q", "sid": 26, "sentence": "The plot by itself, as I understood, quantifies the model\u2019s uncertainty in in- and out-of sample prediction."}, {"text_id": "SJekKHZ93Q", "sid": 27, "sentence": "While I agree with the authors that it is generally desirable for a model to be more confident when predicting in MNIST (since it has already seen samples of it) compared to when predicting in notMNIST (completely different data), these plots tells us nothing regarding the predictive power of the model."}, {"text_id": "SJekKHZ93Q", "sid": 28, "sentence": "There is no value in being very confident if you are wrong and vice-versa, so unless there is an accompanying plot/table reporting the accuracy I see not much value from this plot alone."}, {"text_id": "SJekKHZ93Q", "sid": 29, "sentence": "Finally, it is unclear how the authors have picked the best \\lambda parameter for their approach? On page 5 they state that they \u201cpick the value that results in a good trade-off between high uncertainty estimates and high prediction accuracy.\u201d Does this mean that you get to observe the performance in the test in order to select the appropriate value for \\lambda? If this is the case this is completely undesirable and is considered a bad practice."}], "reviewlabels": [{"text_id": "SJekKHZ93Q", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 4, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 5, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 6, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 7, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Replicability", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 8, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Replicability", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 9, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 10, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Replicability", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 11, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Replicability", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 12, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Replicability", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 13, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 14, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Replicability", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 15, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 16, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Replicability", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 17, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 18, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Replicability", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 19, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 20, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 21, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 22, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 23, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 24, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 25, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 26, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 27, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 28, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJekKHZ93Q", "sid": 29, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Replicability", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "ByxbnbuB0Q", "sid": 0, "sentence": "We thank the reviewer for the valuable feedback! We reply to the answers and comments in the order they were raised."}, {"text_id": "ByxbnbuB0Q", "sid": 1, "sentence": "Note, that regarding the methodology there were some misunderstandings (which we try to avoid for future readers in the revised version)."}, {"text_id": "ByxbnbuB0Q", "sid": 2, "sentence": "(1) The equations are indeed very related."}, {"text_id": "ByxbnbuB0Q", "sid": 3, "sentence": "Note however, that In a standard Bayesian neural network (BNN), one would assume that \\theta is a global random variable (i.e. does not depend on input x), whereas in the CDN, we assume that \\theta depends on x and is thus a local random variable."}, {"text_id": "ByxbnbuB0Q", "sid": 4, "sentence": "Furthermore, in a Bayesian setting p(theta|...) would play the role of a approximate posterior, which would require variational inference (VI), and thus a different objective,  to estimate it."}, {"text_id": "ByxbnbuB0Q", "sid": 5, "sentence": "(2) In Equation (4) we followed with  p(D | \\psi) a standard notation for \\sum_n p(y_n | x_n; \\psi) (i.e. summation of Equation (3) wrt all data in D) which also can be found e.g. in the work of Graves (2011) [4] and Blundell et al. (2015) [5]."}, {"text_id": "ByxbnbuB0Q", "sid": 6, "sentence": "The objective we introduce for CDNs differs from the ELBO-based objective in VI in the way the logarithm is placed in the first term of the objective: in the ELBO we have a logarithm inside the expectation, while the logarithm is outside the expectation in the CDN objective (note however, that the sample-based approximations get equivalent if only one sample is used)."}, {"text_id": "ByxbnbuB0Q", "sid": 7, "sentence": "Furthermore, in the ELBO we have a fixed value of \\lambda = 1."}, {"text_id": "ByxbnbuB0Q", "sid": 8, "sentence": "We added a new Section 4 in the revised version of the paper discussing these differences."}, {"text_id": "ByxbnbuB0Q", "sid": 9, "sentence": "Moreover, we investigated the impact of the different objectives empirically and found that the CDN-based objective led to significantly better results, as shown in the newly added Section 6.4 in the revised manuscript."}, {"text_id": "ByxbnbuB0Q", "sid": 10, "sentence": "(3) Indeed we need the probabilistic version of hypernetworks to implement the model we described in Equation (3)."}, {"text_id": "ByxbnbuB0Q", "sid": 11, "sentence": "We just wanted to point out that this is in contrast to the vanilla  hypernetworks proposed by Ha et al. (2016) [1] and Jia et al."}, {"text_id": "ByxbnbuB0Q", "sid": 12, "sentence": "(2016) [2] which would produce a point estimate for \\theta."}, {"text_id": "ByxbnbuB0Q", "sid": 13, "sentence": "(4) We used a matrix-variate normal (MVN) to reduce the parameters of the model."}, {"text_id": "ByxbnbuB0Q", "sid": 14, "sentence": "Using a diagonal MVN for X \\in R^{p x q} one needs pq+p+q parameters."}, {"text_id": "ByxbnbuB0Q", "sid": 15, "sentence": "In contrast a fully-factorized diagonal Gaussian needs pq+pq."}, {"text_id": "ByxbnbuB0Q", "sid": 16, "sentence": "But you are right, we could easily extend our approach to account for more flexible distributions by using a \"diagonal plus rank-one\" structure diag(a)+uu^T, with vectors a and u, as noted by Louizos and Welling ( 2016) [3] (the increase of parameters is negligible: adding additional vector u)."}, {"text_id": "ByxbnbuB0Q", "sid": 17, "sentence": "We will investigate the benefits of more flexible mixing distributions in future work."}, {"text_id": "ByxbnbuB0Q", "sid": 18, "sentence": "(5) Thanks for this valuable comment!"}, {"text_id": "ByxbnbuB0Q", "sid": 19, "sentence": "We have revised the toy experiments to include a heteroscedastic regression task (see Section 6.1.)."}, {"text_id": "ByxbnbuB0Q", "sid": 20, "sentence": "It shows that CDNs are able to quantify the heteroscedastic aleatoric uncertainty."}, {"text_id": "ByxbnbuB0Q", "sid": 21, "sentence": "However, we kept the OOD experiments on MNIST and notMNIST in the paper as well, since we consider it as very interesting that the CDN, while being designed for modelling aleatoric uncertainty, is very competitive on this task."}, {"text_id": "ByxbnbuB0Q", "sid": 22, "sentence": "Moreover, we investigate the mixing distribution learned in Appendix G."}, {"text_id": "ByxbnbuB0Q", "sid": 23, "sentence": "(6) Of course, you are right! Previously we showed the test accuracy in Appendix F.  To make it more directly accessible, we have now added the test accuracy achieved by the different models into the legends of the plots, showing that CDN achieves similar predictive power as the baselines."}, {"text_id": "ByxbnbuB0Q", "sid": 24, "sentence": "We now present the validation accuracy instead in Appendix F."}, {"text_id": "ByxbnbuB0Q", "sid": 25, "sentence": "(7) Sorry, for this unfortunate formulation!"}, {"text_id": "ByxbnbuB0Q", "sid": 26, "sentence": "We observed that generally as \\lambda increases, the uncertainty is increasing, while the accuracy is decreasing."}, {"text_id": "ByxbnbuB0Q", "sid": 27, "sentence": "Therefore a simple and effective heuristic for choosing \\lambda is to look at the validation set of MNIST and choose the highest \\lambda that still results in high accuracy (e.g. >. 0.97)."}, {"text_id": "ByxbnbuB0Q", "sid": 28, "sentence": "We have made this procedure clear in the revised manuscript."}, {"text_id": "ByxbnbuB0Q", "sid": 29, "sentence": "References:"}, {"text_id": "ByxbnbuB0Q", "sid": 30, "sentence": "[1] Ha, David, Andrew Dai, and Quoc V. Le. \"Hypernetworks.\" arXiv preprint arXiv:1609.09106 (2016)."}, {"text_id": "ByxbnbuB0Q", "sid": 31, "sentence": "[2] Jia, Xu, et al. \"Dynamic filter networks.\" Advances in Neural Information Processing Systems. 2016."}, {"text_id": "ByxbnbuB0Q", "sid": 32, "sentence": "[3] Louizos, Christos, and Max Welling. \"Structured and efficient variational deep learning with matrix gaussian posteriors.\" International Conference on Machine Learning. 2016."}, {"text_id": "ByxbnbuB0Q", "sid": 33, "sentence": "[4] Graves, A. (2011). Practical variational inference for neural networks. In Advances in neural information processing systems (pp. 2348-2356)."}, {"text_id": "ByxbnbuB0Q", "sid": 34, "sentence": "[5] Blundell, C., Cornebise, J., Kavukcuoglu, K. & Wierstra, D.. (2015). Weight Uncertainty in Neural Network. Proceedings of the 32nd International Conference on Machine Learning, in PMLR 37:1613-1622"}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "ByxbnbuB0Q", "sid": 0}, {"labels": {"alignments": [5], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "ByxbnbuB0Q", "sid": 1}, {"labels": {"alignments": [7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ByxbnbuB0Q", "sid": 2}, {"labels": {"alignments": [7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ByxbnbuB0Q", "sid": 3}, {"labels": {"alignments": [7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ByxbnbuB0Q", "sid": 4}, {"labels": {"alignments": [8, 9, 10, 11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ByxbnbuB0Q", "sid": 5}, {"labels": {"alignments": [8, 9, 10, 11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ByxbnbuB0Q", "sid": 6}, {"labels": {"alignments": [8, 9, 10, 11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ByxbnbuB0Q", "sid": 7}, {"labels": {"alignments": [8, 9, 10, 11, 12], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "ByxbnbuB0Q", "sid": 8}, {"labels": {"alignments": [8, 9, 10, 11, 12], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "ByxbnbuB0Q", "sid": 9}, {"labels": {"alignments": [13], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "ByxbnbuB0Q", "sid": 10}, {"labels": {"alignments": [13], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "ByxbnbuB0Q", "sid": 11}, {"labels": {"alignments": [13], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "ByxbnbuB0Q", "sid": 12}, {"labels": {"alignments": [14, 15, 16, 17, 18], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ByxbnbuB0Q", "sid": 13}, {"labels": {"alignments": [14, 15, 16, 17, 18], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ByxbnbuB0Q", "sid": 14}, {"labels": {"alignments": [14, 15, 16, 17, 18], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ByxbnbuB0Q", "sid": 15}, {"labels": {"alignments": [14, 15, 16, 17, 18], "responsetype": "concede-criticism", "coarseresponse": "concur"}, "text_id": "ByxbnbuB0Q", "sid": 16}, {"labels": {"alignments": [14, 15, 16, 17, 18], "responsetype": "future", "coarseresponse": "concur"}, "text_id": "ByxbnbuB0Q", "sid": 17}, {"labels": {"alignments": [19, 20, 21, 22, 23, 24], "responsetype": "concede-criticism", "coarseresponse": "concur"}, "text_id": "ByxbnbuB0Q", "sid": 18}, {"labels": {"alignments": [19, 20, 21, 22, 23, 24], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "ByxbnbuB0Q", "sid": 19}, {"labels": {"alignments": [19, 20, 21, 22, 23, 24], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ByxbnbuB0Q", "sid": 20}, {"labels": {"alignments": [19, 20, 21, 22, 23, 24], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ByxbnbuB0Q", "sid": 21}, {"labels": {"alignments": [19, 20, 21, 22, 23, 24], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ByxbnbuB0Q", "sid": 22}, {"labels": {"alignments": [25, 26, 27, 28], "responsetype": "concede-criticism", "coarseresponse": "concur"}, "text_id": "ByxbnbuB0Q", "sid": 23}, {"labels": {"alignments": [25, 26, 27, 28], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "ByxbnbuB0Q", "sid": 24}, {"labels": {"alignments": [29], "responsetype": "concede-criticism", "coarseresponse": "concur"}, "text_id": "ByxbnbuB0Q", "sid": 25}, {"labels": {"alignments": [29], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ByxbnbuB0Q", "sid": 26}, {"labels": {"alignments": [29], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "ByxbnbuB0Q", "sid": 27}, {"labels": {"alignments": [29], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "ByxbnbuB0Q", "sid": 28}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "ByxbnbuB0Q", "sid": 29}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "ByxbnbuB0Q", "sid": 30}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "ByxbnbuB0Q", "sid": 31}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "ByxbnbuB0Q", "sid": 32}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "ByxbnbuB0Q", "sid": 33}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "ByxbnbuB0Q", "sid": 34}], "metadata": {"anno": "anno10", "review": "SJekKHZ93Q", "rebuttal": "ByxbnbuB0Q", "conference": "ICLR2019", "title": "Compound Density Networks", "reviewer": "AnonReviewer3", "forum_id": "rkgv9oRqtQ", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}}