{"review": [{"text_id": "HJgQO5qAnQ", "sid": 0, "sentence": "The problem that the paper tackles is very important and the approach to tackle it id appealing."}, {"text_id": "HJgQO5qAnQ", "sid": 1, "sentence": "The idea of regarding the history as a tree looks very promising."}, {"text_id": "HJgQO5qAnQ", "sid": 2, "sentence": "However, it\u2019s noteworthy that embedding to a vector could be useful too if the embedding espace is representative of the entire history and the timing of the events."}, {"text_id": "HJgQO5qAnQ", "sid": 3, "sentence": "Using neural network if an interesting choice for capturing the influence probability and its timing."}, {"text_id": "HJgQO5qAnQ", "sid": 4, "sentence": "The authors need to be clear about their contribution. Is the paper only about replacing the traditional parametric functions of influence and probability with  deep neural networks?"}, {"text_id": "HJgQO5qAnQ", "sid": 5, "sentence": "The experimental sections look rather mechanical. I would have put some results on the learned embedding. Or some demonstration of the embedded history or probability to intuitively convey the idea and how it works."}, {"text_id": "HJgQO5qAnQ", "sid": 6, "sentence": "This could have made the paper much stronger."}, {"text_id": "HJgQO5qAnQ", "sid": 7, "sentence": "It was nice that the paper iterated and reviewed the possible inference and learning ways."}, {"text_id": "HJgQO5qAnQ", "sid": 8, "sentence": "There is one more way."}, {"text_id": "HJgQO5qAnQ", "sid": 9, "sentence": "Similar to [1] one can use MCMC with importance sampling on auxiliary variables to infer the hidden diffusion given the observed cascades in continuous-time independent cascade model."}, {"text_id": "HJgQO5qAnQ", "sid": 10, "sentence": "The paper can benefit from a proofreading."}, {"text_id": "HJgQO5qAnQ", "sid": 11, "sentence": "There are a few typos throughout the paper such as:"}, {"text_id": "HJgQO5qAnQ", "sid": 12, "sentence": "Reference is missing in section 2.1"}, {"text_id": "HJgQO5qAnQ", "sid": 13, "sentence": "Page 2 paragraph 1: \u201can neural attention mechanism\u201d"}, {"text_id": "HJgQO5qAnQ", "sid": 14, "sentence": "[1] Back to the Past: Source Identification in Diffusion Networks from Partially Observed Cascades, AISTATS 2015"}], "reviewlabels": [{"text_id": "HJgQO5qAnQ", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQO5qAnQ", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQO5qAnQ", "sid": 2, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Meaningful Comparison", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQO5qAnQ", "sid": 3, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQO5qAnQ", "sid": 4, "labels": {"coarse": "Request", "fine": "Request.Clarification", "asp": "Motivation/Impact", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQO5qAnQ", "sid": 5, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Meaningful Comparison", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQO5qAnQ", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Motivation/Impact", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQO5qAnQ", "sid": 7, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQO5qAnQ", "sid": 8, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQO5qAnQ", "sid": 9, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQO5qAnQ", "sid": 10, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HJgQO5qAnQ", "sid": 11, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "HJgQO5qAnQ", "sid": 12, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "HJgQO5qAnQ", "sid": 13, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "HJgQO5qAnQ", "sid": 14, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}], "rebuttal": [{"text_id": "B1gDcrvdCm", "sid": 0, "sentence": "Thanks for your valuable comments and feedback."}, {"text_id": "B1gDcrvdCm", "sid": 1, "sentence": "R: \"The authors need to be clear about their contribution. Is the paper only about replacing the traditional parametric functions of influence and probability with  deep neural networks? \""}, {"text_id": "B1gDcrvdCm", "sid": 2, "sentence": "A: Yes but not only."}, {"text_id": "B1gDcrvdCm", "sid": 3, "sentence": "We propose to go beyond the classical markov hypothesis of cascade models that states that any infected node owns the same transmission probabilities whatever from whom comes the propagated content."}, {"text_id": "B1gDcrvdCm", "sid": 4, "sentence": "We indeed do this by replacing the traditional parametric functions with  deep neural networks, which enables to consider recurrent latent states for infected nodes."}, {"text_id": "B1gDcrvdCm", "sid": 5, "sentence": "This allows us to embed the past in node states and hence to output different future diffusion distributions regarding the past trajectory of the propagated content, which is our main contribution (a cascade model with neural network was already proposed for instance in (bourigault et al., 2016) but without past inclusion)."}, {"text_id": "B1gDcrvdCm", "sid": 6, "sentence": "While existing works on cascade models learn parameters by inferring the direct infector of every infected node (i.e., estimating $P(I_i|D_{\\leq i})$), we need to infer the whole past trajectory to compute node states (i.e., considering $P(I_i|D,I_{<i})$), which is greatly more difficult but the proposed learning approach allowed us to efficiently deal with it."}, {"text_id": "B1gDcrvdCm", "sid": 7, "sentence": "R: \"The experimental sections look rather mechanical. I would have put some results on the learned embedding. Or some demonstration of the embedded history or probability to intuitively convey the idea and how it works. This could have made the paper much stronger.\""}, {"text_id": "B1gDcrvdCm", "sid": 8, "sentence": "A: To give more clues about the good behavior of the algorithm, we added results about the accuracy of the sampled trajectories on the artificial datasets (for which we have the ground truth on who infected whom)."}, {"text_id": "B1gDcrvdCm", "sid": 9, "sentence": "We report the rate of good infector choices (i.e., the rate of I_i that equal the ground truth) for our approach and the others."}, {"text_id": "B1gDcrvdCm", "sid": 10, "sentence": "Results show that our approach actually performs better infector choices than CTIC which does not consider the history of the diffusion in its infection probabilities."}, {"text_id": "B1gDcrvdCm", "sid": 11, "sentence": "The use of our recurrent architecture helps the process to distinguish some different diffusion contexts from the past."}, {"text_id": "B1gDcrvdCm", "sid": 12, "sentence": "We also added a second artificial dataset to further analyze the behavior of the approaches."}, {"text_id": "B1gDcrvdCm", "sid": 13, "sentence": "R: \"It was nice that the paper iterated and reviewed the possible inference and learning ways. There is one more way. Similar to [1] one can use MCMC with importance sampling on auxiliary variables to infer the hidden diffusion given the observed cascades in continuous-time independent cascade model.\""}, {"text_id": "B1gDcrvdCm", "sid": 14, "sentence": "A: Thanks for the proposal and the reference that we added in the paper."}, {"text_id": "B1gDcrvdCm", "sid": 15, "sentence": "The full computation of the posterior distributions could indeed be avoided by using an importance sampling MCMC procedure with auxiliary variables"}, {"text_id": "B1gDcrvdCm", "sid": 16, "sentence": "(such as done in [1] in the context of diffusion source detection), but in our context we think that the increased computation efficiency would be at the cost of a very higher variance in the learning process, due to the strong intrication of latent and observed variables."}, {"text_id": "B1gDcrvdCm", "sid": 17, "sentence": "In [1], the problem is easier: they do not have to perform optimization on the diffusion parameters (since relying on a diffusion model learned a priori), the problem is to sample hidden infection times to estimate likelihoods and then identifying the most probable source of diffusion."}, {"text_id": "B1gDcrvdCm", "sid": 18, "sentence": "R: \"The paper can benefit from a proofreading.\""}, {"text_id": "B1gDcrvdCm", "sid": 19, "sentence": "A: Thanks, we indeed corrected serveral typos like this in the new version of the paper."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "B1gDcrvdCm", "sid": 0}, {"labels": {"alignments": [4], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "B1gDcrvdCm", "sid": 1}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "B1gDcrvdCm", "sid": 2}, {"labels": {"alignments": [4], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "B1gDcrvdCm", "sid": 3}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "B1gDcrvdCm", "sid": 4}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "B1gDcrvdCm", "sid": 5}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "B1gDcrvdCm", "sid": 6}, {"labels": {"alignments": [5, 6], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "B1gDcrvdCm", "sid": 7}, {"labels": {"alignments": [5, 6], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "B1gDcrvdCm", "sid": 8}, {"labels": {"alignments": [5, 6], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "B1gDcrvdCm", "sid": 9}, {"labels": {"alignments": [5, 6], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "B1gDcrvdCm", "sid": 10}, {"labels": {"alignments": [5, 6], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "B1gDcrvdCm", "sid": 11}, {"labels": {"alignments": [5, 6], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "B1gDcrvdCm", "sid": 12}, {"labels": {"alignments": [7, 8, 9], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "B1gDcrvdCm", "sid": 13}, {"labels": {"alignments": [7, 8, 9], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "B1gDcrvdCm", "sid": 14}, {"labels": {"alignments": [7, 8, 9], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "B1gDcrvdCm", "sid": 15}, {"labels": {"alignments": [7, 8, 9], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "B1gDcrvdCm", "sid": 16}, {"labels": {"alignments": [7, 8, 9], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "B1gDcrvdCm", "sid": 17}, {"labels": {"alignments": [10, 11, 12, 13], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "B1gDcrvdCm", "sid": 18}, {"labels": {"alignments": [10, 11, 12, 13], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "B1gDcrvdCm", "sid": 19}], "metadata": {"anno": "anno9", "review": "HJgQO5qAnQ", "rebuttal": "B1gDcrvdCm", "conference": "ICLR2019", "title": "A   RECURRENT NEURAL CASCADE-BASED MODEL FOR CONTINUOUS-TIME DIFFUSION PROCESS", "reviewer": "AnonReviewer2", "forum_id": "SJNceh0cFX", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}}