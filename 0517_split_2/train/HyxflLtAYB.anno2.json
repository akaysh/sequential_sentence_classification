{"review": [{"text_id": "HyxflLtAYB", "sid": 0, "sentence": "Summary:"}, {"text_id": "HyxflLtAYB", "sid": 1, "sentence": "This paper describes a contextual encoding scheme for reconstruction of 3D pointclouds from 2D images."}, {"text_id": "HyxflLtAYB", "sid": 2, "sentence": "An encoder outputs the parameters of a hierarchy of reconstruction networks that can be applied in succession to map random samples on a unit sphere to the surface of the reconstructed shape."}, {"text_id": "HyxflLtAYB", "sid": 3, "sentence": "Strengths:"}, {"text_id": "HyxflLtAYB", "sid": 4, "sentence": "The author's model was quite novel in my opinion."}, {"text_id": "HyxflLtAYB", "sid": 5, "sentence": "Deep 2D->3D is becoming a crowded space and there are many other models that encode image inputs, and many others that perform recursive or composition-based decoding."}, {"text_id": "HyxflLtAYB", "sid": 6, "sentence": "However, the particular link here was interesting, and I appreciate the small number of parameters resulting in solid reconstruction performance."}, {"text_id": "HyxflLtAYB", "sid": 7, "sentence": "While most related work was covered well, I believe the authors could have a more up-to-date list of recent work that reconstructs triangle-mesh representations from images [A-C] (especially since several of these methods has an architecture that involves encoding and subsequent compositional refinement)."}, {"text_id": "HyxflLtAYB", "sid": 8, "sentence": "Some of the reconstructions shown in this paper are quite impressive, and the quantitative results show outperforming 2 recent methods."}, {"text_id": "HyxflLtAYB", "sid": 9, "sentence": "I did appreciate also the novel path-based evaluation of shape accuracy in the Appendix, although it would have been helpful to see more discussion of this in the main paper."}, {"text_id": "HyxflLtAYB", "sid": 10, "sentence": "Areas for improvement:"}, {"text_id": "HyxflLtAYB", "sid": 11, "sentence": "I found that the core technical description was quite brief and would have benefited from simply more detail and space."}, {"text_id": "HyxflLtAYB", "sid": 12, "sentence": "You have argued that your method is sensible to try (cog. sci motivations), and shown that one instance works, but what can we expect in a more mathematical or general sense? Can any sizes of encoder and mapping network fit together? How does the number of mapping layers effect performance? Won't we eventually expect vanishing/exploding gradients with particular activation and can one address this in some way?"}, {"text_id": "HyxflLtAYB", "sid": 13, "sentence": "I note that recent papers in this field tend to perform significantly more extensive experimental evaluation, typically selecting a wider range of competitors and using a number of more standardized metrics including IOU, F1 score and CD and typically repeating these at a variety of resolutions or on additional datasets or category splits etc."}, {"text_id": "HyxflLtAYB", "sid": 14, "sentence": "Decision:"}, {"text_id": "HyxflLtAYB", "sid": 15, "sentence": "Weak reject because the idea is quite interesting, but I believe a more thorough explanation and expanded experimental comparison would be of great help to ensure the community can appreciate this work."}, {"text_id": "HyxflLtAYB", "sid": 16, "sentence": "Additional citations suggested:"}, {"text_id": "HyxflLtAYB", "sid": 17, "sentence": "[A] Pixel2Mesh: Generating 3D Mesh Models from Single RGB Images. Wang, Zhang, Li, Fu, Liu and Jiang. ECCV 2018."}, {"text_id": "HyxflLtAYB", "sid": 18, "sentence": "[B] MeshCNN: A Network with an Edge. Hanocka, Hertz, Fish, Giryes, Fleishman and Cohen-Or. SIGGRAPH 2019."}, {"text_id": "HyxflLtAYB", "sid": 19, "sentence": "[C] GEOMetrics: Exploiting Structure for Graph-Encoded Objects. Smith, Fujimoto, Romero and Meger. ICML 2019."}], "reviewlabels": [{"text_id": "HyxflLtAYB", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxflLtAYB", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxflLtAYB", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxflLtAYB", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxflLtAYB", "sid": 4, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxflLtAYB", "sid": 5, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxflLtAYB", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Motivation/Impact", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxflLtAYB", "sid": 7, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Meaningful Comparison", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxflLtAYB", "sid": 8, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxflLtAYB", "sid": 9, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxflLtAYB", "sid": 10, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxflLtAYB", "sid": 11, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxflLtAYB", "sid": 12, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxflLtAYB", "sid": 13, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxflLtAYB", "sid": 14, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxflLtAYB", "sid": 15, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxflLtAYB", "sid": 16, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxflLtAYB", "sid": 17, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Meaningful Comparison", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxflLtAYB", "sid": 18, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Meaningful Comparison", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HyxflLtAYB", "sid": 19, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Meaningful Comparison", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "r1gIbEt9jr", "sid": 0, "sentence": "Thank you for your thoughtful review."}, {"text_id": "r1gIbEt9jr", "sid": 1, "sentence": "We have been hard at work to perform additional experiments to compare with other state of the art methods on a broader dataset."}, {"text_id": "r1gIbEt9jr", "sid": 2, "sentence": "We summarize the changes here and will upload a revised the manuscript with complete quantitative evaluations before the revision deadline."}, {"text_id": "r1gIbEt9jr", "sid": 3, "sentence": "Q1: More extensive evaluations"}, {"text_id": "r1gIbEt9jr", "sid": 4, "sentence": "In response to your comments, we have trained and tested our method on the dataset provided in [1], using the F1 score rather than Chamfer Distance in accordance with the recommendations in that work."}, {"text_id": "r1gIbEt9jr", "sid": 5, "sentence": "This dataset contains more than 4 times as many classes as our original dataset."}, {"text_id": "r1gIbEt9jr", "sid": 6, "sentence": "We find that HOF is competitive with the performance of various state of the art methods reported in [1], showing the highest average F1 score out of all methods compared in [1]."}, {"text_id": "r1gIbEt9jr", "sid": 7, "sentence": "See Section 4.1.2 for added discussion, and the Appendix Sections A7 and A8 for complete class performance breakdowns for both our original experiments as well as the new comparison with [1]."}, {"text_id": "r1gIbEt9jr", "sid": 8, "sentence": "We hope this extended comparison provides a more convincing experimental evaluation of HOF."}, {"text_id": "r1gIbEt9jr", "sid": 9, "sentence": "Q2: Technical description and justification"}, {"text_id": "r1gIbEt9jr", "sid": 10, "sentence": "In the paper, we make the observation that codeword based approaches are equivalent to learning the biases of a fixed network, whereas the fast-weights-based HOF approach learns all of the weights."}, {"text_id": "r1gIbEt9jr", "sid": 11, "sentence": "Therefore, we conclude that HOF is mathematically at least as general as codeword based architectures."}, {"text_id": "r1gIbEt9jr", "sid": 12, "sentence": "We further show, with experiments, that the coding provided by HOF is more efficient than codeword-based approaches in terms of number of parameters in the decoder."}, {"text_id": "r1gIbEt9jr", "sid": 13, "sentence": "There is similar evidence in the literature which suggests that fast-weights based approaches can be more efficient than static networks."}, {"text_id": "r1gIbEt9jr", "sid": 14, "sentence": "However at this point, similar to our paper, the evidence is empirical and a theoretical justification of this phenomenon is missing."}, {"text_id": "r1gIbEt9jr", "sid": 15, "sentence": "In response to your comments, in our concluding remarks, we mention this lack of theoretical analysis and note it as an important direction for future research"}, {"text_id": "r1gIbEt9jr", "sid": 16, "sentence": "Q3: Architecture of encoder/mapping network"}, {"text_id": "r1gIbEt9jr", "sid": 17, "sentence": "In addition to experiments on a new dataset, we have performed new evaluations of variants of HOF on our original dataset to demonstrate that HOF performs competitively even when we change the encoder architecture, decoder depth, decoder activation function, or input sampling for the decoder network."}, {"text_id": "r1gIbEt9jr", "sid": 18, "sentence": "For example, using Resnet18 as the encoder network gives almost identical performance in terms of average chamfer distance on our original test set."}, {"text_id": "r1gIbEt9jr", "sid": 19, "sentence": "The complete quantitative results of these comparisons will be included in an updated PDF before the end of the discussion period."}, {"text_id": "r1gIbEt9jr", "sid": 20, "sentence": "Q4: Number of mapping layers"}, {"text_id": "r1gIbEt9jr", "sid": 21, "sentence": "Our original results reported in Table 1 compare two different mapping function architectures."}, {"text_id": "r1gIbEt9jr", "sid": 22, "sentence": "HOF-1 has one hidden layer with 1024 units, HOF-3 has 3 hidden layers with 128 units each."}, {"text_id": "r1gIbEt9jr", "sid": 23, "sentence": "We have updated the text to clarify this distinction."}, {"text_id": "r1gIbEt9jr", "sid": 24, "sentence": "In response to your comments, we have also conducted an additional experiment with a mapping network with 6 hidden layers with 128 units each; the test performance of this architecture is almost identical to that of HOF-3 (1.2485 average Chamfer distance with 6 layers compared with 1.247 average CD for 3 layers)."}, {"text_id": "r1gIbEt9jr", "sid": 25, "sentence": "Q5: Vanishing/exploding gradients"}, {"text_id": "r1gIbEt9jr", "sid": 26, "sentence": "In all of our experiments, we address the problem of vanishing/exploding gradients by dividing by the square root of the in-degree of each neuron (as in [2])."}, {"text_id": "r1gIbEt9jr", "sid": 27, "sentence": "Using the same initialization in the encoder network, we find that training a mapping function with 6 hidden layers (\"HOF-6\") trained easily with no modifications to our training code."}, {"text_id": "r1gIbEt9jr", "sid": 28, "sentence": "Another advantage of HOF over deeper, fixed decoder architectures is that it admits extremely shallow decoders, which require less careful tuning of hyperparameters such as initialization scaling and normalization compared with deeper networks."}, {"text_id": "r1gIbEt9jr", "sid": 29, "sentence": "For this work, our goal was not necessarily to find the optimal architecture for the decoder, but rather to demonstrate that the usage of the higher-order function paradigm allows for a much smaller decoder architecture than LVC methods."}, {"text_id": "r1gIbEt9jr", "sid": 30, "sentence": "Thank you for bringing the additional literature to our attention."}, {"text_id": "r1gIbEt9jr", "sid": 31, "sentence": "We have included it in our discussion of related work in a revised manuscript."}, {"text_id": "r1gIbEt9jr", "sid": 32, "sentence": "We have also updated the text to more clearly explain the path-based evaluation and its motivation."}, {"text_id": "r1gIbEt9jr", "sid": 33, "sentence": "We hope that these additional experiments better demonstrate the effectiveness of HOF as a competitive, parameter-efficient 3d reconstruction paradigm."}, {"text_id": "r1gIbEt9jr", "sid": 34, "sentence": "Thank you again for your feedback."}, {"text_id": "r1gIbEt9jr", "sid": 35, "sentence": "[1] M. Tatarchenko, S. R. Richter, R. Ranftl, Z. Li, V. Koltun, and T. Brox, \u201cWhat do single-view 3d reconstruction networks learn?,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3405\u2013 3414, 2019."}, {"text_id": "r1gIbEt9jr", "sid": 36, "sentence": "[2] K. He, X. Zhang, S. Ren, and J. Sun. Delving deep into rectifiers: Surpassing human-level performance on imagenet classification. In ICCV, 2015."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "r1gIbEt9jr", "sid": 0}, {"labels": {"alignments": [], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "r1gIbEt9jr", "sid": 1}, {"labels": {"alignments": [], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "r1gIbEt9jr", "sid": 2}, {"labels": {"alignments": [13, 15], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "r1gIbEt9jr", "sid": 3}, {"labels": {"alignments": [13, 15], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "r1gIbEt9jr", "sid": 4}, {"labels": {"alignments": [13, 15], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gIbEt9jr", "sid": 5}, {"labels": {"alignments": [13, 15], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gIbEt9jr", "sid": 6}, {"labels": {"alignments": [13, 15], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "r1gIbEt9jr", "sid": 7}, {"labels": {"alignments": [13, 15], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "r1gIbEt9jr", "sid": 8}, {"labels": {"alignments": [11, 12], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "r1gIbEt9jr", "sid": 9}, {"labels": {"alignments": [11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gIbEt9jr", "sid": 10}, {"labels": {"alignments": [11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gIbEt9jr", "sid": 11}, {"labels": {"alignments": [11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gIbEt9jr", "sid": 12}, {"labels": {"alignments": [11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gIbEt9jr", "sid": 13}, {"labels": {"alignments": [11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gIbEt9jr", "sid": 14}, {"labels": {"alignments": [11, 12], "responsetype": "future", "coarseresponse": "concur"}, "text_id": "r1gIbEt9jr", "sid": 15}, {"labels": {"alignments": [12], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "r1gIbEt9jr", "sid": 16}, {"labels": {"alignments": [12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gIbEt9jr", "sid": 17}, {"labels": {"alignments": [12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gIbEt9jr", "sid": 18}, {"labels": {"alignments": [12], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "r1gIbEt9jr", "sid": 19}, {"labels": {"alignments": [12], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "r1gIbEt9jr", "sid": 20}, {"labels": {"alignments": [12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gIbEt9jr", "sid": 21}, {"labels": {"alignments": [12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gIbEt9jr", "sid": 22}, {"labels": {"alignments": [12], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "r1gIbEt9jr", "sid": 23}, {"labels": {"alignments": [12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gIbEt9jr", "sid": 24}, {"labels": {"alignments": [12], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "r1gIbEt9jr", "sid": 25}, {"labels": {"alignments": [12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gIbEt9jr", "sid": 26}, {"labels": {"alignments": [12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gIbEt9jr", "sid": 27}, {"labels": {"alignments": [12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gIbEt9jr", "sid": 28}, {"labels": {"alignments": [12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "r1gIbEt9jr", "sid": 29}, {"labels": {"alignments": [16, 17, 18, 19], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "r1gIbEt9jr", "sid": 30}, {"labels": {"alignments": [16, 17, 18, 19], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "r1gIbEt9jr", "sid": 31}, {"labels": {"alignments": [16, 17, 18, 19], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "r1gIbEt9jr", "sid": 32}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "r1gIbEt9jr", "sid": 33}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "r1gIbEt9jr", "sid": 34}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "r1gIbEt9jr", "sid": 35}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "r1gIbEt9jr", "sid": 36}], "metadata": {"anno": "anno2", "review": "HyxflLtAYB", "rebuttal": "r1gIbEt9jr", "conference": "ICLR2020", "title": "Higher-Order Function Networks for Learning Composable 3D Object Representations", "reviewer": "AnonReviewer2", "forum_id": "HJgfDREKDB", "rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years."}}