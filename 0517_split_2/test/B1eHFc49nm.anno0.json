{"review": [{"text_id": "B1eHFc49nm", "sid": 0, "sentence": "Problem and contribution:"}, {"text_id": "B1eHFc49nm", "sid": 1, "sentence": "The paper studies if the Visual Question answering model \u201cFILM\u201d from Perez et al (2018) is able to decide if \u201cmost\u201d of the objects have a certain attribute or color."}, {"text_id": "B1eHFc49nm", "sid": 2, "sentence": "For this it tries to mimic the setup used to test human abilities in the study by Pietroski et al. (2009)."}, {"text_id": "B1eHFc49nm", "sid": 3, "sentence": "The main contribution of this is work is a discussion of how a model could solve the problem of deciding \u201cmost\u201d and the study which shows that the studied model has some ability to do this."}, {"text_id": "B1eHFc49nm", "sid": 4, "sentence": "From this the paper concludes that the model is likely to have some approximate number system."}, {"text_id": "B1eHFc49nm", "sid": 5, "sentence": "Strengths:"}, {"text_id": "B1eHFc49nm", "sid": 6, "sentence": "1.\tThe paper looks at a new angle to study and characterize CNN models in general, and VQA models in particular by looking into the psycholinguistic literature experimental setup studied with human subjects."}, {"text_id": "B1eHFc49nm", "sid": 7, "sentence": "2.\tThe paper studies different variants of controlling for different factors (e.g. pairing data points, area used, different training data and pre-trained vs. trained from scratch CNN models)"}, {"text_id": "B1eHFc49nm", "sid": 8, "sentence": "3.\tIt is interesting to see that the models performance reasonably aligns with the curve predicted by \u201cWeber\u2019s law\u201d."}, {"text_id": "B1eHFc49nm", "sid": 9, "sentence": "Weaknesses:"}, {"text_id": "B1eHFc49nm", "sid": 10, "sentence": "4.\tNumber of objects vs. ratios is not disentangled: While the paper clarifies that not only a smaller number of objects are used, it would be interesting to understand if similar conclusions hold if only the same number or about the same number of total objects are used but the ratios change (at least for more extreme ratios, 1:2, this seems to be the case as they achieve 100% accuracy)."}, {"text_id": "B1eHFc49nm", "sid": 11, "sentence": "5."}, {"text_id": "B1eHFc49nm", "sid": 12, "sentence": "The paper only focusses on a single VQA model (FILM) which limits the understanding if this observation is specific to this model; what about other models such as the one from Hudson & Manning (2018), or Relation Networks (Santoro et al) or even simpler baselines: A system which two attention mechanisms (without normalizations) which are sum pooled and then compared would sort of explicitly encode the idea of the APN system."}, {"text_id": "B1eHFc49nm", "sid": 13, "sentence": "It would be valuable to compare them to see how different systems (can) solve this task."}, {"text_id": "B1eHFc49nm", "sid": 14, "sentence": "I would expect that the architecture favors certain capabilities; e.g. Relation Networks might lead more to a paring-based strategy. Or Zhang et al. (2018) might be able to exploit explicit counting to solve the task."}, {"text_id": "B1eHFc49nm", "sid": 15, "sentence": "6.\tThe \u201cmost\u201d ability or APN ability seems to be highly related to accumulation in neural networks."}, {"text_id": "B1eHFc49nm", "sid": 16, "sentence": "The paper FiLM uses global max-pooling and I am wondering if this affect this ability."}, {"text_id": "B1eHFc49nm", "sid": 17, "sentence": "7.\tThe study is only performed on symbols which a very large training set (given the difficulty of the problem) and it not clear how well this generalizes to real images or scenarios with less training data."}, {"text_id": "B1eHFc49nm", "sid": 18, "sentence": "7.1."}, {"text_id": "B1eHFc49nm", "sid": 19, "sentence": "Maybe beyond the scope of this work, but it would be interesting to understand how much training data different models need to obtain this capability."}, {"text_id": "B1eHFc49nm", "sid": 20, "sentence": "8.\tFor evaluation: Are there distractors, i.e. elements which don\u2019t belong to set A or B? If not, how would distractors affect it."}, {"text_id": "B1eHFc49nm", "sid": 21, "sentence": "9.\tClarity:"}, {"text_id": "B1eHFc49nm", "sid": 22, "sentence": "9.1."}, {"text_id": "B1eHFc49nm", "sid": 23, "sentence": "The equation between equation (1) and (2) misses a number [I will call it 1.5 for now]"}, {"text_id": "B1eHFc49nm", "sid": 24, "sentence": "9.2.\tIn formula (1.5) \u201c<=>\u201d seems to be used at different levels (?) it would be good to use brackets to make clear which level \u201c<=>\u201d refers to."}, {"text_id": "B1eHFc49nm", "sid": 25, "sentence": "Minor:"}, {"text_id": "B1eHFc49nm", "sid": 26, "sentence": "10.\tThe title suggests that the paper studies multiple VQA models but only a single model is studied."}, {"text_id": "B1eHFc49nm", "sid": 27, "sentence": "Conclusion:"}, {"text_id": "B1eHFc49nm", "sid": 28, "sentence": "The paper looks into an interesting direction to study CNN models but has some limitations including studying only a single VQA model type, limited to artificially generated images."}], "reviewlabels": [{"text_id": "B1eHFc49nm", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eHFc49nm", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eHFc49nm", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eHFc49nm", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eHFc49nm", "sid": 4, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eHFc49nm", "sid": 5, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eHFc49nm", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eHFc49nm", "sid": 7, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eHFc49nm", "sid": 8, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eHFc49nm", "sid": 9, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eHFc49nm", "sid": 10, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eHFc49nm", "sid": 11, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eHFc49nm", "sid": 12, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eHFc49nm", "sid": 13, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eHFc49nm", "sid": 14, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eHFc49nm", "sid": 15, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eHFc49nm", "sid": 16, "labels": {"coarse": "Request", "fine": "Request.Clarification", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eHFc49nm", "sid": 17, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eHFc49nm", "sid": 18, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eHFc49nm", "sid": 19, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eHFc49nm", "sid": 20, "labels": {"coarse": "Request", "fine": "Request.Clarification", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eHFc49nm", "sid": 21, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eHFc49nm", "sid": 22, "labels": {"coarse": "Request", "fine": "Request.Typo", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "B1eHFc49nm", "sid": 23, "labels": {"coarse": "Request", "fine": "Request.Typo", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "B1eHFc49nm", "sid": 24, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eHFc49nm", "sid": 25, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eHFc49nm", "sid": 26, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eHFc49nm", "sid": 27, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eHFc49nm", "sid": 28, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "Ske5xOUn6m", "sid": 0, "sentence": "Many thanks for the valuable feedback! We uploaded a revised version of the paper, and in the following address the weaknesses you pointed out:"}, {"text_id": "Ske5xOUn6m", "sid": 1, "sentence": "4."}, {"text_id": "Ske5xOUn6m", "sid": 2, "sentence": "Note that the training data is not constrained with respect to ratios and number of objects addressed by the caption, so the learned behavior should be independent of these aspects."}, {"text_id": "Ske5xOUn6m", "sid": 3, "sentence": "Moreover, note that for most ratios there is only one combination of numbers with at most 15 objects in total, but larger images fitting a greater total number of objects would definitely be an option here."}, {"text_id": "Ske5xOUn6m", "sid": 4, "sentence": "For the less close-to-balanced ratios 1:2, 2:3, 3:4 where there are multiple possibilities, performance generally is (close-to-)perfect, indicating that there is no increased difficulty of learning multiples in the presence of more close-to-balanced ratios (for instance, 6:9 vs 7:8)."}, {"text_id": "Ske5xOUn6m", "sid": 5, "sentence": "We hope this clarifies your concern."}, {"text_id": "Ske5xOUn6m", "sid": 6, "sentence": "5. We fully agree that it would be very interesting to investigate these models."}, {"text_id": "Ske5xOUn6m", "sid": 7, "sentence": "For this paper, we decided to focus on the methodology of investigating such questions in detail (the evaluation for FiLM alone comprises around 100 experiments) as opposed to focusing on the comparison of behavior of different models, and leave the latter to future work."}, {"text_id": "Ske5xOUn6m", "sid": 8, "sentence": "We added a few additional sentences to section 3.2 regarding that."}, {"text_id": "Ske5xOUn6m", "sid": 9, "sentence": "6. We added a few sentences to the end of section 2.4 on our speculative intuition regarding what strategy a model may prefer."}, {"text_id": "Ske5xOUn6m", "sid": 10, "sentence": "We didn't think about the fact that one may want to control which strategy is learned, which would indeed be interesting, but that's why we considered FiLM as is and didn't experiment with changing architecture details."}, {"text_id": "Ske5xOUn6m", "sid": 11, "sentence": "At the same time, considering that understanding \"most\" is only one of many capabilities a VQA model is supposed to learn, these results are unlikely to be an important influencing factor for architecture choice, while at least knowing about the properties of a model is nonetheless interesting."}, {"text_id": "Ske5xOUn6m", "sid": 12, "sentence": "7. The evaluation is supposed to show what an architecture is capable of learning under \"ideal\" conditions."}, {"text_id": "Ske5xOUn6m", "sid": 13, "sentence": "It's an interesting question whether/how this changes when gradually shifting towards \"less ideal\" setups."}, {"text_id": "Ske5xOUn6m", "sid": 14, "sentence": "An advantage of using a controlled setup like ours is that this is possible to investigate, to some degree at least (for instance, add more types of captions to the training data, not just quantifier statements)."}, {"text_id": "Ske5xOUn6m", "sid": 15, "sentence": "At some point we may be interested in actually investigating the same for real-world data, but we think it's unclear right now what exactly such evaluation data should ideally look like, what problems are most interesting, what details to pay attention to. Artificial data allows us to investigate these questions while avoiding the elaborate and expensive process of obtaining real-world data."}, {"text_id": "Ske5xOUn6m", "sid": 16, "sentence": "8. Note that the training data is far less constrained than the evaluation data, including various distracting aspects like additional shapes/colors."}, {"text_id": "Ske5xOUn6m", "sid": 17, "sentence": "The evaluation data doesn't contain such distractors, but it would of course be possible (and potentially interesting) to add such."}, {"text_id": "Ske5xOUn6m", "sid": 18, "sentence": "We didn't do so since we considered instances with only \"relevant\" attributes to be the most difficult setup, like a minimal pair, where a model is required to focus on all objects and both their shape and color attribute to decide correctly."}, {"text_id": "Ske5xOUn6m", "sid": 19, "sentence": "9. We incorporated the changes as you suggested."}, {"text_id": "Ske5xOUn6m", "sid": 20, "sentence": "Thanks!"}, {"text_id": "Ske5xOUn6m", "sid": 21, "sentence": "10. We didn't think about this interpretation -- our intention was to signal that we take the \"The Meaning of 'Most'\" setup and methodology of Pietroski et al. from psychology, and implement a deep learning version for visual question answering models."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "Ske5xOUn6m", "sid": 0}, {"labels": {"alignments": [10], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "Ske5xOUn6m", "sid": 1}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Ske5xOUn6m", "sid": 2}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Ske5xOUn6m", "sid": 3}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Ske5xOUn6m", "sid": 4}, {"labels": {"alignments": [10], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "Ske5xOUn6m", "sid": 5}, {"labels": {"alignments": [12], "responsetype": "future", "coarseresponse": "concur"}, "text_id": "Ske5xOUn6m", "sid": 6}, {"labels": {"alignments": [12], "responsetype": "future", "coarseresponse": "concur"}, "text_id": "Ske5xOUn6m", "sid": 7}, {"labels": {"alignments": [12], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "Ske5xOUn6m", "sid": 8}, {"labels": {"alignments": [12], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "Ske5xOUn6m", "sid": 9}, {"labels": {"alignments": [15, 16], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Ske5xOUn6m", "sid": 10}, {"labels": {"alignments": [15, 16], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Ske5xOUn6m", "sid": 11}, {"labels": {"alignments": [17], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "Ske5xOUn6m", "sid": 12}, {"labels": {"alignments": [17], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "Ske5xOUn6m", "sid": 13}, {"labels": {"alignments": [17], "responsetype": "mitigate-criticism", "coarseresponse": "dispute"}, "text_id": "Ske5xOUn6m", "sid": 14}, {"labels": {"alignments": [17], "responsetype": "future", "coarseresponse": "concur"}, "text_id": "Ske5xOUn6m", "sid": 15}, {"labels": {"alignments": [20], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Ske5xOUn6m", "sid": 16}, {"labels": {"alignments": [20], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Ske5xOUn6m", "sid": 17}, {"labels": {"alignments": [20], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Ske5xOUn6m", "sid": 18}, {"labels": {"alignments": [21, 22, 23, 24], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "Ske5xOUn6m", "sid": 19}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "Ske5xOUn6m", "sid": 20}, {"labels": {"alignments": [26], "responsetype": "concede-criticism", "coarseresponse": "concur"}, "text_id": "Ske5xOUn6m", "sid": 21}], "metadata": {"anno": "anno0", "review": "B1eHFc49nm", "rebuttal": "Ske5xOUn6m", "conference": "ICLR2019", "title": "The meaning of \"most\" for visual question answering models", "reviewer": "AnonReviewer1", "forum_id": "rket4i0qtX", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}}