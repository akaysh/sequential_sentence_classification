{"review": [{"text_id": "B1eVKwraFH", "sid": 0, "sentence": "In the paper, the authors propose a pipelined backpropagation algorithm faster than the traditional backpropagation algorithm."}, {"text_id": "B1eVKwraFH", "sid": 1, "sentence": "The proposed method allows computing gradients using stale weights such that computations in different layers can be executed in parallel."}, {"text_id": "B1eVKwraFH", "sid": 2, "sentence": "They also conduct experiments to evaluate the effect of staleness and show that the proposed method is faster than compared methods."}, {"text_id": "B1eVKwraFH", "sid": 3, "sentence": "I have the following concerns:"}, {"text_id": "B1eVKwraFH", "sid": 4, "sentence": "1) There are several important works on model-parallelism and convergence guarantee of pipeline-based methods missing in this paper, for example [1][2]."}, {"text_id": "B1eVKwraFH", "sid": 5, "sentence": "2) Does the proposed method store immediate activations or recompute the activations in the backward pass?"}, {"text_id": "B1eVKwraFH", "sid": 6, "sentence": "3) In the experiments, the accuracy values are too low for me."}, {"text_id": "B1eVKwraFH", "sid": 7, "sentence": "For example, resnet110 on cifar10 is 91.99% only, it should be around 93%, an example online"}, {"text_id": "B1eVKwraFH", "sid": 8, "sentence": "https://github.com/akamaster/pytorch_resnet_cifar10."}, {"text_id": "B1eVKwraFH", "sid": 9, "sentence": "4) In the experiments, more comparisons with methods in [1] or [2] should be conducted given they are all parallelizing the backpropagation algorithm and achieve speedup in the training."}, {"text_id": "B1eVKwraFH", "sid": 10, "sentence": "5) Last but not least, convergence analysis of the proposed method should be provided given that asynchrony may lead to divergence in the optimization."}, {"text_id": "B1eVKwraFH", "sid": 11, "sentence": "[1] Huo, Zhouyuan, et al. \"Decoupled parallel backpropagation with convergence guarantee.\" arXiv preprint arXiv:1804.10574 (2018)."}, {"text_id": "B1eVKwraFH", "sid": 12, "sentence": "[2] Huo, Zhouyuan, Bin Gu, and Heng Huang. \"Training neural networks using features replay.\" Advances in Neural Information Processing Systems. 2018."}], "reviewlabels": [{"text_id": "B1eVKwraFH", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eVKwraFH", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eVKwraFH", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eVKwraFH", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eVKwraFH", "sid": 4, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eVKwraFH", "sid": 5, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eVKwraFH", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "B1eVKwraFH", "sid": 7, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "B1eVKwraFH", "sid": 8, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eVKwraFH", "sid": 9, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Meaningful Comparison", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eVKwraFH", "sid": 10, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eVKwraFH", "sid": 11, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1eVKwraFH", "sid": 12, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "Sye1hVSDjS", "sid": 0, "sentence": "1"}, {"text_id": "Sye1hVSDjS", "sid": 1, "sentence": "."}, {"text_id": "Sye1hVSDjS", "sid": 2, "sentence": "We thank the reviewer for pointing out papers [1] and [2]."}, {"text_id": "Sye1hVSDjS", "sid": 3, "sentence": "We will definitely cite them in the paper and include a discussion in related work on how our scheme compares to that proposed in the two papers."}, {"text_id": "Sye1hVSDjS", "sid": 4, "sentence": "In essence, our scheme is different than [1] in two key aspects: (1) we pipeline both the forward and backward passes of the backpropagation while [1] pipelines only the backward pass."}, {"text_id": "Sye1hVSDjS", "sid": 5, "sentence": "Further, equation (9) in [1] suggests that while weight updates use delayed gradients, the delayed weights (W^(t-K+k)) are used for the weight gradient calculation."}, {"text_id": "Sye1hVSDjS", "sid": 6, "sentence": "This is essentially similar to weight stashing used in PipeDream, which we compared to in our paper."}, {"text_id": "Sye1hVSDjS", "sid": 7, "sentence": "Thus, our scheme has the advantage of a smaller memory footprint."}, {"text_id": "Sye1hVSDjS", "sid": 8, "sentence": "The follow up work in [2] attempts to reduce the memory footprint through feature replay (i.e., re-computing activations during backward pass, similar to GPipe)."}, {"text_id": "Sye1hVSDjS", "sid": 9, "sentence": "Our scheme saves the activations instead of re-computing them to eliminate pipeline bubble, thus achieving better utilization of the accelerators (GPUs)."}, {"text_id": "Sye1hVSDjS", "sid": 10, "sentence": "We will edit the related work section to include the above discussion."}, {"text_id": "Sye1hVSDjS", "sid": 11, "sentence": "2.\tThe method proposed in our paper stores immediate activations, which is mentioned in Section 3 of the submission."}, {"text_id": "Sye1hVSDjS", "sid": 12, "sentence": "3."}, {"text_id": "Sye1hVSDjS", "sid": 13, "sentence": "We appreciate the pointer to the better performance of ResNet-110."}, {"text_id": "Sye1hVSDjS", "sid": 14, "sentence": "We trained the network for only 164 epochs with a batch size of 100, which is probably the reason that its inference accuracy is lower than expected."}, {"text_id": "Sye1hVSDjS", "sid": 15, "sentence": "Should we adopt the hyperparameters (a batch size of 128) and more training epochs (200 epochs) as shown at https://github.com/akamaster/pytorch_resnet_cifar10 , our ResNet-110 baseline reached 93.59% in inference accuracy, and the pipelined ResNet-110 reached 92.88% in inference accuracy."}, {"text_id": "Sye1hVSDjS", "sid": 16, "sentence": "The speedup obtained is 1.73X, slightly higher than the 1.71X obtained in our paper, which could be caused by the batch size increase that makes the GPU process more efficient."}, {"text_id": "Sye1hVSDjS", "sid": 17, "sentence": "The exact inference accuracy of the model is somewhat orthogonal to our study."}, {"text_id": "Sye1hVSDjS", "sid": 18, "sentence": "It is the trend of the decline in inference accuracy with pipelining is what we study and this trend exists with both our hyperparameters and those at https://github.com/akamaster/pytorch_resnet_cifar10."}, {"text_id": "Sye1hVSDjS", "sid": 19, "sentence": "Nonetheless, it is relatively easy for us to update the results in the paper with these new hyperparameters."}, {"text_id": "Sye1hVSDjS", "sid": 20, "sentence": "4."}, {"text_id": "Sye1hVSDjS", "sid": 21, "sentence": "Indeed, comparisons to the results in [1][2] would be interesting."}, {"text_id": "Sye1hVSDjS", "sid": 22, "sentence": "However, since the scheme in [1] employ weight stashing as PipeDream does and in [2] utilizes re-computing activations, as in GPipe, our comparisons to PipeDream and GPipe subsume comparisons to [1][2], particularly given the space limitations of submission."}, {"text_id": "Sye1hVSDjS", "sid": 23, "sentence": "5."}, {"text_id": "Sye1hVSDjS", "sid": 24, "sentence": "We appreciate such detailed and rigorous convergence analysis provided in [1] and [2]."}, {"text_id": "Sye1hVSDjS", "sid": 25, "sentence": "The main goal of our submission is to experimentally show that our pipelined training, using stale weights without weight stashing or micro-batching, is simpler and does converge."}, {"text_id": "Sye1hVSDjS", "sid": 26, "sentence": "The paper does achieve this goal, on a number of networks."}, {"text_id": "Sye1hVSDjS", "sid": 27, "sentence": "Given the limited space provided, it would be difficult to fit a convergence analysis in our paper."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "Sye1hVSDjS", "sid": 0}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "Sye1hVSDjS", "sid": 1}, {"labels": {"alignments": [4], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "Sye1hVSDjS", "sid": 2}, {"labels": {"alignments": [4], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "Sye1hVSDjS", "sid": 3}, {"labels": {"alignments": [4, 11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Sye1hVSDjS", "sid": 4}, {"labels": {"alignments": [4, 11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Sye1hVSDjS", "sid": 5}, {"labels": {"alignments": [4, 9, 11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Sye1hVSDjS", "sid": 6}, {"labels": {"alignments": [4, 9, 11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Sye1hVSDjS", "sid": 7}, {"labels": {"alignments": [4, 9, 11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Sye1hVSDjS", "sid": 8}, {"labels": {"alignments": [4, 9, 11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Sye1hVSDjS", "sid": 9}, {"labels": {"alignments": [4, 9, 11, 12], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "Sye1hVSDjS", "sid": 10}, {"labels": {"alignments": [5], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Sye1hVSDjS", "sid": 11}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "Sye1hVSDjS", "sid": 12}, {"labels": {"alignments": [6, 7, 8], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "Sye1hVSDjS", "sid": 13}, {"labels": {"alignments": [6, 7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Sye1hVSDjS", "sid": 14}, {"labels": {"alignments": [6, 7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Sye1hVSDjS", "sid": 15}, {"labels": {"alignments": [6, 7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Sye1hVSDjS", "sid": 16}, {"labels": {"alignments": [6, 7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Sye1hVSDjS", "sid": 17}, {"labels": {"alignments": [6, 7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Sye1hVSDjS", "sid": 18}, {"labels": {"alignments": [6, 7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Sye1hVSDjS", "sid": 19}, {"labels": {"alignments": [9], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "Sye1hVSDjS", "sid": 20}, {"labels": {"alignments": [9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Sye1hVSDjS", "sid": 21}, {"labels": {"alignments": [9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Sye1hVSDjS", "sid": 22}, {"labels": {"alignments": [10], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "Sye1hVSDjS", "sid": 23}, {"labels": {"alignments": [10], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "Sye1hVSDjS", "sid": 24}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Sye1hVSDjS", "sid": 25}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Sye1hVSDjS", "sid": 26}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "Sye1hVSDjS", "sid": 27}], "metadata": {"anno": "anno3", "review": "B1eVKwraFH", "rebuttal": "Sye1hVSDjS", "conference": "ICLR2020", "title": "Pipelined Training with Stale Weights of Deep Convolutional Neural Networks", "reviewer": "AnonReviewer1", "forum_id": "SkgTR3VFvH", "rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years."}}