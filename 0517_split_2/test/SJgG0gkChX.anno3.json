{"review": [{"text_id": "SJgG0gkChX", "sid": 0, "sentence": "In this paper the authors proposed a new policy gradient method, which is known as the angular policy gradient (APG), that aims to provide provably lower variance in the gradient estimate."}, {"text_id": "SJgG0gkChX", "sid": 1, "sentence": "Here they presented a stochastic policy gradient method for directional control."}, {"text_id": "SJgG0gkChX", "sid": 2, "sentence": "Under the set of parameterized Gaussian policies, they presented a unified analysis of the variance of APG and showed how it theoretically outperform (in terms of having lower variance) than other state-of-the art methods."}, {"text_id": "SJgG0gkChX", "sid": 3, "sentence": "They further evaluated the APG algorithms on a grid-world navigation domain as well as the King of Glory task, and showed that the APG estimator significantly out-performs the standard policy gradient."}, {"text_id": "SJgG0gkChX", "sid": 4, "sentence": "In general I think this paper addressed an important issue in policy gradient in terms of deriving a lower variance gradient estimate."}, {"text_id": "SJgG0gkChX", "sid": 5, "sentence": "In particular the authors showed that under the parameterized marginal distribution, such as the angular Gaussian distribution, the corresponding APG estimate has a lower variance estimate than that of CAPG."}, {"text_id": "SJgG0gkChX", "sid": 6, "sentence": "Furthermore, I also appreciate that they evaluated these results in realistic experiments such as the RTS game domains."}, {"text_id": "SJgG0gkChX", "sid": 7, "sentence": "My only question is on the possibility of deriving realistic APG algorithms beyond the class of angular Gaussian policy."}, {"text_id": "SJgG0gkChX", "sid": 8, "sentence": "In terms of the layout of the paper, I would also recommend including the exact algorithm pseudo-code used in the main paper."}], "reviewlabels": [{"text_id": "SJgG0gkChX", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJgG0gkChX", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJgG0gkChX", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJgG0gkChX", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJgG0gkChX", "sid": 4, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Motivation/Impact", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "SJgG0gkChX", "sid": 5, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Motivation/Impact", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "SJgG0gkChX", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJgG0gkChX", "sid": 7, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJgG0gkChX", "sid": 8, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "S1eUaqUjTQ", "sid": 0, "sentence": "Thank you for the time and effort spent reviewing our paper."}, {"text_id": "S1eUaqUjTQ", "sid": 1, "sentence": "We are glad you liked the paper."}, {"text_id": "S1eUaqUjTQ", "sid": 2, "sentence": "We want to emphasize one point that we perhaps did not highlight enough in our paper: there are other existing algorithms that fall into the marginal policy gradients framework."}, {"text_id": "S1eUaqUjTQ", "sid": 3, "sentence": "Specifically, researchers and practitioners both almost always clip actions for use in robotics control environments (read: MuJoCo tasks)."}, {"text_id": "S1eUaqUjTQ", "sid": 4, "sentence": "Recently, a reduced variance method was introduced by Fujita and Maeda (2018) for clipped action spaces."}, {"text_id": "S1eUaqUjTQ", "sid": 5, "sentence": "Their algorithm is also a member of the marginal policy gradients family and our theoretical results for MPG significantly tighten existing analyses of variance reduction that can be achieved for clipped actions."}, {"text_id": "S1eUaqUjTQ", "sid": 6, "sentence": "To respond to your question, yes it is possible (e.g. the example given above), but their is no general procedure that we know of to derive such methods."}, {"text_id": "S1eUaqUjTQ", "sid": 7, "sentence": "Rather, this would be done on an action space by action space basis"}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "S1eUaqUjTQ", "sid": 0}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "S1eUaqUjTQ", "sid": 1}, {"labels": {"alignments": [7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "S1eUaqUjTQ", "sid": 2}, {"labels": {"alignments": [7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "S1eUaqUjTQ", "sid": 3}, {"labels": {"alignments": [7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "S1eUaqUjTQ", "sid": 4}, {"labels": {"alignments": [7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "S1eUaqUjTQ", "sid": 5}, {"labels": {"alignments": [7], "responsetype": "future", "coarseresponse": "concur"}, "text_id": "S1eUaqUjTQ", "sid": 6}, {"labels": {"alignments": [7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "S1eUaqUjTQ", "sid": 7}], "metadata": {"anno": "anno3", "review": "SJgG0gkChX", "rebuttal": "S1eUaqUjTQ", "conference": "ICLR2019", "title": "Marginal Policy Gradients: A Unified Family of Estimators for Bounded Action Spaces with Applications", "reviewer": "AnonReviewer3", "forum_id": "HkgqFiAcFm", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}}