{"review": [{"text_id": "HkluNlHfcS", "sid": 0, "sentence": "This paper investigates the impact of stale weights on the statistical efficiency and performance in a pipelined backpropagation scheme that maximizes accelerator utilization while keeping the memory overhead modest."}, {"text_id": "HkluNlHfcS", "sid": 1, "sentence": "The paper proposes to combine pipelined and non-pipelined training in a hybrid scheme to address the issue of significant drop in accuracy when pipelining is deeper in the network."}, {"text_id": "HkluNlHfcS", "sid": 2, "sentence": "The performance of the proposed pipelined backpropagation is demonstrated on 2 GPUs using ResNet with speedups of up to 1.8X over a 1-GPU baseline and a small drop in inference accuracy."}, {"text_id": "HkluNlHfcS", "sid": 3, "sentence": "The paper is well written and easy to follow."}, {"text_id": "HkluNlHfcS", "sid": 4, "sentence": "The proposed idea is interesting and its effectiveness is well demonstrated with a promising speed and a small drop in accuracy."}, {"text_id": "HkluNlHfcS", "sid": 5, "sentence": "The proposed approach is compared to two existing works:  PipeDream [1] and GPipe [2]."}, {"text_id": "HkluNlHfcS", "sid": 6, "sentence": "Though promising results have been demonstrated, a drawback of the proposed method is that it introduces more memory overhead compared to GPipe."}, {"text_id": "HkluNlHfcS", "sid": 7, "sentence": "Although a detailed discussion is provided related to the memory consumption between the proposed method and PipeDream, no detailed discussion is provided with respect to GPipe."}, {"text_id": "HkluNlHfcS", "sid": 8, "sentence": "Further, no proper convergence analysis of the proposed approach is provided and is desired due to the likely divergence in the optimization."}, {"text_id": "HkluNlHfcS", "sid": 9, "sentence": "Minor comment: An interesting line of work is that of [3] which could be included in the discussion."}, {"text_id": "HkluNlHfcS", "sid": 10, "sentence": "Overall, the proposed approach is interesting and is shown to achieve promising results."}, {"text_id": "HkluNlHfcS", "sid": 11, "sentence": "However, memory overhead is still an issue compared to existing method."}, {"text_id": "HkluNlHfcS", "sid": 12, "sentence": "[1] Aaron Harlap, Deepak Narayanan, Amar Phanishayee, Vivek Seshadri, Nikhil Devanur, Greg Ganger, and Phil Gibbons. Pipedream: Fast and efficient pipeline parallel DNN training, 2018. URL http://arXiv:1806.03377."}, {"text_id": "HkluNlHfcS", "sid": 13, "sentence": "[2] Yanping Huang, Yonglong Cheng, Dehao Chen, HyoukJoong Lee, Jiquan Ngiam, Quoc V. Le, and Zhifeng Chen. Gpipe: Efficient training of giant neural networks using pipeline parallelism, 2018. URL http://arXiv:1811.06965."}, {"text_id": "HkluNlHfcS", "sid": 14, "sentence": "[3] Guanhua Wang, Shivaram Venkataraman, Amar Phanishayee, Jorgen Thelin, Nikhil Devanur, Ion Stoica: Blink: Fast and Generic Collectives for Distributed ML. arXiv:1910.04940, 2019."}], "reviewlabels": [{"text_id": "HkluNlHfcS", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkluNlHfcS", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkluNlHfcS", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkluNlHfcS", "sid": 3, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkluNlHfcS", "sid": 4, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkluNlHfcS", "sid": 5, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkluNlHfcS", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkluNlHfcS", "sid": 7, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkluNlHfcS", "sid": 8, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkluNlHfcS", "sid": 9, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkluNlHfcS", "sid": 10, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Motivation/Impact", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkluNlHfcS", "sid": 11, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Meaningful Comparison", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkluNlHfcS", "sid": 12, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkluNlHfcS", "sid": 13, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkluNlHfcS", "sid": 14, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "BkxCvEBDsH", "sid": 0, "sentence": "Indeed, GPipe [2] incurs less memory footprint than our pipelining scheme and PipeDream [1] because it only saves the activations at the boundary of each model partition and re-computes the activations of the model during the backward pass."}, {"text_id": "BkxCvEBDsH", "sid": 1, "sentence": "However, the re-computation still incurs pipeline bubbles during training."}, {"text_id": "BkxCvEBDsH", "sid": 2, "sentence": "Our scheme saves all activations instead of re-computing them to eliminate pipeline bubble, thus achieving better utilization for the accelerators (GPUs)."}, {"text_id": "BkxCvEBDsH", "sid": 3, "sentence": "Our scheme has less memory footprint than PipeDream because it does not stash weights."}, {"text_id": "BkxCvEBDsH", "sid": 4, "sentence": "The main goal of our submission is to experimentally show that our pipelined training, using stale weights without weight stashing [1] or micro-batching [2], is simpler and does converge."}, {"text_id": "BkxCvEBDsH", "sid": 5, "sentence": "The paper does achieve this goal, on a number of networks."}, {"text_id": "BkxCvEBDsH", "sid": 6, "sentence": "It would be difficult fit a detailed convergence analysis in our paper given the limited space provided."}, {"text_id": "BkxCvEBDsH", "sid": 7, "sentence": "Thank you for pointing out paper [3]."}, {"text_id": "BkxCvEBDsH", "sid": 8, "sentence": "We notice that it is submitted to arXive after the submission deadline of ICLR, thus we were unaware of it at the time of submission."}, {"text_id": "BkxCvEBDsH", "sid": 9, "sentence": "Nonetheless, we will cite it and discuss its approach in comparison to ours in the related work section of the final revised version of our paper."}], "rebuttallabels": [{"labels": {"alignments": [5, 6, 7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BkxCvEBDsH", "sid": 0}, {"labels": {"alignments": [5, 6, 7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BkxCvEBDsH", "sid": 1}, {"labels": {"alignments": [5, 6, 7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BkxCvEBDsH", "sid": 2}, {"labels": {"alignments": [5, 6, 7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BkxCvEBDsH", "sid": 3}, {"labels": {"alignments": [5, 6, 7, 8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BkxCvEBDsH", "sid": 4}, {"labels": {"alignments": [5, 6, 7, 8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BkxCvEBDsH", "sid": 5}, {"labels": {"alignments": [5, 6, 7, 8, 9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BkxCvEBDsH", "sid": 6}, {"labels": {"alignments": [9], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "BkxCvEBDsH", "sid": 7}, {"labels": {"alignments": [9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "BkxCvEBDsH", "sid": 8}, {"labels": {"alignments": [9], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "BkxCvEBDsH", "sid": 9}], "metadata": {"anno": "anno3", "review": "HkluNlHfcS", "rebuttal": "BkxCvEBDsH", "conference": "ICLR2020", "title": "Pipelined Training with Stale Weights of Deep Convolutional Neural Networks", "reviewer": "AnonReviewer3", "forum_id": "SkgTR3VFvH", "rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area."}}