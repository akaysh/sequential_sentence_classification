{"review": [{"text_id": "S1gyA_wmhX", "sid": 0, "sentence": "The paper suggests a new regularization technique which can be added on top of those used in AWD-LSTM of Merity et al. (2017) with little overhead."}, {"text_id": "S1gyA_wmhX", "sid": 1, "sentence": "This is a well-written paper with a clear structure."}, {"text_id": "S1gyA_wmhX", "sid": 2, "sentence": "The experiments are presented in a clear and understandable fashion, and the evaluation seems thorough."}, {"text_id": "S1gyA_wmhX", "sid": 3, "sentence": "The methodology seems sound, and the authors present the reader with all the information needed to replicate the experiments."}, {"text_id": "S1gyA_wmhX", "sid": 4, "sentence": "I would only suggest evaluating this technique on AWD-LSTM-MoS of Yang et al. (2017) to get a more complete picture."}, {"text_id": "S1gyA_wmhX", "sid": 5, "sentence": "References"}, {"text_id": "S1gyA_wmhX", "sid": 6, "sentence": "- Merity, S., Keskar, N.S. and Socher, R., 2017. Regularizing and optimizing LSTM language models. arXiv preprint arXiv:1708.02182."}, {"text_id": "S1gyA_wmhX", "sid": 7, "sentence": "- Yang, Z., Dai, Z., Salakhutdinov, R. and Cohen, W.W., 2017. Breaking the softmax bottleneck: A high-rank RNN language model."}, {"text_id": "S1gyA_wmhX", "sid": 8, "sentence": "arXiv preprint arXiv:1711.03953."}], "reviewlabels": [{"text_id": "S1gyA_wmhX", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "S1gyA_wmhX", "sid": 1, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "S1gyA_wmhX", "sid": 2, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "S1gyA_wmhX", "sid": 3, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Replicability", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "S1gyA_wmhX", "sid": 4, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Meaningful Comparison", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "S1gyA_wmhX", "sid": 5, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "S1gyA_wmhX", "sid": 6, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "S1gyA_wmhX", "sid": 7, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "S1gyA_wmhX", "sid": 8, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "HylZSxkGAQ", "sid": 0, "sentence": "We thank the reviewer very much for reading the paper carefully and providing us with constructive comments."}, {"text_id": "HylZSxkGAQ", "sid": 1, "sentence": "We have conducted further experiments applying our Past Decode Regularization (PDR) to the mixture-of-softmax (AWD-LSTM-MoS) model of (Yang et al. 2017)."}, {"text_id": "HylZSxkGAQ", "sid": 2, "sentence": "We use the same model sizes as in the paper."}, {"text_id": "HylZSxkGAQ", "sid": 3, "sentence": "Even with the very limited hyperparameter search in the vicinity of those used in the paper and fixing the PDR loss coefficient to 0.001 (as used in the other models in our paper), we see consistent gains on the Penn Treebank and WikiText-2 datasets."}, {"text_id": "HylZSxkGAQ", "sid": 4, "sentence": "The validation/test perplexities are as follows -"}, {"text_id": "HylZSxkGAQ", "sid": 5, "sentence": "AWD-LSTM-MoS+PDR  || AWD-LSTM-MoS (Yang et al. 2017)"}, {"text_id": "HylZSxkGAQ", "sid": 6, "sentence": "Penn Treebank with finetuning -"}, {"text_id": "HylZSxkGAQ", "sid": 7, "sentence": "56.2/53.8"}, {"text_id": "HylZSxkGAQ", "sid": 8, "sentence": "||  56.5/54.4"}, {"text_id": "HylZSxkGAQ", "sid": 9, "sentence": "Penn Treebank with dynamic evaluation -"}, {"text_id": "HylZSxkGAQ", "sid": 10, "sentence": "48.0/47.3"}, {"text_id": "HylZSxkGAQ", "sid": 11, "sentence": "||  48.3/47.7"}, {"text_id": "HylZSxkGAQ", "sid": 12, "sentence": "WikiText-2 with finetuning -"}, {"text_id": "HylZSxkGAQ", "sid": 13, "sentence": "63.0/60.5"}, {"text_id": "HylZSxkGAQ", "sid": 14, "sentence": "||  63.9/61.5"}, {"text_id": "HylZSxkGAQ", "sid": 15, "sentence": "WikiText-2 with dynamic evaluation -"}, {"text_id": "HylZSxkGAQ", "sid": 16, "sentence": "42.0/40.3"}, {"text_id": "HylZSxkGAQ", "sid": 17, "sentence": "||  42.4/40.7"}, {"text_id": "HylZSxkGAQ", "sid": 18, "sentence": "Thus we observe gains of 0.6 and 1.0 points in test perplexity for PTB and WT2."}, {"text_id": "HylZSxkGAQ", "sid": 19, "sentence": "With dynamic evaluation, the gains for both datasets is 0.4 points."}, {"text_id": "HylZSxkGAQ", "sid": 20, "sentence": "Note again that we did a very limited hyperparameter search and more exhaustive experiments will likely lead to even better gains by using PDR."}, {"text_id": "HylZSxkGAQ", "sid": 21, "sentence": "We will update and reorganize the experiments section in the paper accordingly."}, {"text_id": "HylZSxkGAQ", "sid": 22, "sentence": "The updated manuscript will be posted shortly."}, {"text_id": "HylZSxkGAQ", "sid": 23, "sentence": "Yang et al. 2017. Breaking the softmax bottleneck: A high-rank RNN language model. arXiv:1711.03953."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "HylZSxkGAQ", "sid": 0}, {"labels": {"alignments": [4], "responsetype": "done_manu_No", "coarseresponse": "concur"}, "text_id": "HylZSxkGAQ", "sid": 1}, {"labels": {"alignments": [4], "responsetype": "done_manu_No", "coarseresponse": "concur"}, "text_id": "HylZSxkGAQ", "sid": 2}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HylZSxkGAQ", "sid": 3}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HylZSxkGAQ", "sid": 4}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HylZSxkGAQ", "sid": 5}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HylZSxkGAQ", "sid": 6}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HylZSxkGAQ", "sid": 7}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HylZSxkGAQ", "sid": 8}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HylZSxkGAQ", "sid": 9}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HylZSxkGAQ", "sid": 10}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HylZSxkGAQ", "sid": 11}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HylZSxkGAQ", "sid": 12}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HylZSxkGAQ", "sid": 13}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HylZSxkGAQ", "sid": 14}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HylZSxkGAQ", "sid": 15}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HylZSxkGAQ", "sid": 16}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HylZSxkGAQ", "sid": 17}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HylZSxkGAQ", "sid": 18}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HylZSxkGAQ", "sid": 19}, {"labels": {"alignments": [4], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "HylZSxkGAQ", "sid": 20}, {"labels": {"alignments": [4], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "HylZSxkGAQ", "sid": 21}, {"labels": {"alignments": [4], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "HylZSxkGAQ", "sid": 22}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "HylZSxkGAQ", "sid": 23}], "metadata": {"anno": "anno0", "review": "S1gyA_wmhX", "rebuttal": "HylZSxkGAQ", "conference": "ICLR2019", "title": "Improved Language Modeling by Decoding the Past", "reviewer": "AnonReviewer3", "forum_id": "SklckhR5Ym", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}}