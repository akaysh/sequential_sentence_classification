{"review": [{"text_id": "ryxpUP6RKr", "sid": 0, "sentence": "Summary: This paper uses visual representation learned over monolingual corpora with image annotations, which overcomes the lack of large-scale bilingual sentence-image pairs for multimodal NMT."}, {"text_id": "ryxpUP6RKr", "sid": 1, "sentence": "Their approach enables visual information to be integrated into large-scale text-only NMT."}, {"text_id": "ryxpUP6RKr", "sid": 2, "sentence": "Experiments on four widely used translation datasets show that the proposed approach achieves significant improvements over strong baselines."}, {"text_id": "ryxpUP6RKr", "sid": 3, "sentence": "Strengths:"}, {"text_id": "ryxpUP6RKr", "sid": 4, "sentence": "- This paper is well motivated and well written. I especially like how they use external paired sentence-image data from Multi30k to learn weak pairs for sentences in machine translation."}, {"text_id": "ryxpUP6RKr", "sid": 5, "sentence": "- Experimental results are convincing. I like how low-resource translation is included as a priority in their experiments."}, {"text_id": "ryxpUP6RKr", "sid": 6, "sentence": "Weaknesses:"}, {"text_id": "ryxpUP6RKr", "sid": 7, "sentence": "- Do you have any explanations as to why the number of images, if too large, actually hurts translation performance? Is it because more images also leads to a higher chance of noisy images?"}, {"text_id": "ryxpUP6RKr", "sid": 8, "sentence": "- It would be nice to have an experiment that varies the size of the external paired sentence-image dataset and tested the impact on performance."}, {"text_id": "ryxpUP6RKr", "sid": 9, "sentence": "- Please comment on the extra computation required for obtaining image data for MT sentences and for learning image representations."}, {"text_id": "ryxpUP6RKr", "sid": 10, "sentence": "- Why are there missing BLEU scores and the number of parameters in Table 1?"}, {"text_id": "ryxpUP6RKr", "sid": 11, "sentence": "### Post rebuttal"}, {"text_id": "ryxpUP6RKr", "sid": 12, "sentence": "#"}, {"text_id": "ryxpUP6RKr", "sid": 13, "sentence": "##"}, {"text_id": "ryxpUP6RKr", "sid": 14, "sentence": "Thank you for your detailed answers to my questions."}], "reviewlabels": [{"text_id": "ryxpUP6RKr", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryxpUP6RKr", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryxpUP6RKr", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryxpUP6RKr", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryxpUP6RKr", "sid": 4, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryxpUP6RKr", "sid": 5, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryxpUP6RKr", "sid": 6, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryxpUP6RKr", "sid": 7, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Replicability", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryxpUP6RKr", "sid": 8, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryxpUP6RKr", "sid": 9, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Replicability", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryxpUP6RKr", "sid": 10, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "ryxpUP6RKr", "sid": 11, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "ryxpUP6RKr", "sid": 12, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "ryxpUP6RKr", "sid": 13, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "ryxpUP6RKr", "sid": 14, "labels": {"coarse": "Social", "fine": "Social", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "rJezfnmEoB", "sid": 0, "sentence": "Thanks so much for your constructive feedbacks. Please see our response below."}, {"text_id": "rJezfnmEoB", "sid": 1, "sentence": "1. Influence of the number of images:"}, {"text_id": "rJezfnmEoB", "sid": 2, "sentence": "Yes. The reason might be the higher chance of noise."}, {"text_id": "rJezfnmEoB", "sid": 3, "sentence": "It would be very important to provide a group of images that share similar patterns or topics."}, {"text_id": "rJezfnmEoB", "sid": 4, "sentence": "However, too many images for a sentence would have greater chance of noise."}, {"text_id": "rJezfnmEoB", "sid": 5, "sentence": "2. Impact of paired sentence-image dataset:"}, {"text_id": "rJezfnmEoB", "sid": 6, "sentence": "Yes. We add the external MS COCO image caption training set and evaluate on the EN-RO task for quick evaluation."}, {"text_id": "rJezfnmEoB", "sid": 7, "sentence": "The BLEU scores are 33.55 and 33.71 respectively for COCO only and Multi30K+COCO."}, {"text_id": "rJezfnmEoB", "sid": 8, "sentence": "In addition, we are also interested in the influence of the number of sentence-image pairs inspired by your suggestion."}, {"text_id": "rJezfnmEoB", "sid": 9, "sentence": "We randomly split the pairs of Multi30K into the proportion in [0.1, 0.3, 0.5, 0.7, 0.9], the corresponding BLEU scores are [33.07, 33.44, 34.01, 34.06, 33.80] respectively."}, {"text_id": "rJezfnmEoB", "sid": 10, "sentence": "These results indicate that a modest number of pairs would be beneficial."}, {"text_id": "rJezfnmEoB", "sid": 11, "sentence": "3. The extra computation:"}, {"text_id": "rJezfnmEoB", "sid": 12, "sentence": "The extra computation is negligible."}, {"text_id": "rJezfnmEoB", "sid": 13, "sentence": "The time of obtaining image data for MT sentences for EN-RO dataset, for example, is approximately less than 1 minute by tensor operation in GPU."}, {"text_id": "rJezfnmEoB", "sid": 14, "sentence": "The lookup table is formed as the mapping of token (only topic words) index to image id."}, {"text_id": "rJezfnmEoB", "sid": 15, "sentence": "Then, the retrieval method is applied as the tensor indexing from the sentence token (only topic words) index to image ids, which is the same as the procedure of word embedding."}, {"text_id": "rJezfnmEoB", "sid": 16, "sentence": "The retrieved image ids are then sorted by frequency."}, {"text_id": "rJezfnmEoB", "sid": 17, "sentence": "Learning image representations takes only about 2 minutes for all the 29,000 images in Multi30K using 6G GPU memory for feature extraction and 8 threads of CPU for transforming images."}, {"text_id": "rJezfnmEoB", "sid": 18, "sentence": "The extracted features are formed as the \u201cimage embedding layer\u201d with the size of (29000, 2400) for quick accessing in neural network."}, {"text_id": "rJezfnmEoB", "sid": 19, "sentence": "4. Missing BLEU scores & the number of parameters:"}, {"text_id": "rJezfnmEoB", "sid": 20, "sentence": "Because those missing numbers (N/A) are not reported in the corresponding literature."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "rJezfnmEoB", "sid": 0}, {"labels": {"alignments": [7], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJezfnmEoB", "sid": 1}, {"labels": {"alignments": [7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJezfnmEoB", "sid": 2}, {"labels": {"alignments": [7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJezfnmEoB", "sid": 3}, {"labels": {"alignments": [7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJezfnmEoB", "sid": 4}, {"labels": {"alignments": [8], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJezfnmEoB", "sid": 5}, {"labels": {"alignments": [8], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "rJezfnmEoB", "sid": 6}, {"labels": {"alignments": [8], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "rJezfnmEoB", "sid": 7}, {"labels": {"alignments": [8], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "rJezfnmEoB", "sid": 8}, {"labels": {"alignments": [8], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "rJezfnmEoB", "sid": 9}, {"labels": {"alignments": [8], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "rJezfnmEoB", "sid": 10}, {"labels": {"alignments": [9], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJezfnmEoB", "sid": 11}, {"labels": {"alignments": [9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJezfnmEoB", "sid": 12}, {"labels": {"alignments": [9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJezfnmEoB", "sid": 13}, {"labels": {"alignments": [9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJezfnmEoB", "sid": 14}, {"labels": {"alignments": [9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJezfnmEoB", "sid": 15}, {"labels": {"alignments": [9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJezfnmEoB", "sid": 16}, {"labels": {"alignments": [9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJezfnmEoB", "sid": 17}, {"labels": {"alignments": [9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJezfnmEoB", "sid": 18}, {"labels": {"alignments": [10], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJezfnmEoB", "sid": 19}, {"labels": {"alignments": [10], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJezfnmEoB", "sid": 20}], "metadata": {"anno": "anno10", "review": "ryxpUP6RKr", "rebuttal": "rJezfnmEoB", "conference": "ICLR2020", "title": "Neural Machine Translation with Universal Visual Representation", "reviewer": "AnonReviewer3", "forum_id": "Byl8hhNYPS", "rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area."}}