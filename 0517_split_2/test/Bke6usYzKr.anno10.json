{"review": [{"text_id": "Bke6usYzKr", "sid": 0, "sentence": "The authors study the generalization error of two-layer neural nets, where an asymptotic point of view is taken."}, {"text_id": "Bke6usYzKr", "sid": 1, "sentence": "Their main results can be summarized as follows."}, {"text_id": "Bke6usYzKr", "sid": 2, "sentence": "1. If only the second layer is optimized, they observe the double-descent phenomenon."}, {"text_id": "Bke6usYzKr", "sid": 3, "sentence": "2. However, if only the first layer is optimized, the double-descent is not observed."}, {"text_id": "Bke6usYzKr", "sid": 4, "sentence": "This shows that recent results for certain linear models (e.g. Song, Montanari 2019) do not directly transfer to neural networks."}, {"text_id": "Bke6usYzKr", "sid": 5, "sentence": "As the authors point out, however, if a different scaling is used in the asymptotics, double descent might still be observed."}, {"text_id": "Bke6usYzKr", "sid": 6, "sentence": "I see the following strengths of the paper."}, {"text_id": "Bke6usYzKr", "sid": 7, "sentence": "-This is a very well-written paper with a clear message."}, {"text_id": "Bke6usYzKr", "sid": 8, "sentence": "-The result is important and gives new insights into the generalization properties of neural networks."}, {"text_id": "Bke6usYzKr", "sid": 9, "sentence": "In my view, this is an interesting contribution, which should be accepted."}, {"text_id": "Bke6usYzKr", "sid": 10, "sentence": "---------"}, {"text_id": "Bke6usYzKr", "sid": 11, "sentence": "Thank you for your response. I will leave the rating unchanged."}], "reviewlabels": [{"text_id": "Bke6usYzKr", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Bke6usYzKr", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Bke6usYzKr", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Bke6usYzKr", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Bke6usYzKr", "sid": 4, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Bke6usYzKr", "sid": 5, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Bke6usYzKr", "sid": 6, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Bke6usYzKr", "sid": 7, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Bke6usYzKr", "sid": 8, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Bke6usYzKr", "sid": 9, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Bke6usYzKr", "sid": 10, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Bke6usYzKr", "sid": 11, "labels": {"coarse": "Social", "fine": "Social", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "B1xu2HCssS", "sid": 0, "sentence": "Thank you for the comments and suggestions."}, {"text_id": "B1xu2HCssS", "sid": 1, "sentence": "We agree that characterizing the generalization properties of neural network under different scalings is an important future direction."}, {"text_id": "B1xu2HCssS", "sid": 2, "sentence": "We have updated the manuscript with a few minor modifications: 1) Figure on the population risk of sigmoid network (first layer optimized) in addition to SoftPlus; 2) additional remarks on the population risk of network in the kernel regime in Section 5.2; 3) corrected typos."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "B1xu2HCssS", "sid": 0}, {"labels": {"alignments": [8], "responsetype": "future", "coarseresponse": "concur"}, "text_id": "B1xu2HCssS", "sid": 1}, {"labels": {"alignments": [8], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "B1xu2HCssS", "sid": 2}], "metadata": {"anno": "anno10", "review": "Bke6usYzKr", "rebuttal": "B1xu2HCssS", "conference": "ICLR2020", "title": "Generalization of Two-layer Neural Networks: An Asymptotic Viewpoint", "reviewer": "AnonReviewer2", "forum_id": "H1gBsgBYwH", "rating": "8: Accept", "experience_assessment": "I do not know much about this area."}}