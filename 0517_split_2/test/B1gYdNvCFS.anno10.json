{"review": [{"text_id": "B1gYdNvCFS", "sid": 0, "sentence": "This paper provides an approach to use visual information to improve text only neural machine translation systems."}, {"text_id": "B1gYdNvCFS", "sid": 1, "sentence": "The approach creates a \"topic word to images\" map using an existing image aligned translation corpora."}, {"text_id": "B1gYdNvCFS", "sid": 2, "sentence": "Given a source sentence, the model extracts relevant images, extracts their Resnet features and fuses them with the features generated from the word sequence."}, {"text_id": "B1gYdNvCFS", "sid": 3, "sentence": "The decoder uses these fused representation to generate the target sentence."}, {"text_id": "B1gYdNvCFS", "sid": 4, "sentence": "Overall, I like the approach, seems like it can be easily augmented to existing NMT systems."}, {"text_id": "B1gYdNvCFS", "sid": 5, "sentence": "One of the claims of the paper was to be able to use monolingual image aligned data."}, {"text_id": "B1gYdNvCFS", "sid": 6, "sentence": "However image captioning datasets are not mentioned."}, {"text_id": "B1gYdNvCFS", "sid": 7, "sentence": "It would make sense to use image captioning data to create the image lookup."}, {"text_id": "B1gYdNvCFS", "sid": 8, "sentence": "Also, what will be the performance of a standard image captioning system on the task ?"}, {"text_id": "B1gYdNvCFS", "sid": 9, "sentence": "I believe it will not be great, but I think for completeness, you should add such a baseline."}, {"text_id": "B1gYdNvCFS", "sid": 10, "sentence": "Minor comments:"}, {"text_id": "B1gYdNvCFS", "sid": 11, "sentence": "1. What is M in Algorithm 1 ?"}, {"text_id": "B1gYdNvCFS", "sid": 12, "sentence": "2. First paragraph in related work is very unrelated to the current subject, please remove."}], "reviewlabels": [{"text_id": "B1gYdNvCFS", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1gYdNvCFS", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1gYdNvCFS", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1gYdNvCFS", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1gYdNvCFS", "sid": 4, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1gYdNvCFS", "sid": 5, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1gYdNvCFS", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1gYdNvCFS", "sid": 7, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1gYdNvCFS", "sid": 8, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1gYdNvCFS", "sid": 9, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1gYdNvCFS", "sid": 10, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1gYdNvCFS", "sid": 11, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "B1gYdNvCFS", "sid": 12, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "r1eQFhX4ir", "sid": 0, "sentence": "Thanks for your constructive feedbacks! Please see our response below."}, {"text_id": "r1eQFhX4ir", "sid": 1, "sentence": "1. About image captioning."}, {"text_id": "r1eQFhX4ir", "sid": 2, "sentence": "Yes. Image captioning dataset is absolutely available for creating the lookup table."}, {"text_id": "r1eQFhX4ir", "sid": 3, "sentence": "As you suggest, we use MS COCO Image captioning dataset to learn a lookup table and apply it to the EN-RO translation task to do the quick evaluation."}, {"text_id": "r1eQFhX4ir", "sid": 4, "sentence": "As a result, the BLEU score is (33.55), which is comparable to the current lookup table (33.78) based on Multi30K, and outperforms the Trans. (base) (32.66)."}, {"text_id": "r1eQFhX4ir", "sid": 5, "sentence": "Regarding the performance of the standard image captioning system, we train a caption model (Show, Attend, and Tell (Xu et al., 2015b)) with fine-tuned encoder (ResNet101) on the COCO dataset to encode the images."}, {"text_id": "r1eQFhX4ir", "sid": 6, "sentence": "The result on EN-RO is 33.58."}, {"text_id": "r1eQFhX4ir", "sid": 7, "sentence": "We are a little bit uncertain if we have well understood this request because our task is text to text translation while image captioning is image to text."}, {"text_id": "r1eQFhX4ir", "sid": 8, "sentence": "If not, we are glad to address further."}, {"text_id": "r1eQFhX4ir", "sid": 9, "sentence": "2. About the minor comments."}, {"text_id": "r1eQFhX4ir", "sid": 10, "sentence": "(1)\tThis is typo. It is Q."}, {"text_id": "r1eQFhX4ir", "sid": 11, "sentence": "(2)\tYes. We will remove it following your suggestion."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "r1eQFhX4ir", "sid": 0}, {"labels": {"alignments": [5, 6, 7, 8, 9], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "r1eQFhX4ir", "sid": 1}, {"labels": {"alignments": [5, 6, 7, 8, 9], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "r1eQFhX4ir", "sid": 2}, {"labels": {"alignments": [5, 6, 7, 8, 9], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "r1eQFhX4ir", "sid": 3}, {"labels": {"alignments": [5, 6, 7, 8, 9], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "r1eQFhX4ir", "sid": 4}, {"labels": {"alignments": [5, 6, 7, 8, 9], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "r1eQFhX4ir", "sid": 5}, {"labels": {"alignments": [5, 6, 7, 8, 9], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "r1eQFhX4ir", "sid": 6}, {"labels": {"alignments": [5, 6, 7, 8, 9], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "r1eQFhX4ir", "sid": 7}, {"labels": {"alignments": [5, 6, 7, 8, 9], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "r1eQFhX4ir", "sid": 8}, {"labels": {"alignments": [10], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "r1eQFhX4ir", "sid": 9}, {"labels": {"alignments": [11], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "r1eQFhX4ir", "sid": 10}, {"labels": {"alignments": [12], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "r1eQFhX4ir", "sid": 11}], "metadata": {"anno": "anno10", "review": "B1gYdNvCFS", "rebuttal": "r1eQFhX4ir", "conference": "ICLR2020", "title": "Neural Machine Translation with Universal Visual Representation", "reviewer": "AnonReviewer2", "forum_id": "Byl8hhNYPS", "rating": "8: Accept", "experience_assessment": "I have published one or two papers in this area."}}