{"review": [{"text_id": "BJlxMu4a37", "sid": 0, "sentence": "This paper proposes use of intra-life coverage (an agent must visit all locations within each episode) for effective exploration in Atari games."}, {"text_id": "BJlxMu4a37", "sid": 1, "sentence": "This is in contrast of approaches that use inter-life coverage or curiosity metrics to incentivize exploration."}, {"text_id": "BJlxMu4a37", "sid": 2, "sentence": "The paper shows detailed results and analysis on 2 Atari games: Montezuma\u2019s Revenge and Seaquest, and reports results on other games as well."}, {"text_id": "BJlxMu4a37", "sid": 3, "sentence": "Strengths"}, {"text_id": "BJlxMu4a37", "sid": 4, "sentence": "1. Intuitively, the idea of intra-life curiosity is reasonable."}, {"text_id": "BJlxMu4a37", "sid": 5, "sentence": "The paper pursues this idea and provides experimental evidence towards it on 2 Atari games."}, {"text_id": "BJlxMu4a37", "sid": 6, "sentence": "It is able to show compelling improvements on the challenging Montezuma\u2019s Revenge game."}, {"text_id": "BJlxMu4a37", "sid": 7, "sentence": "Weaknesses"}, {"text_id": "BJlxMu4a37", "sid": 8, "sentence": "1. The two primary comparison points are missing:"}, {"text_id": "BJlxMu4a37", "sid": 9, "sentence": "1a. Comparison to other exploration methods."}, {"text_id": "BJlxMu4a37", "sid": 10, "sentence": "A number of methods that use state visitation counts (also referred to as diversity, eg. [A,B]), or prediction error (also referred to as curiosity, eg [C]) have been proposed in recent years."}, {"text_id": "BJlxMu4a37", "sid": 11, "sentence": "It is important to place the contributions in this paper in context of these other works."}, {"text_id": "BJlxMu4a37", "sid": 12, "sentence": "A number of these references are missing and no experimental comparison to these methods has been made."}, {"text_id": "BJlxMu4a37", "sid": 13, "sentence": "1b. Comparison between inter and intra life curiosity."}, {"text_id": "BJlxMu4a37", "sid": 14, "sentence": "One of the central motivation is the utility of intra-life curiosity vs inter-life curiosity, yet no comparisons to this effect have been provided."}, {"text_id": "BJlxMu4a37", "sid": 15, "sentence": "2."}, {"text_id": "BJlxMu4a37", "sid": 16, "sentence": "Additionally, the paper employs a custom way of computing coverage (or diversity)."}, {"text_id": "BJlxMu4a37", "sid": 17, "sentence": "It is in terms of location of agent on the screen, as opposed to featurization of the full game screen as used in prior works."}, {"text_id": "BJlxMu4a37", "sid": 18, "sentence": "It is possible that a large part of the gain comes from the clever design of the space for computing intrinsic exploration reward."}, {"text_id": "BJlxMu4a37", "sid": 19, "sentence": "The paper tries to control for it, however that description is rather short and vague (not clear how the proposed reward is computed without there being a grid, or how is the grid useful without the intrinsic reward)."}, {"text_id": "BJlxMu4a37", "sid": 20, "sentence": "More details should be provided, and when comparisons to past works or inter-life curiosity are made, this should be controlled for."}, {"text_id": "BJlxMu4a37", "sid": 21, "sentence": "The two ideas (use of grids, and intra-life curiosity vs inter-life curiosity) should be independently investigated and put in context of past work."}, {"text_id": "BJlxMu4a37", "sid": 22, "sentence": "3. I will encourage investigation on a more varied set of tasks."}, {"text_id": "BJlxMu4a37", "sid": 23, "sentence": "Perhaps, also using some MuJoCo environments, or 3D navigation environments."}, {"text_id": "BJlxMu4a37", "sid": 24, "sentence": "Table 1 tries to provide some comparisons on Atari, however number of samples is different for different methods making the comparisons invalid."}, {"text_id": "BJlxMu4a37", "sid": 25, "sentence": "Additionally, all of these are still on Atari."}, {"text_id": "BJlxMu4a37", "sid": 26, "sentence": "[A] Diversity is All You Need: Learning Skills without a Reward Function Benjamin Eysenbach, Abhishek Gupta, Julian Ibarz, Sergey Levine"}, {"text_id": "BJlxMu4a37", "sid": 27, "sentence": "[B] EX2: Exploration with Exemplar Models for Deep Reinforcement Learning Justin Fu, John D. Co-Reyes, Sergey Levine"}, {"text_id": "BJlxMu4a37", "sid": 28, "sentence": "[C] Curiosity-driven Exploration by Self-supervised Prediction Deepak Pathak, Pulkit Agrawal, Alexei A. Efros and Trevor Darrell International Conference on Machine Learning (ICML), 2017"}], "reviewlabels": [{"text_id": "BJlxMu4a37", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJlxMu4a37", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJlxMu4a37", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJlxMu4a37", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJlxMu4a37", "sid": 4, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJlxMu4a37", "sid": 5, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJlxMu4a37", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJlxMu4a37", "sid": 7, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJlxMu4a37", "sid": 8, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJlxMu4a37", "sid": 9, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Meaningful Comparison", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJlxMu4a37", "sid": 10, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJlxMu4a37", "sid": 11, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Meaningful Comparison", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJlxMu4a37", "sid": 12, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Meaningful Comparison", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJlxMu4a37", "sid": 13, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJlxMu4a37", "sid": 14, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJlxMu4a37", "sid": 15, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJlxMu4a37", "sid": 16, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJlxMu4a37", "sid": 17, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJlxMu4a37", "sid": 18, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJlxMu4a37", "sid": 19, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJlxMu4a37", "sid": 20, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJlxMu4a37", "sid": 21, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJlxMu4a37", "sid": 22, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJlxMu4a37", "sid": 23, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJlxMu4a37", "sid": 24, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJlxMu4a37", "sid": 25, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJlxMu4a37", "sid": 26, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJlxMu4a37", "sid": 27, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJlxMu4a37", "sid": 28, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "SyeVGit-kE", "sid": 0, "sentence": "Due to the overlap between reviewer comments, we decided to address all concerns in a single response (please see above)."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "SyeVGit-kE", "sid": 0}], "metadata": {"anno": "anno10", "review": "BJlxMu4a37", "rebuttal": "SyeVGit-kE", "conference": "ICLR2019", "title": "Deep Curiosity Search: Intra-Life Exploration Can Improve Performance on Challenging Deep Reinforcement Learning Problems", "reviewer": "AnonReviewer2", "forum_id": "BkeDEoCctQ", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}}