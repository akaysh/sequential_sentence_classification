{"review": [{"text_id": "Hye-Lo29hm", "sid": 0, "sentence": "This paper studies the problem of generating contracts by a principal to incentive agents to optimally accomplish multiagent tasks."}, {"text_id": "Hye-Lo29hm", "sid": 1, "sentence": "The setup of the environment is that the agents have certain skills and preferences for activities, which the principal must learn to act optimally."}, {"text_id": "Hye-Lo29hm", "sid": 2, "sentence": "The paper takes a combined approach of agent modeling to infer agent skills and preferences, and a deep reinforcement learning approach to generate contracts."}, {"text_id": "Hye-Lo29hm", "sid": 3, "sentence": "The evaluation of the approach is fairly thorough."}, {"text_id": "Hye-Lo29hm", "sid": 4, "sentence": "The main novel contribution of the paper is to introduce the principal-agent problem to the deep multiagent reinforcement learning literature."}, {"text_id": "Hye-Lo29hm", "sid": 5, "sentence": "My concerns are:"}, {"text_id": "Hye-Lo29hm", "sid": 6, "sentence": "- The paper should perform a literature search on related work from operations research, including especially principal-agent problems, which are not currently surveyed, and perhaps also optimal scheduling problems."}, {"text_id": "Hye-Lo29hm", "sid": 7, "sentence": "- How do the problems introduced either map onto real applications or map onto environments studied in existing literature (such as in operations research)?"}, {"text_id": "Hye-Lo29hm", "sid": 8, "sentence": "- More details should be given on the mind tracker module."}, {"text_id": "Hye-Lo29hm", "sid": 9, "sentence": "- Is it necessary to use deep reinforcement learning for contract generation?"}, {"text_id": "Hye-Lo29hm", "sid": 10, "sentence": "If the agent modeling is good, the optimal contracts look like they are probably simple to compute directly in the environments studied."}, {"text_id": "Hye-Lo29hm", "sid": 11, "sentence": "Overall, the paper is somewhat interesting and relatively technically sound, but the contribution seems marginal. The problems studied seem pulled out a hat, when they could be situated in specific existing literature."}], "reviewlabels": [{"text_id": "Hye-Lo29hm", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hye-Lo29hm", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hye-Lo29hm", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hye-Lo29hm", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hye-Lo29hm", "sid": 4, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hye-Lo29hm", "sid": 5, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hye-Lo29hm", "sid": 6, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Meaningful Comparison", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hye-Lo29hm", "sid": 7, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Soundness/Correctness", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hye-Lo29hm", "sid": 8, "labels": {"coarse": "Request", "fine": "Request.Edit", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hye-Lo29hm", "sid": 9, "labels": {"coarse": "Request", "fine": "Request.Clarification", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hye-Lo29hm", "sid": 10, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "Hye-Lo29hm", "sid": 11, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "H1lU9Hrf0X", "sid": 0, "sentence": "Thank you for your comments and suggestions."}, {"text_id": "H1lU9Hrf0X", "sid": 1, "sentence": "We respond to your questions and concerns as follows."}, {"text_id": "H1lU9Hrf0X", "sid": 2, "sentence": "1. Connection with principal-agent problems."}, {"text_id": "H1lU9Hrf0X", "sid": 3, "sentence": "Thank you for pointing this out."}, {"text_id": "H1lU9Hrf0X", "sid": 4, "sentence": "We really appreciate it."}, {"text_id": "H1lU9Hrf0X", "sid": 5, "sentence": "The problem we address is indeed closely connected to principal-agent problems, or moral hazard problems in economics, which considers whether the agent makes the best choice for what the principal delegates (e.g., a plumber might make more money by suggesting an overhaul rather than a short-term fix)."}, {"text_id": "H1lU9Hrf0X", "sid": 6, "sentence": "In this setting, there are a lot of issues to be modeled, e.g., information asymmetry between principals and agents, how to setup incentive cost, how to infer agents\u2019 types and how to monitor their behaviors, etc."}, {"text_id": "H1lU9Hrf0X", "sid": 7, "sentence": "Traditional approaches [1] in economics build mathematical models to address these issues separately, leading to complicated models with many tunable parameters."}, {"text_id": "H1lU9Hrf0X", "sid": 8, "sentence": "In comparison, our paper provides a practical end-to-end computational framework to address this problem in a data-driven way, once the agents\u2019 utility function is written down as a combination of principal\u2019s request and its own preference (Eqn. 1)."}, {"text_id": "H1lU9Hrf0X", "sid": 9, "sentence": "Moreover, this framework is adaptive to changes of agents\u2019 preferences and capabilities, which very few papers in economics have addressed."}, {"text_id": "H1lU9Hrf0X", "sid": 10, "sentence": "Because of the connection to principal-agent problems and the data-driven nature of the proposed method, there could be a broad number of practical applications."}, {"text_id": "H1lU9Hrf0X", "sid": 11, "sentence": "We will incorporate a more thorough literature reviews in the next revision."}, {"text_id": "H1lU9Hrf0X", "sid": 12, "sentence": "[1] The theory of incentives: the principal-agent model, Jean-Jacques Laffont, 2001"}, {"text_id": "H1lU9Hrf0X", "sid": 13, "sentence": "2. More details should be given on the mind tracker module."}, {"text_id": "H1lU9Hrf0X", "sid": 14, "sentence": "We will explain more implementation details in the appendix in the next revision."}, {"text_id": "H1lU9Hrf0X", "sid": 15, "sentence": "We will also release the code."}, {"text_id": "H1lU9Hrf0X", "sid": 16, "sentence": "3. Is it necessary to use deep reinforcement learning for contract generation?"}, {"text_id": "H1lU9Hrf0X", "sid": 17, "sentence": "As stated in the introduction, one of the main points of this work is about incomplete information."}, {"text_id": "H1lU9Hrf0X", "sid": 18, "sentence": "I.e., we do not know the true agent models and their mental states, and also do not assume that the task dependency is known."}, {"text_id": "H1lU9Hrf0X", "sid": 19, "sentence": "In real world problems, we indeed can not assume that a manager knows the exact nature of other agents."}, {"text_id": "H1lU9Hrf0X", "sid": 20, "sentence": "So we want to train a manager that can quickly model worker agents through observations and simultaneously generate optimal contracts."}, {"text_id": "H1lU9Hrf0X", "sid": 21, "sentence": "In contrast, traditional methods do not consider task dependency, and usually assume agent types are either known or follow a given distribution."}, {"text_id": "H1lU9Hrf0X", "sid": 22, "sentence": "Also, deep models are flexible enough to handle complicated interactions between agents and changes of settings."}, {"text_id": "H1lU9Hrf0X", "sid": 23, "sentence": "Thus, deep RL is a more suitable approach than traditional methods under the incomplete information setting."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "H1lU9Hrf0X", "sid": 0}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "H1lU9Hrf0X", "sid": 1}, {"labels": {"alignments": [6], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "H1lU9Hrf0X", "sid": 2}, {"labels": {"alignments": [6], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "H1lU9Hrf0X", "sid": 3}, {"labels": {"alignments": [6], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "H1lU9Hrf0X", "sid": 4}, {"labels": {"alignments": [6], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1lU9Hrf0X", "sid": 5}, {"labels": {"alignments": [6], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1lU9Hrf0X", "sid": 6}, {"labels": {"alignments": [6], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1lU9Hrf0X", "sid": 7}, {"labels": {"alignments": [6], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1lU9Hrf0X", "sid": 8}, {"labels": {"alignments": [6], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1lU9Hrf0X", "sid": 9}, {"labels": {"alignments": [6], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1lU9Hrf0X", "sid": 10}, {"labels": {"alignments": [6], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "H1lU9Hrf0X", "sid": 11}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "H1lU9Hrf0X", "sid": 12}, {"labels": {"alignments": [8], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "H1lU9Hrf0X", "sid": 13}, {"labels": {"alignments": [8], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "H1lU9Hrf0X", "sid": 14}, {"labels": {"alignments": [8], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "H1lU9Hrf0X", "sid": 15}, {"labels": {"alignments": [9], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "H1lU9Hrf0X", "sid": 16}, {"labels": {"alignments": [9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1lU9Hrf0X", "sid": 17}, {"labels": {"alignments": [9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1lU9Hrf0X", "sid": 18}, {"labels": {"alignments": [9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1lU9Hrf0X", "sid": 19}, {"labels": {"alignments": [9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1lU9Hrf0X", "sid": 20}, {"labels": {"alignments": [9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1lU9Hrf0X", "sid": 21}, {"labels": {"alignments": [9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1lU9Hrf0X", "sid": 22}, {"labels": {"alignments": [9], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "H1lU9Hrf0X", "sid": 23}], "metadata": {"anno": "anno2", "review": "Hye-Lo29hm", "rebuttal": "H1lU9Hrf0X", "conference": "ICLR2019", "title": "M^3RL: Mind-aware Multi-agent Management Reinforcement Learning", "reviewer": "AnonReviewer2", "forum_id": "BkzeUiRcY7", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}}