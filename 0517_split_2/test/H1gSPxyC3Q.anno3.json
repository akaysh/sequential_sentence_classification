{"review": [{"text_id": "H1gSPxyC3Q", "sid": 0, "sentence": "This paper introduces policy gradient methods for RL where the policy must choose a direction (a.k.a., the navigation problem)."}, {"text_id": "H1gSPxyC3Q", "sid": 1, "sentence": "Mapping techniques from \"non-directional\" problems (where the action space is not a direction) and then projeting on the sphere is sub-optimal (the variance is too big)."}, {"text_id": "H1gSPxyC3Q", "sid": 2, "sentence": "The authors propose to sample directly on the sphere, using the fact that the likelyhood of an angular Gaussian r.v. has *almost* a closed form and its gradient can almost be computed, up to some normalization term (the integral which is constant in the standard Gaussian case)."}, {"text_id": "H1gSPxyC3Q", "sid": 3, "sentence": "This can be seen as a variance reduction techniques."}, {"text_id": "H1gSPxyC3Q", "sid": 4, "sentence": "The proofs are not too intricate, for someone used to variance reduction (yet computations must be made quite carefully)."}, {"text_id": "H1gSPxyC3Q", "sid": 5, "sentence": "The result is coherent, interesting from a theoretical point of view and the experiment are somehow convincing."}, {"text_id": "H1gSPxyC3Q", "sid": 6, "sentence": "The main drawback would be the rather incrementality of that paper (basically sample before projecting is a bit better than projecting after sampling) and that this directional setting is quite limited..."}], "reviewlabels": [{"text_id": "H1gSPxyC3Q", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1gSPxyC3Q", "sid": 1, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1gSPxyC3Q", "sid": 2, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1gSPxyC3Q", "sid": 3, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1gSPxyC3Q", "sid": 4, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1gSPxyC3Q", "sid": 5, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "H1gSPxyC3Q", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Replicability", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "SJlQqs8spQ", "sid": 0, "sentence": "Thank you for the time and effort spent reviewing our paper."}, {"text_id": "SJlQqs8spQ", "sid": 1, "sentence": "We mostly agree with your characterization of our work, but we think there are two important points we perhaps did not sufficiently emphasize in our paper and that we would like to mention:"}, {"text_id": "SJlQqs8spQ", "sid": 2, "sentence": "(1) There are other existing tasks and algorithms that fall into the marginal policy gradients framework."}, {"text_id": "SJlQqs8spQ", "sid": 3, "sentence": "For example, researchers and practitioners both almost always clip actions when using policy gradient algorithms for robotics control environments (read: MuJoCo tasks)."}, {"text_id": "SJlQqs8spQ", "sid": 4, "sentence": "Recently, a reduced variance method was introduced by Fujita and Maeda (2018) for clipped action spaces."}, {"text_id": "SJlQqs8spQ", "sid": 5, "sentence": "Their algorithm is also a member of the marginal policy gradients family and our theoretical results for MPG significantly tighten the existing analysis of their algorithm."}, {"text_id": "SJlQqs8spQ", "sid": 6, "sentence": "(2) To the best of our knowledge, our work is the first to apply such variance reduction techniques to RL."}, {"text_id": "SJlQqs8spQ", "sid": 7, "sentence": "To summarize, our work consists of two components: (a) a new algorithm for directional control and (b) a variance reduction framework that can be applied to directional action space and clipped action spaces."}, {"text_id": "SJlQqs8spQ", "sid": 8, "sentence": "While directional action spaces are not very common at this time, clipped action spaces are extremely common."}, {"text_id": "SJlQqs8spQ", "sid": 9, "sentence": "We also anticipate that in the future, many additional environments will be available that feature directional actions (many console or PC games, for example)."}, {"text_id": "SJlQqs8spQ", "sid": 10, "sentence": "For these reasons, we feel that our work is not incremental at all, and is actually quite novel."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "SJlQqs8spQ", "sid": 0}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SJlQqs8spQ", "sid": 1}, {"labels": {"alignments": [], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlQqs8spQ", "sid": 2}, {"labels": {"alignments": [], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlQqs8spQ", "sid": 3}, {"labels": {"alignments": [], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlQqs8spQ", "sid": 4}, {"labels": {"alignments": [], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SJlQqs8spQ", "sid": 5}, {"labels": {"alignments": [6], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "SJlQqs8spQ", "sid": 6}, {"labels": {"alignments": [], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "SJlQqs8spQ", "sid": 7}, {"labels": {"alignments": [], "responsetype": "summary", "coarseresponse": "nonarg"}, "text_id": "SJlQqs8spQ", "sid": 8}, {"labels": {"alignments": [], "responsetype": "future", "coarseresponse": "concur"}, "text_id": "SJlQqs8spQ", "sid": 9}, {"labels": {"alignments": [6], "responsetype": "reject-criticism", "coarseresponse": "dispute"}, "text_id": "SJlQqs8spQ", "sid": 10}], "metadata": {"anno": "anno3", "review": "H1gSPxyC3Q", "rebuttal": "SJlQqs8spQ", "conference": "ICLR2019", "title": "Marginal Policy Gradients: A Unified Family of Estimators for Bounded Action Spaces with Applications", "reviewer": "AnonReviewer2", "forum_id": "HkgqFiAcFm", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}}