{"review": [{"text_id": "rJeb2tXkqB", "sid": 0, "sentence": "The paper presents a new attack, called the shadow attack, that can maintain the imperceptibility of adversarial samples when out of the certified radius."}, {"text_id": "rJeb2tXkqB", "sid": 1, "sentence": "This work not only aims to target the classifier label but also the certificate by adding large perturbations to the image."}, {"text_id": "rJeb2tXkqB", "sid": 2, "sentence": "The attacks produce a 'spoofed' certificate, so though these certified systems are meant to be secure, can be attacked."}, {"text_id": "rJeb2tXkqB", "sid": 3, "sentence": "Theirs seem to be the first work focusing on manipulating certificates to attack strongly certified networks."}, {"text_id": "rJeb2tXkqB", "sid": 4, "sentence": "The paper presents shadow attack, that is a generalization of the PGD attack."}, {"text_id": "rJeb2tXkqB", "sid": 5, "sentence": "It involves creation of adversarial examples, and addition of few constraints that forces these perturbations to be small, smooth and not many color variations."}, {"text_id": "rJeb2tXkqB", "sid": 6, "sentence": "For certificate spoofing the authors explore different spoofing losses for l-2(attacks on randomized smoothing) and l-inf(attacks on crown-ibp) norm bounded attacks."}, {"text_id": "rJeb2tXkqB", "sid": 7, "sentence": "Strengths: The paper is well written and well motivated."}, {"text_id": "rJeb2tXkqB", "sid": 8, "sentence": "The work is novel since most of the current work focus on the imperceptibility and misclassification aspects of the classifier, but this work addresses attacking the strongly certified networks."}, {"text_id": "rJeb2tXkqB", "sid": 9, "sentence": "Weakness: It would be good to see some comparison to the state of the art"}], "reviewlabels": [{"text_id": "rJeb2tXkqB", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJeb2tXkqB", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJeb2tXkqB", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJeb2tXkqB", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJeb2tXkqB", "sid": 4, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJeb2tXkqB", "sid": 5, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJeb2tXkqB", "sid": 6, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJeb2tXkqB", "sid": 7, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Motivation/Impact", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJeb2tXkqB", "sid": 8, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "rJeb2tXkqB", "sid": 9, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Meaningful Comparison", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "r1lSZ9qnir", "sid": 0, "sentence": "Thank you for the encouraging review."}, {"text_id": "r1lSZ9qnir", "sid": 1, "sentence": "[R3: Weakness: It would be good to see some comparison to the state of the art ]"}, {"text_id": "r1lSZ9qnir", "sid": 2, "sentence": "With regards to your comment on attacking the current state of the art method for smoothed classifiers, we have added new results to the resubmission (Appendix B), in which we attack the adversarially trained smooth classifier [1]."}, {"text_id": "r1lSZ9qnir", "sid": 3, "sentence": "[1]. Salman et al., \u201cProvably Robust Deep Learning via Adversarially Trained Smoothed Classifiers\u201d, NeurIPS 2019"}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "r1lSZ9qnir", "sid": 0}, {"labels": {"alignments": [9], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "r1lSZ9qnir", "sid": 1}, {"labels": {"alignments": [9], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "r1lSZ9qnir", "sid": 2}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "r1lSZ9qnir", "sid": 3}], "metadata": {"anno": "anno3", "review": "rJeb2tXkqB", "rebuttal": "r1lSZ9qnir", "conference": "ICLR2020", "title": "BREAKING  CERTIFIED  DEFENSES:  SEMANTIC  ADVERSARIAL  EXAMPLES  WITH  SPOOFED  ROBUSTNESS  CERTIFICATES", "reviewer": "AnonReviewer3", "forum_id": "HJxdTxHYvB", "rating": "8: Accept", "experience_assessment": "I do not know much about this area."}}