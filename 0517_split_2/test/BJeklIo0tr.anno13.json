{"review": [{"text_id": "BJeklIo0tr", "sid": 0, "sentence": "The paper proposes a new joint learning algorithm that works for two tasks, NER and RE."}, {"text_id": "BJeklIo0tr", "sid": 1, "sentence": "The model is based on a pre-trained BERT model, which provides the word vectors of the input word sequence."}, {"text_id": "BJeklIo0tr", "sid": 2, "sentence": "Then it solves two tasks with two network branches: the first branch minimizes the loss for NER, and the second branch minimizes the loss for RE."}, {"text_id": "BJeklIo0tr", "sid": 3, "sentence": "The second branch uses entity labels predicted by the first branch, so joint learning may benefit both tasks."}, {"text_id": "BJeklIo0tr", "sid": 4, "sentence": "The design of the architecture is novel, but it is also not groundbreaking."}, {"text_id": "BJeklIo0tr", "sid": 5, "sentence": "Each network branch is from known structures, but the combination is not proposed before."}, {"text_id": "BJeklIo0tr", "sid": 6, "sentence": "The submission has evaluated the proposed algorithms on four datasets and improved SOTA performances."}, {"text_id": "BJeklIo0tr", "sid": 7, "sentence": "The ablation study justifies the design details."}, {"text_id": "BJeklIo0tr", "sid": 8, "sentence": "The writing is generally clear."}, {"text_id": "BJeklIo0tr", "sid": 9, "sentence": "Now critics:"}, {"text_id": "BJeklIo0tr", "sid": 10, "sentence": "Ablation study:"}, {"text_id": "BJeklIo0tr", "sid": 11, "sentence": "1. As pointed by one public comment, the ablation study should show how much improvement is from BERT vectors."}, {"text_id": "BJeklIo0tr", "sid": 12, "sentence": "2. I'd like to see another ablation study of whether RE helps NER. If you remove the RE component, does the NER performance suffer?"}, {"text_id": "BJeklIo0tr", "sid": 13, "sentence": "Writing:"}, {"text_id": "BJeklIo0tr", "sid": 14, "sentence": "3. how are predicted labels embedded? Do you learn a vector of each tag of BIOES and then take a weighted sum of these vectors with predicted probabilities as weights?"}], "reviewlabels": [{"text_id": "BJeklIo0tr", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeklIo0tr", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeklIo0tr", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeklIo0tr", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeklIo0tr", "sid": 4, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeklIo0tr", "sid": 5, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Originality", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeklIo0tr", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeklIo0tr", "sid": 7, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeklIo0tr", "sid": 8, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeklIo0tr", "sid": 9, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeklIo0tr", "sid": 10, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeklIo0tr", "sid": 11, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeklIo0tr", "sid": 12, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeklIo0tr", "sid": 13, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "BJeklIo0tr", "sid": 14, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Substance", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "SyeYlggviB", "sid": 0, "sentence": "Hello,"}, {"text_id": "SyeYlggviB", "sid": 1, "sentence": "Thank you for your review of our paper."}, {"text_id": "SyeYlggviB", "sid": 2, "sentence": "We appreciate the positive assessment of the clarity of our writing."}, {"text_id": "SyeYlggviB", "sid": 3, "sentence": "Regarding the suggested ablations,"}, {"text_id": "SyeYlggviB", "sid": 4, "sentence": "1. For reasons outlined in our response to the public comment you reference, we do not believe this ablation (as suggested) would be meaningful."}, {"text_id": "SyeYlggviB", "sid": 5, "sentence": "For convenience, we have copied that response here: In our model, BERT is more than a source of contextual word embeddings as we fine-tune all of its ~110M parameters during training."}, {"text_id": "SyeYlggviB", "sid": 6, "sentence": "Simply replacing BERT with distributed embeddings and a character-CNN or LSTM wouldn\u2019t allow us to determine the effect of contextualized embeddings because we would simultaneously be removing the majority of our model\u2019s trainable parameters."}, {"text_id": "SyeYlggviB", "sid": 7, "sentence": "Nevertheless, we performed the suggested ablation by swapping BERT for GloVe embeddings (300 dimensional) and found that NER performance dropped from 89.46% to 40.33% and RE performance fell from 66.83% to 14.44% on the test set of the ConLL04 corpus (note that we had to increase the learning rate by 10X to get the model to converge)."}, {"text_id": "SyeYlggviB", "sid": 8, "sentence": "If you were to somehow control for this drop in model capacity, say by adding in an LSTM network, the ablated model would closely match this paper [1], whom we outperform by ~3% overall on the CoNLL04 corpus."}, {"text_id": "SyeYlggviB", "sid": 9, "sentence": "This paper is not cited in Table 1 as they report macro-averaged F1 scores, while most other papers (including the current state-of-the-art [2]) report micro-averaged F1 scores, as we did."}, {"text_id": "SyeYlggviB", "sid": 10, "sentence": "Finally, it is well known that contextual embeddings outperform distributed embeddings on a wide range of NLP tasks, including NER [3]."}, {"text_id": "SyeYlggviB", "sid": 11, "sentence": "The aim of our study wasn\u2019t to compare contextual vs. distributed embeddings but on how to successfully integrate BERT into a state-of-the-art joint NER and RE architecture."}, {"text_id": "SyeYlggviB", "sid": 12, "sentence": "2. Thank you for this suggestion."}, {"text_id": "SyeYlggviB", "sid": 13, "sentence": "We are currently performing the ablation, and will comment again once we have the results."}, {"text_id": "SyeYlggviB", "sid": 14, "sentence": "We will be performing the same ablation as used in [2] (see section 6.2)."}, {"text_id": "SyeYlggviB", "sid": 15, "sentence": "Just note, because our manuscript is already at the page limit, we may have to place the results of this ablation in the appendix."}, {"text_id": "SyeYlggviB", "sid": 16, "sentence": "Regarding predicted entity label embeddings,"}, {"text_id": "SyeYlggviB", "sid": 17, "sentence": "Before training, all unique entity labels (e.g. B-PER, I-PER, ... etc.) are embedded by assigning them to randomly initialized, continuous vectors of 128 dimensions (this hyperparam is mentioned in Table A.2 of the appendix)."}, {"text_id": "SyeYlggviB", "sid": 18, "sentence": "The embeddings are then updated along with the rest of the models' parameters during training."}, {"text_id": "SyeYlggviB", "sid": 19, "sentence": "Practically speaking, this is handled for us via the embedding layer in PyTorch [4]."}, {"text_id": "SyeYlggviB", "sid": 20, "sentence": "This is the same method used in the works we compare to ([1], [5], [6])."}, {"text_id": "SyeYlggviB", "sid": 21, "sentence": "We have updated the text in the manuscript (under section 2) to make this more clear."}, {"text_id": "SyeYlggviB", "sid": 22, "sentence": "Thank you again for taking the time to review our paper."}, {"text_id": "SyeYlggviB", "sid": 23, "sentence": "[1] https://link.springer.com/chapter/10.1007/978-3-030-15712-8_47"}, {"text_id": "SyeYlggviB", "sid": 24, "sentence": "[2] https://arxiv.org/abs/1905.05529"}, {"text_id": "SyeYlggviB", "sid": 25, "sentence": "[3] https://arxiv.org/abs/1802.05365"}, {"text_id": "SyeYlggviB", "sid": 26, "sentence": "[4] https://pytorch.org/docs/stable/nn.html#embedding"}, {"text_id": "SyeYlggviB", "sid": 27, "sentence": "[5] https://www.aclweb.org/anthology/P16-1105/"}, {"text_id": "SyeYlggviB", "sid": 28, "sentence": "[6] https://www.sciencedirect.com/science/article/pii/S095741741830455X"}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "SyeYlggviB", "sid": 0}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "SyeYlggviB", "sid": 1}, {"labels": {"alignments": [8], "responsetype": "accept-praise", "coarseresponse": "concur"}, "text_id": "SyeYlggviB", "sid": 2}, {"labels": {"alignments": [10, 11, 12], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SyeYlggviB", "sid": 3}, {"labels": {"alignments": [10, 11, 12], "responsetype": "reject-request_scope_Yes", "coarseresponse": "dispute"}, "text_id": "SyeYlggviB", "sid": 4}, {"labels": {"alignments": [10, 11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyeYlggviB", "sid": 5}, {"labels": {"alignments": [10, 11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyeYlggviB", "sid": 6}, {"labels": {"alignments": [10, 11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyeYlggviB", "sid": 7}, {"labels": {"alignments": [10, 11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyeYlggviB", "sid": 8}, {"labels": {"alignments": [10, 11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyeYlggviB", "sid": 9}, {"labels": {"alignments": [10, 11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyeYlggviB", "sid": 10}, {"labels": {"alignments": [10, 11, 12], "responsetype": "reject-request_scope_Yes", "coarseresponse": "dispute"}, "text_id": "SyeYlggviB", "sid": 11}, {"labels": {"alignments": [12], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SyeYlggviB", "sid": 12}, {"labels": {"alignments": [12], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "SyeYlggviB", "sid": 13}, {"labels": {"alignments": [12], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "SyeYlggviB", "sid": 14}, {"labels": {"alignments": [12], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "SyeYlggviB", "sid": 15}, {"labels": {"alignments": [14], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "SyeYlggviB", "sid": 16}, {"labels": {"alignments": [14], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyeYlggviB", "sid": 17}, {"labels": {"alignments": [14], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyeYlggviB", "sid": 18}, {"labels": {"alignments": [14], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyeYlggviB", "sid": 19}, {"labels": {"alignments": [14], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "SyeYlggviB", "sid": 20}, {"labels": {"alignments": [14], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "SyeYlggviB", "sid": 21}, {"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "SyeYlggviB", "sid": 22}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "SyeYlggviB", "sid": 23}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "SyeYlggviB", "sid": 24}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "SyeYlggviB", "sid": 25}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "SyeYlggviB", "sid": 26}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "SyeYlggviB", "sid": 27}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "SyeYlggviB", "sid": 28}], "metadata": {"anno": "anno13", "review": "BJeklIo0tr", "rebuttal": "SyeYlggviB", "conference": "ICLR2020", "title": "End-to-end named entity recognition and relation extraction using pre-trained language models", "reviewer": "AnonReviewer2", "forum_id": "rkgqm0VKwB", "rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area."}}