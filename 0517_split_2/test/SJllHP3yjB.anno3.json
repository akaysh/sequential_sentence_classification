{"review": [{"text_id": "SJllHP3yjB", "sid": 0, "sentence": "The paper presents a new attack: Shadow Attack, which can generate imperceptible adversarial samples."}, {"text_id": "SJllHP3yjB", "sid": 1, "sentence": "This method is based on adding regularization on total variation, color change in each channel and similar perturbation in each channel."}, {"text_id": "SJllHP3yjB", "sid": 2, "sentence": "This method is easy to follow and a lot of examples of different experiments are shown."}, {"text_id": "SJllHP3yjB", "sid": 3, "sentence": "However, I have several questions about motivation and method."}, {"text_id": "SJllHP3yjB", "sid": 4, "sentence": "First, the proposed attack method can yield adversarial perturbations to images that are large in the \\ell_p norm."}, {"text_id": "SJllHP3yjB", "sid": 5, "sentence": "Therefore, the authors claim that the method can attack certified systems."}, {"text_id": "SJllHP3yjB", "sid": 6, "sentence": "However, attack in Wasserstein distance and some other methods can also do so."}, {"text_id": "SJllHP3yjB", "sid": 7, "sentence": "They can generate adversarial examples whose \\ell_p norm is large."}, {"text_id": "SJllHP3yjB", "sid": 8, "sentence": "I think the author should have some discussions about these related methods."}, {"text_id": "SJllHP3yjB", "sid": 9, "sentence": "Second, I notice that compared to the result in Table 1, PGD attack can yield better results [1]."}, {"text_id": "SJllHP3yjB", "sid": 10, "sentence": "I hope to see some discussions about this."}, {"text_id": "SJllHP3yjB", "sid": 11, "sentence": "Also, Table 1 is really confused. I would not understand the meaning if I am not familiar with the experiment settings."}, {"text_id": "SJllHP3yjB", "sid": 12, "sentence": "[1] Salman, Hadi, et al. \"Provably Robust Deep Learning via Adversarially Trained Smoothed Classifiers.\" Neuips (2019)."}], "reviewlabels": [{"text_id": "SJllHP3yjB", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJllHP3yjB", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJllHP3yjB", "sid": 2, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJllHP3yjB", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJllHP3yjB", "sid": 4, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJllHP3yjB", "sid": 5, "labels": {"coarse": "Fact", "fine": "Fact", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJllHP3yjB", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Meaningful Comparison", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "SJllHP3yjB", "sid": 7, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Meaningful Comparison", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "SJllHP3yjB", "sid": 8, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Meaningful Comparison", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJllHP3yjB", "sid": 9, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "SJllHP3yjB", "sid": 10, "labels": {"coarse": "Request", "fine": "Request.Experiment", "asp": "Substance", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": true}, {"text_id": "SJllHP3yjB", "sid": 11, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Clarity", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "SJllHP3yjB", "sid": 12, "labels": {"coarse": "Other", "fine": "Other", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "rJe2nF5nsB", "sid": 0, "sentence": "Thanks for your constructive feedback."}, {"text_id": "rJe2nF5nsB", "sid": 1, "sentence": "We have modified the paper to include some of the experiments you have suggested."}, {"text_id": "rJe2nF5nsB", "sid": 2, "sentence": "Please find our detailed response below:"}, {"text_id": "rJe2nF5nsB", "sid": 3, "sentence": "[R4: First, the proposed attack method can yield adversarial perturbations to images that are large in the \\ell_p norm."}, {"text_id": "rJe2nF5nsB", "sid": 4, "sentence": "Therefore, the authors claim that the method can attack certified systems."}, {"text_id": "rJe2nF5nsB", "sid": 5, "sentence": "However, attack in Wasserstein distance and some other methods can also do so."}, {"text_id": "rJe2nF5nsB", "sid": 6, "sentence": "They can generate adversarial examples whose \\ell_p norm is large."}, {"text_id": "rJe2nF5nsB", "sid": 7, "sentence": "I think the author should have some discussions about these related methods.]"}, {"text_id": "rJe2nF5nsB", "sid": 8, "sentence": "Thank you for pointing us out to the missing related work which we have included in the revision."}, {"text_id": "rJe2nF5nsB", "sid": 9, "sentence": "Indeed, the Wasserstein attack and the other previously mentioned non-$\\ell_p$ bounded attacks are alternatives for producing quasi-imperceptible non-$\\ell_p$ bounded adversarial examples."}, {"text_id": "rJe2nF5nsB", "sid": 10, "sentence": "Any of these methods can alternatively be used for generating non $\\ell_p$ bounded attacks."}, {"text_id": "rJe2nF5nsB", "sid": 11, "sentence": "However, one major advantage of our attack method over the Wasserstein attack may be its simplicity and scalability."}, {"text_id": "rJe2nF5nsB", "sid": 12, "sentence": "Per your suggestion, we ran experiments using the Wasserstein attack."}, {"text_id": "rJe2nF5nsB", "sid": 13, "sentence": "The authors of [1] suggest that the Wasserstein PGD attack works best when the attacker takes PGD steps in $ell_p$-norm directions and then project the noise back onto the Wasserstein ball."}, {"text_id": "rJe2nF5nsB", "sid": 14, "sentence": "We used their official implementation and adapted it to attack the Randomized Smoothed classifier."}, {"text_id": "rJe2nF5nsB", "sid": 15, "sentence": "Based on the official implementation, after every 10 iterations, if the attack is not successful, we increase the radius of the wasserstein ball in which the noise is projected back onto."}, {"text_id": "rJe2nF5nsB", "sid": 16, "sentence": "Consequently, the attack is always able to reach a comparable, but slightly weaker, spoofed certified radii (~ 67% that of the shadow attack) at the cost of slightly more perceptible adversarial noise in difficult cases."}, {"text_id": "rJe2nF5nsB", "sid": 17, "sentence": "Note that the reason that the examples are more perceptible than those from [1] is that they are made to produce large certified radii and not only cause misclassification (i.e., the entire Gaussian augmented batch needs to get misclassified.) A comparison of the resulting images and average certified radii of those images can be found in the following anonymized link:"}, {"text_id": "rJe2nF5nsB", "sid": 18, "sentence": "https://docs.google.com/spreadsheets/d/1F0P8aOD_5aiVjW3CrR49fudz4EgrORz7v4t0ZIJEBAo/edit?usp=sharing."}, {"text_id": "rJe2nF5nsB", "sid": 19, "sentence": "[1] Wong et al., \u201cWasserstein Adversarial Examples via Projected Sinkhorn Iterations\u201d."}, {"text_id": "rJe2nF5nsB", "sid": 20, "sentence": "[R4: Second, I notice that compared to the result in Table 1, PGD attack can yield better results [1]."}, {"text_id": "rJe2nF5nsB", "sid": 21, "sentence": "I hope to see some discussions about this. Also, Table 1 is really confused. I would not understand the meaning if I am not familiar with the experiment settings.]"}, {"text_id": "rJe2nF5nsB", "sid": 22, "sentence": "Per your request, we have attacked the work of [2] and reported results of attacking the pre-trained SmoothAdv classifiers (available in [3]) in Appendix B."}, {"text_id": "rJe2nF5nsB", "sid": 23, "sentence": "Similar to the non-adversarially trained smooth classifier included in the original submission, we can produce adversarial examples for the SmoothAdv classifier which on average produce larger certified radii than their natural example counterpart."}, {"text_id": "rJe2nF5nsB", "sid": 24, "sentence": "Also, in the revised document, we have expanded the caption of Table 1 to make sure that it is clear what a certified is and that a larger radii is better."}, {"text_id": "rJe2nF5nsB", "sid": 25, "sentence": "[2]. Salman et al., \u201cProvably Robust Deep Learning via Adversarially Trained Smoothed Classifiers\u201d, NeurIPS 2019"}, {"text_id": "rJe2nF5nsB", "sid": 26, "sentence": "[3]. https://github.com/Hadisalman/smoothing-adversarial"}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "rJe2nF5nsB", "sid": 0}, {"labels": {"alignments": [], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "rJe2nF5nsB", "sid": 1}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJe2nF5nsB", "sid": 2}, {"labels": {"alignments": [5, 6, 7], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJe2nF5nsB", "sid": 3}, {"labels": {"alignments": [5, 6, 7], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJe2nF5nsB", "sid": 4}, {"labels": {"alignments": [5, 6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJe2nF5nsB", "sid": 5}, {"labels": {"alignments": [5, 6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJe2nF5nsB", "sid": 6}, {"labels": {"alignments": [5, 6, 7], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJe2nF5nsB", "sid": 7}, {"labels": {"alignments": [8], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "rJe2nF5nsB", "sid": 8}, {"labels": {"alignments": [5, 6, 7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJe2nF5nsB", "sid": 9}, {"labels": {"alignments": [5, 6, 7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJe2nF5nsB", "sid": 10}, {"labels": {"alignments": [5, 6, 7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJe2nF5nsB", "sid": 11}, {"labels": {"alignments": [5, 6, 7, 8], "responsetype": "done_manu_No", "coarseresponse": "concur"}, "text_id": "rJe2nF5nsB", "sid": 12}, {"labels": {"alignments": [5, 6, 7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJe2nF5nsB", "sid": 13}, {"labels": {"alignments": [5, 6, 7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJe2nF5nsB", "sid": 14}, {"labels": {"alignments": [5, 6, 7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJe2nF5nsB", "sid": 15}, {"labels": {"alignments": [5, 6, 7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJe2nF5nsB", "sid": 16}, {"labels": {"alignments": [5, 6, 7, 8], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJe2nF5nsB", "sid": 17}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "rJe2nF5nsB", "sid": 18}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "rJe2nF5nsB", "sid": 19}, {"labels": {"alignments": [9], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJe2nF5nsB", "sid": 20}, {"labels": {"alignments": [10, 11], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJe2nF5nsB", "sid": 21}, {"labels": {"alignments": [9, 10, 11], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "rJe2nF5nsB", "sid": 22}, {"labels": {"alignments": [9, 10, 11], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJe2nF5nsB", "sid": 23}, {"labels": {"alignments": [9, 10, 11], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJe2nF5nsB", "sid": 24}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "rJe2nF5nsB", "sid": 25}, {"labels": {"alignments": [], "responsetype": "other", "coarseresponse": "nonarg"}, "text_id": "rJe2nF5nsB", "sid": 26}], "metadata": {"anno": "anno3", "review": "SJllHP3yjB", "rebuttal": "rJe2nF5nsB", "conference": "ICLR2020", "title": "BREAKING  CERTIFIED  DEFENSES:  SEMANTIC  ADVERSARIAL  EXAMPLES  WITH  SPOOFED  ROBUSTNESS  CERTIFICATES", "reviewer": "AnonReviewer4", "forum_id": "HJxdTxHYvB", "rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area."}}