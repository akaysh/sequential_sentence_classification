{"review": [{"text_id": "HkgbGMxEnm", "sid": 0, "sentence": "This paper studies the problem of coordinating many strategic agents with private valuation to perform a series of common goals."}, {"text_id": "HkgbGMxEnm", "sid": 1, "sentence": "The algorithm designer is a manager who can assign goals to various agents but cannot see their valuation or control them explicitly."}, {"text_id": "HkgbGMxEnm", "sid": 2, "sentence": "The manager has a utility function for various goals and wants to maximize the total revenue."}, {"text_id": "HkgbGMxEnm", "sid": 3, "sentence": "The abstract problem is well-motivated and significant and is an entire branch of study called algorithmic mechanism design."}, {"text_id": "HkgbGMxEnm", "sid": 4, "sentence": "However often many assumptions have to be made to make the problem mathematically tractable."}, {"text_id": "HkgbGMxEnm", "sid": 5, "sentence": "In this paper, the authors take an empirical approach by designing an RL framework that efficiently maximizes rewards across many episodes."}, {"text_id": "HkgbGMxEnm", "sid": 6, "sentence": "Overall I find the problem interesting, well-motivated."}, {"text_id": "HkgbGMxEnm", "sid": 7, "sentence": "The paper is well-written and contains significant experiments to support its point."}, {"text_id": "HkgbGMxEnm", "sid": 8, "sentence": "However, I do not have the necessary background in the related literature to assess the significance of the methods proposed compared to prior work and thus would refrain from making a judgment on the novelty of this paper in terms of methodology."}, {"text_id": "HkgbGMxEnm", "sid": 9, "sentence": "Here are some of my comments/questions to the author on this paper."}, {"text_id": "HkgbGMxEnm", "sid": 10, "sentence": "(1) I want to clarify how the skills of the agents play a role in the problem setup. Does it show up in the expression for the manager's reward?"}, {"text_id": "HkgbGMxEnm", "sid": 11, "sentence": "In particular, does it affect the Indicator for whether a goal is completed Eq. (2) via a process that need not be explicitly modeled but can be observed via a feedback of whether or not the goal is completed?"}, {"text_id": "HkgbGMxEnm", "sid": 12, "sentence": "So in the case of resource collection example, the skill set is a binary value for each resource, whether it can be collected or not?"}, {"text_id": "HkgbGMxEnm", "sid": 13, "sentence": "(2) Related to the first point, the motivation for modeling the agents as maximizing their utility is the assumption that agents do not know their skills. I am wondering, is this really justified? Over the course of episodes, can the agents learn their skills based on the relationship between their intention and the goals they achieve? In the resource collection example, when they reach a resource and are not able to collect it, they understand that they do not have the corresponding skill."}, {"text_id": "HkgbGMxEnm", "sid": 14, "sentence": "Is there a way to extrapolate the results from this paper to such a setting?"}, {"text_id": "HkgbGMxEnm", "sid": 15, "sentence": "(3) I am slightly concerned about the sample complexity of keeping track of the probability of worker i finishing goal g within t steps with a bonus b. This scales linearly in parameters which usually would be large (such as the number of time-steps)."}, {"text_id": "HkgbGMxEnm", "sid": 16, "sentence": "Are there alternate ways to overcome maintaining the UCB explicitly, especially for the number of time-steps?"}, {"text_id": "HkgbGMxEnm", "sid": 17, "sentence": "Some minor comments on the presentation."}, {"text_id": "HkgbGMxEnm", "sid": 18, "sentence": "(1) What are the units for rewards in the plots? Is it the average per episode reward? It would be good to mention this in the caption."}, {"text_id": "HkgbGMxEnm", "sid": 19, "sentence": "(2) There are a few typos in the paper."}, {"text_id": "HkgbGMxEnm", "sid": 20, "sentence": "Some I could catch was,"}, {"text_id": "HkgbGMxEnm", "sid": 21, "sentence": "- Last line in Page 5: \"quantitative\" -> \"quantity\""}, {"text_id": "HkgbGMxEnm", "sid": 22, "sentence": "- Page 8: skills nad preferences -> skills and preferences"}, {"text_id": "HkgbGMxEnm", "sid": 23, "sentence": "- Page 8: For which we combining -> for which we combine"}], "reviewlabels": [{"text_id": "HkgbGMxEnm", "sid": 0, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgbGMxEnm", "sid": 1, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgbGMxEnm", "sid": 2, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgbGMxEnm", "sid": 3, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgbGMxEnm", "sid": 4, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgbGMxEnm", "sid": 5, "labels": {"coarse": "Structuring", "fine": "Structuring.Summary", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgbGMxEnm", "sid": 6, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Motivation/Impact", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgbGMxEnm", "sid": 7, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Substance", "pol": "P-Positive"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgbGMxEnm", "sid": 8, "labels": {"coarse": "Social", "fine": "Social", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgbGMxEnm", "sid": 9, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgbGMxEnm", "sid": 10, "labels": {"coarse": "Request", "fine": "Request.Clarification", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgbGMxEnm", "sid": 11, "labels": {"coarse": "Request", "fine": "Request.Clarification", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgbGMxEnm", "sid": 12, "labels": {"coarse": "Request", "fine": "Request.Clarification", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgbGMxEnm", "sid": 13, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Soundness/Correctness", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgbGMxEnm", "sid": 14, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Soundness/Correctness", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgbGMxEnm", "sid": 15, "labels": {"coarse": "Evaluative", "fine": "Evaluative", "asp": "Soundness/Correctness", "pol": "N-Negative"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgbGMxEnm", "sid": 16, "labels": {"coarse": "Request", "fine": "Request.Explanation", "asp": "Soundness/Correctness", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgbGMxEnm", "sid": 17, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgbGMxEnm", "sid": 18, "labels": {"coarse": "Request", "fine": "Request.Clarification", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgbGMxEnm", "sid": 19, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgbGMxEnm", "sid": 20, "labels": {"coarse": "Structuring", "fine": "Structuring.Heading", "asp": "", "pol": ""}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgbGMxEnm", "sid": 21, "labels": {"coarse": "Request", "fine": "Request.Typo", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgbGMxEnm", "sid": 22, "labels": {"coarse": "Request", "fine": "Request.Typo", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}, {"text_id": "HkgbGMxEnm", "sid": 23, "labels": {"coarse": "Request", "fine": "Request.Typo", "asp": "Clarity", "pol": "U-Neutral"}, "secondarylabels": [], "merge-with-prior": false}], "rebuttal": [{"text_id": "rJlQL4SGC7", "sid": 0, "sentence": "Thank you for your reviews."}, {"text_id": "rJlQL4SGC7", "sid": 1, "sentence": "Here are our responses to your questions:"}, {"text_id": "rJlQL4SGC7", "sid": 2, "sentence": "1. Clarify how the skills of agents play a role in the problem setup"}, {"text_id": "rJlQL4SGC7", "sid": 3, "sentence": "We clarify the definition of skills and how it influences the manager\u2019s decision as follows."}, {"text_id": "rJlQL4SGC7", "sid": 4, "sentence": "i) As defined in Section 3, an agent\u2019s skill depends on its state transition probabilities and its policy."}, {"text_id": "rJlQL4SGC7", "sid": 5, "sentence": "The state transition probabilities define if a resource can be collected by an agent (i.e., whether the \u201ccollect\u201d action executed by this agent will have real effect), and it is equivalent to a binary value for each resource in Resource Collection."}, {"text_id": "rJlQL4SGC7", "sid": 6, "sentence": "The agent\u2019s skill also depends on its policy because it affects how fast an agent can achieve a goal."}, {"text_id": "rJlQL4SGC7", "sid": 7, "sentence": "E.g., when the agent has a suboptimal policy, it may not be able to reach a goal within the time limit even though it actually can collect the resource if given more time."}, {"text_id": "rJlQL4SGC7", "sid": 8, "sentence": "ii) The skills are completely hidden from the manager."}, {"text_id": "rJlQL4SGC7", "sid": 9, "sentence": "It can be inferred by the manager based on the performance history, and also on the estimated worker policies by IL."}, {"text_id": "rJlQL4SGC7", "sid": 10, "sentence": "However, only checking whether a goal is reached is not sufficient to determine skills."}, {"text_id": "rJlQL4SGC7", "sid": 11, "sentence": "Failing to reach a goal may be a result of several reasons -- it may be because i) the bonus in the contract is too low, ii) the contract terminates prematurely before the agent can reach the goal, or iii) the assigned task depends on another task which has not been finished yet."}, {"text_id": "rJlQL4SGC7", "sid": 12, "sentence": "So the manager needs to infer agents\u2019 skills, preferences, and the task dependency jointly through multiple trials."}, {"text_id": "rJlQL4SGC7", "sid": 13, "sentence": "2. Is maximizing utility justified?"}, {"text_id": "rJlQL4SGC7", "sid": 14, "sentence": "Maximizing utility is actually the setup in similar problems in economics."}, {"text_id": "rJlQL4SGC7", "sid": 15, "sentence": "Just like those problems (e.g., mechanism design), this paper focuses on scenarios where agents won\u2019t truthfully or clearly reveal its skills and preferences to the manager, and do not always behave optimally."}, {"text_id": "rJlQL4SGC7", "sid": 16, "sentence": "As we stated in the paper, maximizing utility is more realistic, and typically the span of the decision making process of the manager is much shorter than the time needed for improving worker agents."}, {"text_id": "rJlQL4SGC7", "sid": 17, "sentence": "Let\u2019s consider a simple scenario."}, {"text_id": "rJlQL4SGC7", "sid": 18, "sentence": "An agent is unable to collect a certain kind of resource."}, {"text_id": "rJlQL4SGC7", "sid": 19, "sentence": "By maximizing its utility, it may still accept the contract and go to that resource."}, {"text_id": "rJlQL4SGC7", "sid": 20, "sentence": "Once a resource is occupied by this agent, other agents can no longer collect it according to our setting."}, {"text_id": "rJlQL4SGC7", "sid": 21, "sentence": "This means that the resource will never be really collected."}, {"text_id": "rJlQL4SGC7", "sid": 22, "sentence": "As an empirical evidence,  you may compare the S2 and S3 settings with S1 in Resource Collection."}, {"text_id": "rJlQL4SGC7", "sid": 23, "sentence": "In S2 and S3, workers may prefer a task that it can not perform, which should never happen in the case of maximizing return."}, {"text_id": "rJlQL4SGC7", "sid": 24, "sentence": "As a result (shown in Figure 4b and Figure 4c), the training difficult significantly increases."}, {"text_id": "rJlQL4SGC7", "sid": 25, "sentence": "3. Are there alternate ways to overcome maintaining the UCB explicitly, especially for the number of time-steps?"}, {"text_id": "rJlQL4SGC7", "sid": 26, "sentence": "Yes, there are ways to overcome this."}, {"text_id": "rJlQL4SGC7", "sid": 27, "sentence": "First, we can define small time intervals instead of maintaining statistics for each step (i.e., combining statistics in every dT consecutive steps will reduce the complexity to 1 / dT of the original size)."}, {"text_id": "rJlQL4SGC7", "sid": 28, "sentence": "Note that this has been done in results shown in Appendix C.1, where dT also means that for every dT steps, the manager can only change the contracts once."}, {"text_id": "rJlQL4SGC7", "sid": 29, "sentence": "Second, we may define a maximum number of steps to be considered in the performance history, which can be determined by the upper bound of the execution time for a subtask, and can be smaller than the step limit of the whole episode."}, {"text_id": "rJlQL4SGC7", "sid": 30, "sentence": "4. What are the units for rewards in the plots?"}, {"text_id": "rJlQL4SGC7", "sid": 31, "sentence": "It is the average per episode."}, {"text_id": "rJlQL4SGC7", "sid": 32, "sentence": "The reward is defined as in Section 5.1.1 and Section 5.1.2 without any rescaling."}, {"text_id": "rJlQL4SGC7", "sid": 33, "sentence": "We have added this in the caption."}, {"text_id": "rJlQL4SGC7", "sid": 34, "sentence": "5. Typos"}, {"text_id": "rJlQL4SGC7", "sid": 35, "sentence": "Thank you for pointing out these typos. We will fix them in the next revision."}], "rebuttallabels": [{"labels": {"alignments": [], "responsetype": "social", "coarseresponse": "nonarg"}, "text_id": "rJlQL4SGC7", "sid": 0}, {"labels": {"alignments": [], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJlQL4SGC7", "sid": 1}, {"labels": {"alignments": [10, 11, 12], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJlQL4SGC7", "sid": 2}, {"labels": {"alignments": [10, 11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 3}, {"labels": {"alignments": [10, 11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 4}, {"labels": {"alignments": [10, 11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 5}, {"labels": {"alignments": [10, 11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 6}, {"labels": {"alignments": [10, 11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 7}, {"labels": {"alignments": [10, 11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 8}, {"labels": {"alignments": [10, 11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 9}, {"labels": {"alignments": [10, 11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 10}, {"labels": {"alignments": [10, 11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 11}, {"labels": {"alignments": [10, 11, 12], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 12}, {"labels": {"alignments": [13, 14], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJlQL4SGC7", "sid": 13}, {"labels": {"alignments": [13, 14], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 14}, {"labels": {"alignments": [13, 14], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 15}, {"labels": {"alignments": [13, 14], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 16}, {"labels": {"alignments": [13, 14], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 17}, {"labels": {"alignments": [13, 14], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 18}, {"labels": {"alignments": [13, 14], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 19}, {"labels": {"alignments": [13, 14], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 20}, {"labels": {"alignments": [13, 14], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 21}, {"labels": {"alignments": [13, 14], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 22}, {"labels": {"alignments": [13, 14], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 23}, {"labels": {"alignments": [13, 14], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 24}, {"labels": {"alignments": [16], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJlQL4SGC7", "sid": 25}, {"labels": {"alignments": [16], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 26}, {"labels": {"alignments": [16], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 27}, {"labels": {"alignments": [16], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 28}, {"labels": {"alignments": [16], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 29}, {"labels": {"alignments": [18], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJlQL4SGC7", "sid": 30}, {"labels": {"alignments": [18], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 31}, {"labels": {"alignments": [18], "responsetype": "answer", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 32}, {"labels": {"alignments": [18], "responsetype": "done_manu_Yes", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 33}, {"labels": {"alignments": [19, 20, 21, 22, 23], "responsetype": "structuring", "coarseresponse": "nonarg"}, "text_id": "rJlQL4SGC7", "sid": 34}, {"labels": {"alignments": [19, 20, 21, 22, 23], "responsetype": "by-cr_manu_Yes", "coarseresponse": "concur"}, "text_id": "rJlQL4SGC7", "sid": 35}], "metadata": {"anno": "anno2", "review": "HkgbGMxEnm", "rebuttal": "rJlQL4SGC7", "conference": "ICLR2019", "title": "M^3RL: Mind-aware Multi-agent Management Reinforcement Learning", "reviewer": "AnonReviewer1", "forum_id": "BkzeUiRcY7", "rating": "6: Marginally above acceptance threshold", "confidence": "1: The reviewer's evaluation is an educated guess"}}